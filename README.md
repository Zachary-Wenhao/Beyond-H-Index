# Research Impact Comparison Survey

**Carnegie Mellon University Research Study**

## Overview

This is an interactive web-based survey designed to explore how researchers evaluate excellence and impact in AI and Natural Language Processing. Participants compare pairs of prominent researchers based on their publication profiles and career metrics.

## Survey Details

- **Duration:** 15-20 minutes
- **Comparisons:** 10 pairs of researchers
- **Data Collection:** Client-side (browser localStorage)
- **Privacy:** No personal information is collected without consent

## Study Design

The survey employs a randomized within-subjects design where participants see researcher profiles in either:
- **Minimal information mode:** Basic metrics only
- **Full information mode:** Comprehensive publication and impact data

This randomization allows us to study how different information influences evaluation of research impact.

## Technical Details

- Pure HTML/CSS/JavaScript (no backend required)
- Fully client-side operation
- Responses stored in browser until export
- Works offline once loaded

## For Participants

Simply visit the hosted survey URL and follow the on-screen instructions. Your responses are valuable for understanding how the academic community evaluates research impact beyond traditional metrics like the h-index.

## For Researchers

This survey is part of a study examining the limitations of traditional citation metrics and exploring how researchers make holistic judgments about academic impact.

### IRB Information

If you have questions about your rights as a research participant, please contact the Carnegie Mellon University IRB.

### Contact

For questions about this research study, please contact the research team.

## License

This survey is for research purposes only.

---

**Last Updated:** November 2025

