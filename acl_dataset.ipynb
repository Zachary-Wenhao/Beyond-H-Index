{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACL PyPI Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acl_anthology import Anthology\n",
    "anthology = Anthology.from_repo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = anthology.get(\"D10-1001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACL Anthology \n",
    "- [Github](https://github.com/acl-org/acl-anthology/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing\n",
      "Authors: [Name(first='Alexander M.', last='Rush'), Name(first='David', last='Sontag'), Name(first='Michael', last='Collins'), Name(first='Tommi', last='Jaakkola')]\n"
     ]
    }
   ],
   "source": [
    "title = str(paper.title)\n",
    "authors = [author.name for author in paper.authors]\n",
    "print(f'Title: {title}\\nAuthors: {authors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'rush-etal-2010-dual',\n",
       " 'title': 'On Dual Decomposition and Linear Programming Relaxations for Natural Language Processing',\n",
       " 'type': 'paper-conference',\n",
       " 'author': [{'family': 'Rush', 'given': 'Alexander M.'},\n",
       "  {'family': 'Sontag', 'given': 'David'},\n",
       "  {'family': 'Collins', 'given': 'Michael'},\n",
       "  {'family': 'Jaakkola', 'given': 'Tommi'}],\n",
       " 'editor': [{'family': 'Li', 'given': 'Hang'},\n",
       "  {'family': 'Màrquez', 'given': 'Lluís'}],\n",
       " 'publisher': 'Association for Computational Linguistics',\n",
       " 'publisher-place': 'Cambridge, MA',\n",
       " 'issued': {'date-parts': [['2010']]},\n",
       " 'URL': 'https://aclanthology.org/D10-1001/',\n",
       " 'page': '1–11',\n",
       " 'container-title': 'Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper.citeproc_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACL Anthology Corpus \n",
    "- [Github](https://github.com/shauryr/ACL-anthology-corpus), [HuggingFace](https://huggingface.co/datasets/WINGNUS/ACL-OCL)\n",
    "- AAC_path: the 489MB Dataframe version on Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow\n",
    "# Dataframe with extracted metadata (table below with details) and full text of the collection for analysis : size 489M\n",
    "AAC_path = \"data/acl-publication-info.74k.parquet\"\n",
    "\n",
    "df = pd.read_parquet(AAC_path, engine='pyarrow')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Info for dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape\n",
    "print(f\"Dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "print('\\n------------------\\n')\n",
    "# Column names + data types\n",
    "print(df.info())\n",
    "print('\\n------------------\\n')\n",
    "\n",
    "# Descriptive statistics for numeric columns\n",
    "print(df.describe())\n",
    "print('\\n------------------\\n')\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing values per column:\", missing_values)\n",
    "print('\\n------------------\\n')\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "print('\\n------------------\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line Plot: Year vs Publication Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yearly_publications = df['year'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(yearly_publications.index, yearly_publications.values, marker='o')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Publications')\n",
    "plt.title('Publication Trend Over Time')\n",
    "plt.xticks(rotation=60)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full_text column: this would probably be an essential part where we derive our citation network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_full_text = df.loc[0, 'full_text']\n",
    "sample = sample_full_text.lower().strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
