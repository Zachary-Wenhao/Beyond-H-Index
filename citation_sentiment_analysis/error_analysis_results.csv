text,label,labels,original_index,predicted_label,predicted_numeric,confidence,correct,prob_neutral,prob_positive,prob_negative
"3 Perceptron Training The parsing problem is to find a mapping from a set of sentences x ??X to a set of parses y ??Y. We assume that the mapping F is represented through a feature vector (x,y) ??Rd and a parameter vector  ??Rd in the following way (Collins, 2002): F(x) = argmax y?GEN(x) (x,y) (1) where GEN(x) denotes the set of possible parses for sentence x and (x,y)   = summationtexti ii(x,y) is the inner product",o,0,0,o,0,0.9218519,True,0.9218519,0.06644129,0.011706844
"In Table 6 we report our results, together with the state-of-the-art from the ACL wiki5 and the scores of Turney (2008) (PairClass) and from Amac Herdagdelens PairSpace system, that was trained on ukWaC",o,0,1,p,1,0.6417967,False,0.3390298,0.6417967,0.019173505
"(2006) produced a corpus of 4,000 questions annotated with syntactic trees, and obtained an improvement in parsing accuracy for Bikels reimplementation of the Collins parser (Collins, 1997) by training a new parser model with a combination of newspaper and question data",n,2,2,o,0,0.7109326,False,0.7109326,0.24992666,0.039140727
"Our corpora were automatically aligned with Giza++ (Och et al. , 1999) in both directions between source and target and symmetrised using the intersection heuristic (Koehn et al. , 2003)",o,0,3,o,0,0.9568383,True,0.9568383,0.039635908,0.0035258404
"In this work, we propose two models that can be categorized as extensions of standard word lexicons: A discriminative word lexicon that uses global, i.e. sentence-level source information to predict the target words using a statistical classifier and a trigger-based lexicon model that extends the well-known IBM model 1 (Brown et al., 1993) with a second trigger, allowing for a more finegrained lexical choice of target words",p,1,4,p,1,0.6126795,True,0.33522922,0.6126795,0.052091315
"We could also introduce new variables, e.g., nonterminal refinements (Matsuzaki et al., 2005), or secondary linksMij (not constrained by TREE/PTREE) that augment the parse with representations of control, binding, etc",o,0,5,o,0,0.9595925,True,0.9595925,0.03486633,0.0055412045
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact2 or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan & Brockett, 2004) and word N-gram overlap for (Barzilay & Lee, 2003)",o,0,6,n,2,0.61773485,False,0.27606583,0.106199265,0.61773485
"2 Previous Work We briefly outline the most important existing methods and cite error rates on a standard English data set, sections 03-06 of the Wall Street Journal (WSJ) corpus (Marcus et al., 1993), containing nearly 27,000 examples",o,0,7,p,1,0.8079433,False,0.17904836,0.8079433,0.013008274
"The averaged perceptron (Collins, 2002) is a variant which averages the w across all iterations; it has demonstrated good generalization especially with data that is not linearly separable, as in many natural language processing problems",p,1,8,p,1,0.8652098,True,0.11848814,0.8652098,0.016302075
"Recently Bean and Riloff (2004) have sought to acquire automatically some semantic patterns that can be used as contextual information to improve reference resolution, using techniques adapted from information extraction",o,0,9,o,0,0.87740225,True,0.87740225,0.11781941,0.0047782524
"3.2 Wall Street Journal Our out-of-domain data is the Wall Street Journal (WSJ) portion of the Penn Treebank (Marcus et al. , 1993) which consists of about 40,000 sentences (one million words) annotated with syntactic information",o,0,10,o,0,0.80412036,True,0.80412036,0.18171586,0.014163758
"By contrast, in the training method proposed by (Jansche, 2005), the discriminative function f(x;w) is estimated to maximize the F 1 -score of training dataset D. This training method employs an approximate form of the F 1 -score obtained by using a logistic function",o,0,11,o,0,0.91371745,True,0.91371745,0.068897605,0.017384993
"Turney (2002) predicates the sentiment orientation of a review by the average semantic orientation of the phrases in the review that contain adjectives or adverbs, which is denoted as the semantic oriented method",o,0,12,o,0,0.9705245,True,0.9705245,0.024481189,0.0049943402
"The traditional method of evaluating similarity in a semantic network by measuring the path length between two nodes (Lee et al. , 1993; Rada et al. , 1989) also captures this, albeit indirectly, when the semantic network is just an IS-A hierarchy: if the minimal path of IS-A links between two nodes is long, that means it is necessary to go high in the taxonomy, to more abstract concepts, in order to find their least upper bound",o,0,13,o,0,0.7922893,True,0.7922893,0.095367625,0.112343095
"These lists are rescored with the different models described above, a character penalty, and three different features based on IBM Models 1 and 2 (Brown et al. , 1993) calculated in both translation directions",o,0,14,o,0,0.9481082,True,0.9481082,0.041723125,0.01016868
"In other words, learning with L1 regularization naturally has an intrinsic effect of feature selection, which results in an 97 efficient and interpretable inference with almost the same performance as L2 regularization (Gao et al., 2007)",o,0,15,o,0,0.5120114,True,0.5120114,0.36324778,0.12474074
"Bean and Riloff (2004) used bootstrapping to extend their semantic compatibility model, which they called contextual-role knowledge, by identifying certain cases of easily-resolved anaphors and antecedents",o,0,16,o,0,0.954738,True,0.954738,0.040951528,0.0043104677
"5 The Experimental Results We used the Penn Treebank WSJ corpus (Marcus et al. , 1993) to perform empirical experiments on the proposed parsing models",o,0,17,o,0,0.96608144,True,0.96608144,0.027939325,0.0059792027
"POS disambiguation has usually been performed by statistical approaches, mainly using the hidden Markov model (HMM) in English research communities (Cutting et al. 1992; Kupiec 1992; Weischedel et al. 1993)",o,0,18,o,0,0.84051424,True,0.84051424,0.15685204,0.002633698
"Feature selection methods have been proposed in the maximum-entropy literature by several authors (Ratnaparkhi, Roukos, and Ward 1994; Berger, Della Pietra, and Della Pietra 1996; Della Pietra, Della Pietra, and Lafferty 1997; Papineni, Roukos, and Ward 1997, 1998; McCallum 2003; Zhou et al. 2003; Riezler and Vasserman 2004)",o,0,19,o,0,0.94074446,True,0.94074446,0.055106584,0.004148901
"Among the most widely studied is the Gibbs distribution (Mark, Miller, and Grenander 1996; Mark et al. 1996; Mark 1997; Abney 1997)",o,0,20,p,1,0.9223238,False,0.07039642,0.9223238,0.007279772
"For a detailed introduction to IBM translation models, please see (Brown et al. , 1993)",o,0,21,o,0,0.92556363,True,0.92556363,0.065494455,0.008941957
"In the field of statistical analysis of natural language data, it is common to use measures of lexical association, such as the informationtheoretic measure of mutual information, to extract useful relationships between words (e.g. Church and Hanks (1990))",o,0,22,o,0,0.7963926,True,0.7963926,0.2001832,0.0034242196
"Other statistical systems that address word classification probleans do not emphasize the use of linguistic knowledge and do not deal with a specific word class\[Brown et al. , 1992\], or do not exploit as much linguistic knowledge as we do \[Pereira et al. , 1993\]",n,2,23,n,2,0.5576354,True,0.40282816,0.039536368,0.5576354
"Despite the above differences, since the theorems of convergence and their proof (Collins, 2002) are only dependent on the feature vectors, and not on the source of the feature definitions, the perceptron algorithm is applicable to the training of our CWS model",o,0,24,o,0,0.88976735,True,0.88976735,0.07029003,0.039942637
"al. 2003b) 147 is (B)eginning, (I)nside or (O)utside of a chunk (Ramshaw & Marcus, 1995)",o,0,25,o,0,0.9689397,True,0.9689397,0.026886053,0.004174259
arpuat and Wu (2007) and Chan et a,o,0,26,o,0,0.9485502,True,0.9485502,0.04648202,0.0049678227
"Although the relative success of previous disambiguation systems (e.g. Yarowsky, 1995) suggests that this should be the case, the effect has usually not been quantified as the emphasis was on a task-based evaluation",p,1,27,n,2,0.8687606,False,0.09605776,0.03518165,0.8687606
"The agreement on identifying the boundaries of units, using the AK statistic discussed in (Carletta, 1996), was AK BP BMBL (for two annotators and 500 units); the agreement on features(2 annotators and at least 200 units) was follows: Attribute AK Value utype .76 verbed .9 finite .81 subject .86 NPs Our instructions for identifying NP markables derive from those proposed in the MATE project scheme for annotating anaphoric relations (Poesio et al. , 1999)",o,0,28,o,0,0.9696982,True,0.9696982,0.025267625,0.00503414
"4 Method-2: Simple Chunk-based Extraction To overcome the shortcomings of the Brill tagger in identifying particles, we next look to full chunk 2Note, this is the same as the maximum span length of 5 used by Smadja (1993), and above the maximum attested NP length of 3 from our corpus study (see Section 2.2)",o,0,29,o,0,0.77958035,True,0.77958035,0.09077329,0.12964636
"Arguably the most widely used is the mutual information (Hindle, 1990; Church and Hanks, 1990; Dagan et al. , 1995; Luk, 1995; D. Lin, 1998a)",p,1,30,p,1,0.92482656,True,0.056332204,0.92482656,0.018841306
urney (2002) suggested comparing the frequency of phrase co-occurrences with words predetermined by the sentiment lexico,o,0,31,o,0,0.9666195,True,0.9666195,0.026867548,0.0065130307
"This situation is very similar to that involved in training HMM text taggers, where joint probabilities are computed that a particular word corresponds to a particular part-ofspeech, and the rest of the words in the sentence are also generated (e.g. \[Cutting et al. , 1992\])",o,0,32,o,0,0.95812386,True,0.95812386,0.036503162,0.0053729834
"the Wall Street Journal (WSJ) sections of the Penn Treebank (Marcus et al., 1993) as training set, tests on BROWN Sections typically result in a 6-8% drop in labeled attachment scores, although the average sentence length is much shorter in BROWN than that in WSJ",o,0,33,o,0,0.7662533,True,0.7662533,0.07866085,0.15508582
"(owenOcogentex.com) 1 Introduction Dependency grammar has a long tradition in syntactic theory, dating back to at least Tesni~re's work from the thirties3 Recently, it has gained renewed attention as empirical methods in parsing are discovering the importance of relations between words (see, e.g., (Collins, 1997)), which is what dependency grammars model explicitly do, but context-free phrasestructure grammars do not",o,0,34,o,0,0.78371507,True,0.78371507,0.18161468,0.034670234
"Feature comparison measures: to convert two feature sets into a scalar value, several measures have been proposed, such as cosine, Lins measure (Lin, 1998), Kullback-Leibler (KL) divergence and its variants",o,0,35,o,0,0.94344646,True,0.94344646,0.053643063,0.0029103975
larke and Lapata (2007) included discourse level features in their framework to leverage context for enhancing coherenc,o,0,36,o,0,0.9607743,True,0.9607743,0.03337731,0.005848452
"They were based on mutual information (Church & Hanks, 1989), conditional probabilities (Rapp, 1996), or on some standard statistical tests, such as the chi-square test or the loglikelihood ratio (Dunning, 1993)",p,1,37,o,0,0.9665083,False,0.9665083,0.029278802,0.004212865
"Since this trade-off is also affected by the settings of various pruning parameters, we compared decoding time and translation quality, as measured by BLEU score (Papineni et al, 2002), for the two models on our first test set over a broad range of settings for the decoder pruning parameters",o,0,38,o,0,0.9611831,True,0.9611831,0.029539932,0.009277016
"3.1 Phrase-Based Models According to the translation model presented in (Koehn et al. , 2003), given a source sentence f, the best target translation can be obtained using the following model best e 288 )( )()(maxarg )(maxarg | | e e e eef fee length LM best pp p = = (1) Where the translation model can be decomposed into )( | efp  =  = I i i iii i i II aefpbadef efp 1 1 1 1 ),|()()|( )|(   w (2) Where )|( i i ef is the phrase translation probability",o,0,39,o,0,0.93768483,True,0.93768483,0.057087533,0.0052276445
"For evaluation, we used the BLEU metrics, which calculates the geometric mean of n-gram precision for the MT outputs found in reference translations (Papineni et al. , 2002)",o,0,40,o,0,0.96522063,True,0.96522063,0.02942958,0.00534972
"David McClosky, Eugene Charniak, and Mark Johnson Brown Laboratory for Linguistic Information Processing (BLLIP) Brown University Providence, RI 02912 {dmcc|ec|mj}@cs.brown.edu Abstract Self-training has been shown capable of improving on state-of-the-art parser performance (McClosky et al., 2006) despite the conventional wisdom on the matter and several studies to the contrary (Charniak, 1997; Steedman et al., 2003)",p,1,41,p,1,0.71289665,True,0.19468111,0.71289665,0.09242225
"For a full description of the algorithm, see (Collins, 2002a)",o,0,42,o,0,0.95575774,True,0.95575774,0.037656125,0.0065861265
"SMT Team (2003) also used minimum error training as in Och (2003), but used a large number of feature functions",o,0,43,o,0,0.7031942,True,0.7031942,0.089619644,0.20718616
"We use the following features for our rules:  sourceand target-conditioned neg-log lexical weights as described in (Koehn et al. , 2003b)  neg-log relative frequencies: left-handside-conditioned, target-phrase-conditioned, source-phrase-conditioned  Counters: n.o. rule applications, n.o. target words  Flags: IsPurelyLexical (i.e. , contains only terminals), IsPurelyAbstract (i.e. , contains only nonterminals), IsXRule (i.e. , non-syntactical span), IsGlueRule 139  Penalties: rareness penalty exp(1  RuleFrequency); unbalancedness penalty |MeanTargetSourceRatio  n.o. source words n.o. target words| 4 Parsing Our SynCFG rules are equivalent to a probabilistic context-free grammar and decoding is therefore an application of chart parsing",o,0,44,o,0,0.9659498,True,0.9659498,0.030673673,0.0033765747
"These dependencies differ from those used by Liu and Gildea (2005), in that they are extracted according to the rules of the LFG grammar and they are labelled with a type of grammatical relation that connects the head and the modifier, such as subject, determiner, etc. The presence of grammatical relation labels adds another layer of important linguistic information into the comparison and allows us to account for partial matches, for example when a lexical item finds itself in a correct relation but with an incorrect partner",o,0,45,o,0,0.8584329,True,0.8584329,0.11675916,0.024807926
"3.5 Domain adaptation in Machine Translation Within MT there has been a variety of approaches dealing with domain adaption (for example (Wu et al., 2008; Koehn and Schroeder, 2007)",o,0,46,o,0,0.9060947,True,0.9060947,0.08845409,0.005451346
"Therefore, whenever we have access to a large amount of labeled data from some source (out-of-domain), but we would like a model that performs well on some new target domain (Gildea, 2001; Daume III, 2007), we face the problem of domain adaptation",o,0,47,o,0,0.61373556,True,0.61373556,0.13640901,0.24985543
"Collocations have been widely used for tasks such as word sense disambiguation (WSD) (Yarowsky, 1995), information extraction (IE) (Riloff, 1996), and named-entity recognition (Collins and Singer, 1999)",o,0,48,p,1,0.8528567,False,0.14477111,0.8528567,0.0023722192
"Many statistical metrics have been proposed, including pointwise mutual information (MI) (Church et al, 1990), mean and variance, hypothesis testing (t-test, chisquare test, etc.), log-likelihood ratio (LR) (Dunning, 1993), statistic language model (Tomokiyo, et al, 2003), and so on",o,0,49,o,0,0.93909955,True,0.93909955,0.05813076,0.0027697294
"Some of the more popular and more accurate of these approaches to data-driven parsing (Charniak, 2000; Collins, 1997; Klein and Manning, 2002) have been based on generative models that are closely related to probabilistic contextfree grammars",p,1,50,p,1,0.93394977,True,0.060431324,0.93394977,0.005618931
"421 Teufel and Moens Summarizing Scientific Articles We use the kappa coefficient K (Siegel and Castellan 1988) to measure stability and reproducibility, following Carletta (1996)",o,0,51,o,0,0.9567367,True,0.9567367,0.03983298,0.0034303723
"These methods have been used in machine translation (Brown et al. , 1990; Sadler, 1989), terminology research and translation aids (Isabelle, 1992; Ogden and Gonzales, 1993), bilingual lexicography (Klavans and Tzoukermann, 1990), collocation studies (Smadja, 1992), word-sense disambiguation (Brown et al. , 1991b; Gale et al. , 1992) and information retrieval in a multilingual environment (Landauer and Littman, 1990)",o,0,52,o,0,0.94180447,True,0.94180447,0.055791736,0.002403905
"A synchronous 363 binarization method is proposed in (Zhang et al., 2006) whose basic idea is to build a left-heavy binary synchronous tree (Shapiro and Stephens, 1991) with a left-to-right shift-reduce algorithm",o,0,53,o,0,0.9574905,True,0.9574905,0.038753595,0.003755796
"Specifically, three features are used to instantiate the templates:  POS tags on both sides: We assign POS tags using the MXPOST tagger (Ratnaparkhi, 1996) for English and Chinese, and Connexor for Spanish",o,0,54,o,0,0.9631113,True,0.9631113,0.034352433,0.002536324
"For example, the Penn Treebank (Marcus et al. , 1993) was annotated with skeletal syntactic structure, and many syntactic parsers were evaluated and compared on the corpus",o,0,55,o,0,0.9590145,True,0.9590145,0.03526629,0.00571924
"1 Introduction The emergence of phrase-based statistical machine translation (PSMT) (Koehn et al., 2003) has been one of the major developments in statistical approaches to translation",p,1,56,p,1,0.94166744,True,0.055539016,0.94166744,0.0027936238
"C0,C,q  1,q xq xq1 xq1 xq xr xr+1 Table 6: Lexicalized Features for Joint Models aging of the weights suggested by (Collins, 2002)",o,0,57,o,0,0.9672926,True,0.9672926,0.027393125,0.00531429
"Regarding error detection in corpora, Ratnaparkhi (1996) discusses inconsistencies in the Penn Treebank and relates them to interannotator differences in tagging style",o,0,58,o,0,0.9599918,True,0.9599918,0.031329542,0.008678685
"This linear model is learned using a variant of the incremental perceptron algorithm (Collins and Roark, 2004; Daume and Marcu, 2005)",o,0,59,o,0,0.96877843,True,0.96877843,0.0273917,0.0038298776
"A similar approach is used here, including a collapsed version of the Treebank POS tag set (Marcus et al., 1993), with additions for specific words (e.g. personal pronouns and filled pause markers), compound punctuation (e.g. multiple exclamation marks), and a general emoticon tag, resulting in a total of 41 tags",o,0,60,o,0,0.95387644,True,0.95387644,0.039715108,0.006408367
"MI is defined in general as follows: y) I ix y) = log2 P(x) P(y) We can use this definition to derive an estimate of the connectedness between words, in terms of collocations (Smadja, 1993), but also in terms of phrases and grammatical relations (Hindle, 1990)",o,0,61,o,0,0.95922756,True,0.95922756,0.035222497,0.0055499263
"Mutual information compares the probability of the co-occurence of words a and b with the independent probabilities of occurrence of a and b (Church and Hanks, 1990)",o,0,62,o,0,0.95793825,True,0.95793825,0.030777842,0.0112839015
"The parser is coupled with an on-line averaged perceptron (Collins, 2002) as the learning method",o,0,63,o,0,0.9570244,True,0.9570244,0.039820645,0.0031549893
"As expected, we see that MST does better than Malt for all categories except nouns and pronouns (McDonald and Nivre, 2007)",o,0,64,n,2,0.5361348,False,0.31967208,0.14419307,0.5361348
"However, as Categorial Grammar formalisms do not usually change the lexical entries of words to deal with movement, but use further rules (Wood, 1993; Steedman, 1993; Hockenmaier et al. , 2000), the lexicons learned here will be valid over corpora with movement",o,0,65,o,0,0.8976898,True,0.8976898,0.056085393,0.04622478
"Wu (1997) demonstrated that for pairs of sentences that are less than 16 words, the ITG alignment space has a good coverage over all possibilities",o,0,66,o,0,0.60966796,True,0.60966796,0.29720098,0.0931311
"The recent approach for editing extracted text spans (Jing and McKeown, 2000) may also produce improvement for our algorithm",p,1,67,p,1,0.66719776,True,0.3038291,0.66719776,0.028973099
"138 2 Rule Generation We start with phrase translations on the parallel training data using the techniques and implementation described in (Koehn et al. , 2003a)",o,0,68,o,0,0.9668309,True,0.9668309,0.029854847,0.0033142865
"Translation quality is reported using case-insensitive BLEU (Papineni et al., 2002)",o,0,69,o,0,0.96795523,True,0.96795523,0.027947424,0.0040973565
"distance (MSD) and the maximum swap segment size (MSSS) ranging from 0 to 10 and evaluated the translations with the BLEU7 metric (Papineni et al. , 2002)",o,0,70,o,0,0.96516585,True,0.96516585,0.029206028,0.005628082
"The word alignments were created with Giza++ (Och and Ney, 2003) applied to a parallel corpus containing the complete Europarl training data, plus sets of 4,051 sentence pairs created by pairing the test sentences with the reference translations, and the test sentences paired with each of the system translations",o,0,71,o,0,0.9680577,True,0.9680577,0.02843736,0.003505026
he idea of tracing polarity through adjective cooccurrence is adopted by Turney (2002) for the binary (positive and negative) classification of text review,o,0,72,o,0,0.9611324,True,0.9611324,0.035686668,0.0031809334
"For a class bigram model, find  : V --+ C to maximize ~(T) = ~I/L=I p(wi I(wl))p((wi)l(wi-1)))) Alternatively, perplexity (Jardino an d Adda, 1993) or average mutual information (Brown et al. , 1992) can be used as the characteristic value for optimization",o,0,73,o,0,0.9623403,True,0.9623403,0.032948073,0.004711622
"The publicly available Moses4 decoder is used for training and decoding (Koehn and Hoang, 2007)",o,0,74,o,0,0.83130103,True,0.83130103,0.16273654,0.0059625125
"Some of them have been fully tested in real size texts (e.g. statistical methods (Yarowsky, 1992), (Yarowsky, 1994), (Miller and Teibel, 1991), knowledge based methods (Sussna, 1993), (Agirre and Rigau, 1996), or mixed methods (Richardson et al. , 1994), (Resnik, 1995))",o,0,75,o,0,0.54834706,True,0.54834706,0.43974954,0.011903474
"4.2 Data The data comes from the CoNLL 2000 shared task (Sang and Buchholz, 2000), which consists of sentences from the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993)",o,0,76,o,0,0.9710298,True,0.9710298,0.024891809,0.0040783845
"The problem is that with such a definition of collocations, even when improved, one identifies not only collocations but freecombining pairs frequently appearing together such as lawyer-client; doctor-hospital, as pointed out by Smadja (1993)",o,0,77,o,0,0.60883564,True,0.60883564,0.12000398,0.2711604
"Our method is a natural extension of those proposed in (Brown et al. , 1992) and (Li and Abe, 1996), and overcomes their drawbacks while retaining their advantages",n,2,78,o,0,0.4283547,False,0.4283547,0.41578424,0.15586111
"Since it loosely links the two sentences syntactic structures, QG is well suited for problems like word alignment for MT (Smith and Eisner, 2006) and question answering (Wang et al., 2007)",o,0,79,p,1,0.5268081,False,0.44840798,0.5268081,0.024783935
"Many-to-many word alignments are induced by running a one-to-many word alignment model, such as GIZA++ (Och and Ney, 2003), in both directions and by combining the results based on a heuristic (Koehn et al. , 2003)",o,0,80,o,0,0.95913386,True,0.95913386,0.03764182,0.0032243074
"(Yarowsky, 1995) reports a success rate of 96% disambiguating twelve words with two clear sense distinctions each one)",o,0,81,p,1,0.59030217,False,0.30925003,0.59030217,0.100447826
"We implement this algorithm using the perceptron framework, as it can be easily modified for structured prediction while preserving convergence guarantees (Daume III and Marcu, 2005; Snyder and Barzilay, 2007)",o,0,82,o,0,0.77224624,True,0.77224624,0.18850929,0.0392445
"(1992b) has proved to be a simple yet powerful observation and has been successfully used in word sense disambiguation (WSD) and related tasks (e.g., Yarowsky (1995); Agirre and Rigau The author was partially funded by GALE DARPA Contract No",p,1,83,p,1,0.813669,True,0.18226469,0.813669,0.004066268
"Syntax-based MT approaches began with Wu (1997), who introduced the Inversion Transduction Grammars",o,0,84,o,0,0.9527704,True,0.9527704,0.04296978,0.004259781
"The progress in parsing technology are noteworthy, and in particular, various statistical dependency models have been proposed(Collins, 1997),, (Ratnaparkhi, 1997), (Charniak, 2000)",o,0,85,p,1,0.88886166,False,0.09986152,0.88886166,0.011276874
"In marked contrast to annotated training material for partof-speech tagging, (a) there is no coarse-level set of sense distinctions widely agreed upon (whereas part-of-speech tag sets tend to differ in the details); (b) sense annotation has a comparatively high error rate (Miller, personal communication, reports an upper bound for human annotators of around 90% for ambiguous cases, using a non-blind evaluation method that may make even this estimate overly optimistic); and (c) no fully automatic method provides high enough quality output to support the """"annotate automatically, correct manually"""" methodology used to provide high volume annotation by data providers like the Penn Treebank project (Marcus et al. , 1993)",o,0,86,o,0,0.44380742,True,0.44380742,0.33150494,0.2246877
"Indeed, researchers have shown that gigantic language models are key to state-ofthe-art performance (Brants et al., 2007), and the ability of phrase-based decoders to handle large-size, high-order language models with no consequence on asymptotic running time during decoding presents a compelling advantage over CKYdecoders,whosetimecomplexitygrowsprohibitively large with higher-order language models",p,1,87,p,1,0.78141534,True,0.18357448,0.78141534,0.035010155
"1 Introduction Large scale annotated corpora such as the Penn TreeBank (Marcus et al. , 1993) have played a central role in speech and natural language research",p,1,88,p,1,0.8930226,True,0.10433838,0.8930226,0.0026389817
atnaparkhi 1996,o,0,89,o,0,0.9453211,True,0.9453211,0.04488074,0.009798102
"1 Motivation Statistical part-of-speech disambiguation can be efficiently done with n-gram models (Church, 1988; Cutting et al. , 1992)",p,1,90,p,1,0.7360509,True,0.23721693,0.7360509,0.026732221
"There has of course been a large amount of work on the more general problem of word-sense disambiguation, e.g., (Yarowsky 1995) (Kilgarriff and Edmonds 2002)",o,0,91,o,0,0.5998434,True,0.5998434,0.38540155,0.014755124
"We made use of the same data set as introduced in (Cong et al., 2008; Ding et al., 2008)",o,0,92,o,0,0.93852794,True,0.93852794,0.057854757,0.0036172674
"These alignment models stem from the source-channel approach to statistical machine translation (Brown et al. , 1993)",o,0,93,o,0,0.95280176,True,0.95280176,0.042227592,0.0049706344
"This is analogous, and in a certain sense equivalent, to empirical risk minimization, which has been used successfully in related areas, such as speech recognition (Rahim and Lee, 1997), language modeling (Paciorek and Rosenfeld, 2000), and machine translation (Och, 2003)",o,0,94,p,1,0.8870523,False,0.10724447,0.8870523,0.0057032085
"203 Estimating the parameters for these models is more difficult (and more computationally expensive) than with the models considered in the previous section: rather than simply being able to count the word pairs and alignment relationships and estimate the models directly, we must use an existing model to compute the expected counts for all possible alignments, and then use these counts to update the new model.7 This training strategy is referred to as expectationmaximization (EM) and is guaranteed to always improve the quality of the prior model at each iteration (Brown et al., 1993; Dempster et al., 1977)",o,0,95,o,0,0.59916234,True,0.59916234,0.18053915,0.22029847
"The use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks, 1990; Zernik and Jacobs, 1990; Hindle, 1990)",o,0,96,o,0,0.55375135,True,0.55375135,0.4427844,0.0034642532
"In addition, the semi-supervised Morce performs (on single CPU and development data set) 77 times faster than the combination and 23 times faster than (Shen et al., 2007)",n,2,97,n,2,0.74987364,True,0.20148113,0.048645202,0.74987364
"To solve this problem, we will adapt the idea of null generated words from machine translation (Brown et al. , 1993)",o,0,98,o,0,0.92208546,True,0.92208546,0.07386388,0.004050756
"This corpus-based information typically concerns sequences of 1-3 tags or words (with some well-known exceptions, e.g. Cutting et al. 1992)",o,0,99,p,1,0.7703438,False,0.22222109,0.7703438,0.007435099
"Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al. , 2003)",o,0,100,o,0,0.9472393,True,0.9472393,0.045031894,0.0077288337
"The significance values are obtained using the loglikelihood measure assuming a binomial distribution for the unrelatedness hypothesis (Dunning, 1993)",o,0,101,o,0,0.9716974,True,0.9716974,0.023623632,0.0046791052
"According to Carletta (1996), K measures pairwise agreement among a set of coders making category judgments, correcting for expected chance agreement as follows: KP(A) -P(E) 1 -P(E) where P(A) is the proportion of times that the coders agree and P(E) is the proportion of times that they would be expected to agree by chance",o,0,102,o,0,0.9668551,True,0.9668551,0.027744101,0.0054008085
"2.3 Probabilistic models for generation with HPSG Some existing studies on probabilistic models for HPSG parsing (Malouf and van Noord, 2004; Miyao and Tsujii, 2005) adopted log-linear models (Berger et al. , 1996)",o,0,103,o,0,0.9573065,True,0.9573065,0.038577426,0.004116095
"The Attr cells summarize the performance of the 6 models on the wiki table that are based on attributional similarity only (Turney, 2006)",o,0,104,o,0,0.93598133,True,0.93598133,0.054842632,0.009176037
 Introduction Bilingual word alignment is first introduced as an intermediate result in statistical machine translation (SMT) (Brown et al. 1993,o,0,105,o,0,0.93584317,True,0.93584317,0.060413554,0.0037432848
"Some existing resources contain lists of subjective words (e.g. , Levins desire verbs (1993)), and some empirical methods in NLP have automatically identified adjectives, verbs, and N-grams that are statistically associated with subjective language (e.g. , (Turney, 2002; Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Wiebe et al. , 2001))",o,0,106,o,0,0.9523509,True,0.9523509,0.042582814,0.0050662733
"The proposed synchronous grammar is able to cover the previous proposed grammar based on tree (STSG, Eisner, 2003; Zhang et al, 2007) and tree sequence (STSSG, Zhang et al, 2008a) alignment",o,0,107,o,0,0.8952944,True,0.8952944,0.06141839,0.043287147
"(2006) and Jansche (2005), who discuss maximum expected F-score training of decision trees and logistic regression models",o,0,108,o,0,0.8898725,True,0.8898725,0.08684925,0.023278343
"With the in-depth study of opinion mining, researchers committed their efforts for more accurate results: the research of sentiment summarization (Philip et al., 2004; Hu et al., KDD 2004), domain transfer problem of the sentiment analysis (Kanayama et al., 2006; Tan et al., 2007; Blitzer et al., 2007; Tan et al., 2008; Andreevskaia et al., 2008; Tan et al., 2009) and finegrained opinion mining (Hatzivassiloglou et al., 2000; Takamura et al., 2007; Bloom et al., 2007; Wang et al., 2008; Titov et al., 2008) are the main branches of the research of opinion mining",p,1,109,o,0,0.6078956,False,0.6078956,0.37305352,0.019050866
"One of the most successful metrics for judging machine-generated text is BLEU (Papineni et al. , 2002)",p,1,110,p,1,0.92372507,True,0.060688745,0.92372507,0.015586157
"Similar to BLEU score, we also use the similar Brevity Penalty BP (Papineni et al., 2002) to penalize the short translations in computing RAcc",o,0,111,o,0,0.9577459,True,0.9577459,0.03595651,0.006297599
"The second attempts to instill knowledge of collocations in the data; we use the technique described by (Dunning, 1993) to compute multi-word expressions and then mark words that are commonly used as such with a feature that expresses this fact",o,0,112,o,0,0.9439128,True,0.9439128,0.052682936,0.003404281
"A broad view of the possible scope of lexical semantics would thus be one which tries to chart out the systematic, generalizable aspects of word meanings, and of the relations between words, drawing on readily accessible sources of lexical knowledge, such as machine readable dictionaries, encyclopedias, and representative corpora, coupled with the kind of analytic apparatus that is needed to fruitfully explore such sources, for instance custom-built parsers to cope with dictionary definitions (Vossen 1990), statistical programs to deal with the distributional properties of lexical items in large corpora (Church & Hanks 1990) etc. At the same time this kind of massive data-acquisition should be made sensitive to the borders between perceptual experience, lexical knowledge and expert knowledge",o,0,113,o,0,0.7733339,True,0.7733339,0.1984147,0.02825133
"For example, the words corruption and abuse are similar because both of them can be subjects of verbs like arouse, become, betray, cause, continue, cost, exist, force, go on, grow, have, increase, lead to, and persist, etc, and both of them can modify nouns like accusation, act, allegation, appearance, and case, etc. Many methods have been proposed to compute distributional similarity between words, e.g., (Hindle, 1990), (Pereira et al. 1993), (Grefenstette 1994) and (Lin 1998)",o,0,114,o,0,0.93328506,True,0.93328506,0.058060702,0.008654216
"Furthermore, it is not possible to apply the powerful """"one sense per discourse"""" property (Yarowsky, 1995) because there is no discourse in dictionaries",o,0,115,n,2,0.82837605,False,0.14040117,0.031222748,0.82837605
"(2008)), and distributional methods (e.g., Bergsma et al",o,0,116,o,0,0.96534806,True,0.96534806,0.026477553,0.008174377
"We use the discriminative perceptron learning algorithm (Collins, 2002; McDonald et al., 2005) to train the values of vectorw",o,0,117,o,0,0.96491367,True,0.96491367,0.032251697,0.002834769
"Previous publications on Meteor (Lavie et al., 2004; Banerjee and Lavie, 2005; Lavie and Agarwal, 2007) have described the details underlying the metric and have extensively compared its performance with Bleu and several other MT evaluation metrics",o,0,118,o,0,0.91970015,True,0.91970015,0.06575029,0.014549596
"While (Yarowsky, 1995) does not discuss distinguishing more than 2 senses of a word, there is no immediate reason to doubt that the """"one sense per collocation"""" rule (Yarowsky, 1993) would still hold for a larger number of senses",p,1,119,o,0,0.6113441,False,0.6113441,0.09100139,0.2976545
"In addition, the clustering methods used, such as HMMs and Browns algorithm (Brown et al., 1992), seem unable to adequately capture the semantics of MNs since they are based only on the information of adjacent words",n,2,120,n,2,0.8508234,True,0.1151394,0.034037217,0.8508234
"This implementation is exactly the one proposed in (Yarowsky 1995), and we will denote it as MB-D hereafter",o,0,121,o,0,0.94783705,True,0.94783705,0.04032437,0.011838656
"Other systems (Morinaga et al. , 2002; Kushal et al. , 2003) also look at Web product reviews but they do not extract 345 opinions about particular product features",o,0,122,n,2,0.6490104,False,0.32191157,0.029077949,0.6490104
"It also differs from previous proposals on lexical acquisition using statistical measures such as (Church et al. , 1991; Brent, 1991; Brown et al. , 1993) which either deny the prior existence of linguistic knowledge or use linguistic knowledge in ad hoc ways",n,2,123,o,0,0.73932695,False,0.73932695,0.047867443,0.21280557
"2 Evaluation All of the experiments described below have the same basic structure: an estimator is used to infer a bitag HMM from the unsupervised training corpus (the words of Penn Treebank (PTB) Wall Street Journal corpus (Marcus et al. , 1993)), and then the resulting model is used to label each word of that corpus with one of the HMMs hidden states",o,0,124,o,0,0.96750903,True,0.96750903,0.028710665,0.0037802982
"(1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g. , Dang and Palmer (2002), Klein and Manning (2002))",o,0,125,o,0,0.9344357,True,0.9344357,0.052833218,0.012731057
"With this model, we can provide not only qualitative textual summarization such as good food and bad service, but also a numerical scoring of sentiment, i.e., how good the food is and how bad the service is. 2 Related Work There have been many studies on sentiment classification and opinion summarization (Pang and Lee, 2004, 2005; Gamon et al., 2005; Popescu and Etzioni, 2005; Liu et al., 2005; Zhuang et al., 2006; Kim and Hovy, 2006)",o,0,126,o,0,0.8952944,True,0.8952944,0.08921064,0.015494916
"The state of a left-corner parser does capture some linguistic generalizations (Mmming an<l Carpenter, 1997; Roark a.nd Johnson, 1999), but one might still expect sparse-data problems",o,0,127,n,2,0.55234915,False,0.37722155,0.07042935,0.55234915
"The forest representation was obtained by adopting chart generation (Kay, 1996; Car93 roll et al. , 1999) where ambiguous candidates are packed into an equivalence class and mapping a chart into a forest in the same way as parsing",o,0,128,o,0,0.96979773,True,0.96979773,0.026011981,0.004190213
"Indeed, in the II scenario, (Steedman et al. , 2003a; McClosky et al. , 2006a; Charniak, 1997) reported no improvement of the base parser for small (500 sentences, in the first paper) and large (40K sentences, in the last two papers) seed datasets respectively",o,0,129,o,0,0.5075647,True,0.5075647,0.08019085,0.4122444
"In comparison, (Yarowsky, 1995) achieved 48 Table 1: A summary of the experimental results on four polysemous words",o,0,130,o,0,0.8537531,True,0.8537531,0.0898532,0.056393668
"1 Motivation Question Answering has emerged as a key area in natural language processing (NLP) to apply question parsing, information extraction, summarization, and language generation techniques (Clark et al. , 2004; Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002)",o,0,131,p,1,0.637756,False,0.3591489,0.637756,0.0030951325
"The Gaussian prior (i.e. , the P k a 2 k =7 2 k penalty) has been found in practice to be very effective in combating overfitting of the parameters to the training data (Chen and Rosenfeld 1999; Johnson et al. 1999; Lafferty, McCallum, and Pereira 2001; Riezler et al. 2002)",o,0,132,p,1,0.9207694,False,0.06894162,0.9207694,0.010288935
"Various methods (Hindle, 1990; Lin, 1998; Hagiwara et al. , 2005) have been proposed for synonym acquisition",o,0,133,o,0,0.93392617,True,0.93392617,0.061478913,0.004594887
"However, the Naive Bayes classifier has been found to perform well for word-sense disambiguation both here and in a variety of other works (e.g. , (Bruce and Wiebe, 1994a), (Gale et al. , 1992), (Leacock et al. , 1993), and (Mooney, 1996))",o,0,134,p,1,0.87051606,False,0.11729495,0.87051606,0.012188971
"Results for chunking Penn Treebank data were previously presented by several authors (Ramshaw and Marcus, 1995; Argamon et al. , 1998; Veenstra, 1998; Cardie and Pierce, 1998)",o,0,135,o,0,0.96112925,True,0.96112925,0.033777814,0.0050930376
"To identify these, we use a word-aligned corpus annotated with parse trees generated by statistical syntactic parsers [Collins, 1997; Schmidt and Schulte im Walde, 2000]",o,0,136,o,0,0.961047,True,0.961047,0.03585816,0.003094858
"The sentences were processed with the Collins parser (Collins, 1997) to generate automatic parse trees",o,0,137,o,0,0.9583606,True,0.9583606,0.037988685,0.0036506732
"Consequently, we abstract away from specifying a distribution by allowing the user to assign labels to features (c.f. Haghighi and Klein (2006) , Druck et al",o,0,138,o,0,0.958243,True,0.958243,0.033228472,0.008528571
"We conclude by noting that English language models currently used in speech recognition (Chelba and Jelinek, 1999) and automated language translation (Brants et al., 2007) are much more powerful, employing, for example, 7-gram word models (not letter models) trained on trillions of words",p,1,139,n,2,0.4801942,False,0.22926345,0.29054233,0.4801942
"For example, the HMM aligner achieves an AER of 20.7 when using the competitive thresholding heuristic of DeNero and Klein (2007)",o,0,140,o,0,0.93268085,True,0.93268085,0.05098691,0.016332243
"Instead of interpolating the two language models, we explicitly used them in the decoder and optimized their weights via minimumerror-rate (MER) training (Och, 2003)",o,0,141,o,0,0.93832505,True,0.93832505,0.049547624,0.012127355
"Liang (2005) uses the discriminative perceptron algorithm (Collins, 2002) to score whole character tag sequences, finding the best candidate by the global score",o,0,142,o,0,0.9177899,True,0.9177899,0.07600184,0.0062082233
"(Turney, 2002) is one of the most famous work that discussed learning polarity from corpus",p,1,143,p,1,0.87650144,True,0.10509288,0.87650144,0.01840564
"Charniak 1996, 1997), while most current stochastic parsing models use a """"markov grammar"""" (e.g. Collins 1999; Charniak 2000)",o,0,144,o,0,0.7925022,True,0.7925022,0.17417467,0.033323072
"However, developing the PDTB may help facilitate the production of more such corpora, through an initial pass of automatic annotation, followed by manual correction, much as was done in developing the PTB (Marcus et al. , 1993).",o,0,145,o,0,0.63385624,True,0.63385624,0.31717044,0.048973303
"For instance, Church and Hanks (1990) calculated SA in terms of mutual information between two words wl and w2: N * f(wl,w2) I(wl, w2) = log2 (1) f(wl)f(w2) here N is the size of the corpus used in the estimation, f(Wl, w2) is the frequency of the cooccurrence, f(wl) and f(w2) that of each word",o,0,146,o,0,0.9669754,True,0.9669754,0.028409036,0.0046156216
"The Collins (1997) model does not use context-free rules, but generates the next category using zeroth order Markov chains (see Section 3.3), hence no information about the previous sisters is included",o,0,147,n,2,0.6370081,False,0.33814725,0.024844632,0.6370081
"Ontologies are formal specifications of a conceptualization (Gruber, 1993) so that it seems straightforward to formalize annotation schemes as ontologies and make use of semantic annotation tools such as OntoMat (Handschuh et al. , 2001) for the purpose of linguistic annotation",o,0,148,o,0,0.93977505,True,0.93977505,0.056727976,0.0034969477
"In training process, we use GIZA++ 4 toolkit for word alignment in both translation directions, and apply grow-diag-final method to refine it (Koehn et al. , 2003)",o,0,149,o,0,0.94614387,True,0.94614387,0.049300134,0.004556055
"By introducing the hidden word alignment variable a  (Brown et al., 1993), the optimal translation can be searched for based on the following criterion: * 1 , arg max( ( , , )) M mm m ea eh = = efa             (1) where  is a string of phrases in the target language, e f  fa    is the source language string of phrases,  he  are feature functions, weights (, , ) m m  are typically optimized to maximize the scoring function (Och, 2003)",o,0,150,o,0,0.95021206,True,0.95021206,0.044093467,0.005694482
"To obtain their corresponding weights, we adapted the minimum-error-rate training algorithm (Och, 2003) to train the outside-layer model",o,0,151,o,0,0.96096694,True,0.96096694,0.035883635,0.0031494785
"Automatic Creation of WIDL-expressions for MT. We generate WIDL-expressions from Chinese strings by exploiting a phrase-based translation table (Koehn et al. , 2003)",o,0,152,o,0,0.96374965,True,0.96374965,0.03268514,0.0035652074
"2 Models, Search Spaces, and Errors A translation model consists of two distinct elements: an unweighted ruleset, and a parameterization (Lopez, 2008a; 2009)",o,0,153,o,0,0.9746361,True,0.9746361,0.021396268,0.003967586
"We use the maximum entropy tagging method described in (Kazama et al. , 2001) for the experiments, which is a variant of (Ratnaparkhi, 1996) modified to use HMM state features",o,0,154,o,0,0.9528008,True,0.9528008,0.042829752,0.004369464
"We obtain aligned parallel sentences and the phrase table after the training of Moses, which includes running GIZA++ (Och and Ney, 2003), grow-diagonal-final symmetrization and phrase extraction (Koehn et al., 2005)",o,0,155,o,0,0.966831,True,0.966831,0.029248383,0.0039204685
"In the multilingual parsing track, participants train dependency parsers using treebanks provided for ten languages: Arabic (Hajic et al. , 2004), Basque (Aduriz et al. 2003), Catalan (Mart et al. , 2007), Chinese (Chen et al. , 2003), Czech (Bhmova et al. , 2003), English (Marcus et al. , 1993; Johansson and Nugues, 2007), Greek (Prokopidis et al. , 2005), Hungarian (Czendes et al. , 2005), Italian (Montemagni et al. , 2003), and Turkish (Oflazer et al. , 2003)",o,0,156,o,0,0.96601105,True,0.96601105,0.03012502,0.0038639535
"More recently, the integration of information sources, and the modeling of more complex language processing tasks in the statistical framework has increased the interest in smoothing methods (Collins ~z Brooks, 1995; Ratnaparkhi, 1996; Magerman, 1994; Ng & Lee, 1996; Collins, 1996)",o,0,157,p,1,0.63024986,False,0.36298394,0.63024986,0.0067661796
"This is important when LARGE CUT-OFF 0 5 100 NAIVE 541,721 184,493 35,617 SASH 10,599 8,796 6,231 INDEX 5,844 13,187 32,663 Table 4: Average number of comparisons per term considering that different tasks may require different weights and measures (Weeds and Weir, 2005)",o,0,158,o,0,0.8060481,True,0.8060481,0.13215922,0.061792627
"Galley (2006) used skip-chain Conditional Random Fields to model pragmatic dependencies between paired meeting utterances (e.g. QUESTION-ANSWER relations), and used a combination of lexical, prosodic, structural and discourse features to rank utterances by importance",o,0,159,o,0,0.96347183,True,0.96347183,0.03271931,0.003808899
"This task is quite common in corpus linguistics and provides the starting point to many other algorithms, e.g., for computing statistics such as pointwise mutual information (Church and Hanks, 1990), for unsupervised sense clustering (Schutze, 1998), and more generally, a large body of work in lexical semantics based on distributional profiles, dating back to Firth (1957) and Harris (1968)",o,0,160,p,1,0.75879943,False,0.2371402,0.75879943,0.004060348
"We used the averaged perceptron algorithm (Freund and Schapire, 1998; Collins, 2002) to train the parameters of the model",o,0,161,o,0,0.9652367,True,0.9652367,0.03166698,0.003096232
everal artificial techniques have been used so that classifiers can be developed and tested without having to invest in manually tagging the data: Yarowsky (1993) and Sch/itze (1995) have acquired training and testing materials by creating pseudowords from existing nonhomographic form,o,0,162,o,0,0.873533,True,0.873533,0.122869164,0.0035979291
"NP chunks in the shared task data are BaseNPs, which are non-recursive NPs, a definition first proposed by Ramshaw and Marcus (1995)",o,0,163,o,0,0.95812255,True,0.95812255,0.037684843,0.0041926587
"Indeed, the result of Collins (2002) that including low support features helps a voted perceptron model but harms a maximum entropy model is undone once the weights of the maximum entropy model are regularized",o,0,164,o,0,0.66873026,True,0.66873026,0.14339253,0.18787718
"We believe that other kinds of translationunit such as n-gram (Jos et al., 2006),factoredphrasaltranslation(Koehn and Hoang, 2007), or treelet (Quirk et al., 2005) can be used in this method",o,0,165,o,0,0.91562724,True,0.91562724,0.07660423,0.0077685076
"Though this model uses trees in the formal sense, it does not create Penn Treebank (Marcus et al., 1993) style linguistic trees, but uses only one non-terminal label (X) to create those trees using six simple rule structures",o,0,166,o,0,0.8639827,True,0.8639827,0.025962934,0.11005446
ther insights borrowed from the current state of the art include minimum-error-rate training of log-linear models (Och and Ney 2002; Och 2003) and use of an m-gram language mode,p,1,167,p,1,0.5437656,True,0.4472894,0.5437656,0.008945014
"The approach is able to achieve 94% precision and recall for base NPs derived from the Penn Treebank Wall Street Journal (Marcus et al. , 1993)",o,0,168,o,0,0.7259962,True,0.7259962,0.21766451,0.05633931
"In this paper we use the so-called Model 4 from (Brown et al. , 1993)",o,0,169,o,0,0.8949584,True,0.8949584,0.098999724,0.0060419715
"The former is a task of identifying positive and negative sentiments from a text which can be a passage, a sentence, a phrase and even a word (Somasundaran et al., 2008; Pang et al., 2002; Dave et al., 2003; Kim and Hovy, 2004; Takamura et al., 2005)",o,0,170,o,0,0.9613962,True,0.9613962,0.034246292,0.0043575163
"For comparison purposes, we revisit a fullygenerative Bayesian model for unsupervised coreference resolution recently introduced by Haghighi and Klein (2007), discuss its potential weaknesses and consequently propose three modifications to their model (Section 3)",n,2,171,o,0,0.6048308,False,0.6048308,0.14143266,0.25373653
"We extracted tagged sentences from the parse trees.5 We split the data into training, development, and test sets as in (Collins, 2002)",o,0,172,o,0,0.96771884,True,0.96771884,0.029415844,0.0028653082
"For instance, Kazama and Torisawa (2007) used the hyponymy relations extracted from Wikipedia for the English NER, and reported improved accuracies with such a gazetteer",p,1,173,o,0,0.77246886,False,0.77246886,0.21534641,0.012184658
"Like (Church and Hanks, 1990), we used mutual information to measure the cohesion between two words",o,0,174,o,0,0.96611416,True,0.96611416,0.029898794,0.003987034
"Moses used the development data for minimum error-rate training (Och, 2003) of its small number of parameters",o,0,175,o,0,0.93904,True,0.93904,0.05364895,0.007311068
arpuat and Wu (2007) approached the issue as a Word Sense Disambiguation proble,o,0,176,o,0,0.9455267,True,0.9455267,0.04903997,0.0054333857
"The upper envelope is a convex hull and can be inscribed with a convex polygon whose edges are the segments of a piecewise linear function in  (Papineni, 1999; Och, 2003): EnvD4fD5 AG max eC8C AWa D4e,fD5 A0  A4 bD4e,fD5 :  C8 RB4 (6) 726 Score  Error count  0 0 e1 e2 e5 e6 e8 e1e 2 e3 e4 e5e6e 7 e8 Figure 1: The upper envelope (bold, red curve) for a set of lines is the convex hull which consists of the topmost line segments",o,0,177,o,0,0.9656572,True,0.9656572,0.028750315,0.0055925855
"et al. , 1994; Brill and Resnik, 1994; Collins and Brooks, 1995; Merlo et al. , 1997)",o,0,178,o,0,0.96128714,True,0.96128714,0.03303024,0.005682628
"More specifically, the work on optimizing preference factors and semantic collocations was done as part of a project on spoken language translation in which the CLE was used for analysis and generation of both English and Swedish (AgnSs et al. 1993)",o,0,179,o,0,0.92943734,True,0.92943734,0.06570436,0.0048582247
"Among these methods, CRFs is the most common technique used in NLP and has been successfully applied to Part-of-Speech Tagging (Lafferty et al. , 2001), Named-Entity Recognition (Collins, 2002) and shallow parsing (Sha and Pereira, 2003; McCallum, 2003)",o,0,180,p,1,0.9289471,False,0.06689956,0.9289471,0.0041532684
"3 Statistical Word Alignment According to the IBM models (Brown et al. , 1993), the statistical word alignment model can be generally represented as in equation (1)",o,0,181,o,0,0.947567,True,0.947567,0.04603595,0.0063971383
"Ramshaw and Marcus(1995) used transformation-based learning, an error-driven learning technique introduced by Eric Bn11(1993), to locate chunks in the tagged corpus",o,0,182,o,0,0.95445365,True,0.95445365,0.042502664,0.0030437557
"6 Concluding remarks Our work presents a set of improvements on previous state of the art of Grammar Association: first, by providing better language models to the original system described in (Vidal et al. , 1993); second, by setting the technique into a rigorous statistical framework, clarifying which kind of probabilities have to be estimated by association models; third, by developing a novel and especially adequate association model: Loco C. On the other hand, though experimental results are quite good, we find them particularly relevant for pointing out directions to follow for further improvement of the Grammar Association technique",o,0,183,p,1,0.51081496,False,0.3519358,0.51081496,0.13724922
"Mean number of instances of paraphrase phenomena per sentence (such as Multiple Sequence Alignment, as employed by Barzilay & Lee 2003)",o,0,184,o,0,0.94746804,True,0.94746804,0.04418943,0.00834257
"a65 The rest of the factors denote distorsion probabilities (d), which capture the probability that words change their position when translated from one language into another; the probability of some French words being generated from an invisible English NULL element (pa6 ), etc. See (Brown et al. , 1993) or (Germann et al. , 2001) for a detailed discussion of this translation model and a description of its parameters",o,0,185,o,0,0.93621427,True,0.93621427,0.05098054,0.01280521
"While the NASA researchers have applied a heuristic method for labeling a report with shapers (Posse 1http://kdd.ics.uci.edu/databases/20newsgroups/ 2Of course, the fact that sentiment classification requires a deeper understanding of a text also makes it more difficult than topic-based text classification (Pang et al., 2002)",o,0,186,n,2,0.8225901,False,0.13372892,0.04368091,0.8225901
"We set all weights by optimizing Bleu (Papineni et al., 2002) using minimum error rate training (MERT) (Och, 2003) on a separate development set of 2,000 sentences (Indonesian or Spanish), and we used them in a beam search decoder (Koehn et al., 2007) to translate 2,000 test sentences (Indonesian or Spanish) into English",o,0,187,o,0,0.96393424,True,0.96393424,0.03270936,0.0033563927
"Wu (1995, 1997) investigated the use of concurrent parsing of parallel corpora in a transduction inversion framework, helping to resolve attachment ambiguities in one language by the coupled parsing state in the second language",p,1,188,o,0,0.9082434,False,0.9082434,0.08737453,0.0043821
"A few exceptions are the hierarchical (possibly syntaxbased) transduction models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Chiang, 2005) and the string transduction models (Kanthak et al. , 2005)",o,0,189,o,0,0.9269047,True,0.9269047,0.068552695,0.0045425626
"Dubey et al. proposed an unlexicalized PCFG parser that modied PCFG probabilities to condition the existence of syntactic parallelism (Dubey et al. , 2006)",o,0,190,o,0,0.9664206,True,0.9664206,0.029371,0.0042083715
"4.5 Consistency of Annotations In order to assess the consistency of annotation, we follow Carletta (1996) in using Cohen's ~, a chancecorrected measure of inter-rater agreement",o,0,191,o,0,0.9548044,True,0.9548044,0.038929556,0.006266007
"The focus of much of the automatic sentiment analysis research is on identifying the affect bearing words (words with emotional content) and on measurement approaches for sentiment (Turney & Littman, 2003; Pang & Lee, 2004; Wilson et al. , 2005)",o,0,192,o,0,0.93421793,True,0.93421793,0.06213196,0.0036502215
"1 Introduction A hypergraph, as demonstrated by Huang and Chiang (2007), is a compact data-structure that can encode an exponential number of hypotheses generated by a regular phrase-based machine translation (MT) system (e.g., Koehn et al",p,1,193,o,0,0.91893435,False,0.91893435,0.076768376,0.0042972714
"We build sentencespecific zero-cutoff stupid-backoff (Brants et al., 2007) 5-gram language models, estimated using 4.7B words of English newswire text, and apply them to rescore either 10000-best lists generated by HCP or word lattices generated by HiFST",o,0,194,o,0,0.9635579,True,0.9635579,0.032066137,0.004375852
"(Blitzer et al., 2006; Jiang and Zhai, 2007; Daume III, 2007; Finkel and Manning, 2009), or [S+T-], where no labeled target domain data is available, e.g",o,0,195,o,0,0.8219025,True,0.8219025,0.030918304,0.14717923
"Words appearing in similax grammatical contexts are assumed to be similar, and therefore classified into the same class (Lin, 1998; Grefenstette, 1994; Grefenstette, 1992; Ruge, 1992; Hindle, 1990)",o,0,196,o,0,0.9623724,True,0.9623724,0.03374032,0.0038871753
"For instance, Pang and Lee (2004) train an independent subjectivity classifier to identify and remove objective sentences from a review prior to polarity classification",o,0,197,o,0,0.96516424,True,0.96516424,0.030077953,0.004757861
"The averaged version of the perceptron (Collins, 2002), like the voted perceptron (Freund and Schapire, 1999), reduces the effect of over-training",p,1,198,o,0,0.72227174,False,0.72227174,0.20130345,0.07642483
urran (2002) and Lin (1998) use syntactic features in the vector definitio,o,0,199,o,0,0.9651239,True,0.9651239,0.031097794,0.003778351
"For example, in the context of syntactic disambiguation, Black (1993) and Magerman (1995) proposed statistical parsing models based-on decisiontree learning techniques, which incorporated not only syntactic but also lexical/semantic information in the decision-trees",o,0,200,o,0,0.95493996,True,0.95493996,0.040790543,0.0042694807
"(2) We note that these posterior probabilities can be computed efficiently for some alignment models such as the HMM (Vogel et al. , 1996; Och and Ney, 2003), Models 1 and 2 (Brown et al. , 1993)",p,1,201,o,0,0.6592415,False,0.6592415,0.27886793,0.061890535
"Second, instead of disambiguating phrase senses as in (Carpuat and Wu, 2007), we model word selection independently of the phrases used in the MT models",o,0,202,o,0,0.9445733,True,0.9445733,0.026496239,0.028930414
"Successflfl examples of reuse of data resources include: the WordNet thesaurus (Miller el; al. , 1993); the Penn Tree Bank (Marcus et al. , 1993); the Longmans Dictionary of Contemporary English (Summers, 1995)",p,1,203,o,0,0.8611829,False,0.8611829,0.12925957,0.0095575405
"354 supervised induction techniques that have been successfully developed for English (e.g., Schutze (1995), Clark (2003)), including the recentlyproposed prototype-driven approach (Haghighi and Klein, 2006) and Bayesian approach (Goldwater and Griffiths, 2007)",o,0,204,p,1,0.8771683,False,0.11842235,0.8771683,0.0044093626
"Therefore, estimating a natural language model based on the maximum entropy (ME) method (Pietra et al. , 1995; Berger et al. , 1996) has been highlighted recently",o,0,205,o,0,0.76085997,True,0.76085997,0.23001863,0.009121382
"Many traditional clustering techniques [Brown et al. , 1992] attempt to maximize the average mutual information of adjacent clusters  = 21, 2 12 2121 )( )|( log)(),( WW WP WWP WWPWWI, (2) where the same clusters are used for both predicted and conditional words",o,0,206,o,0,0.897552,True,0.897552,0.07815246,0.02429562
"GIZA++ refined alignments have been used in state-of-the-art phrase-based statistical MT systems such as (Och, 2004); variations on the refined heuristic have been used by (Koehn et al., 2003) (diag and diag-and) and by the phrase-based system Moses (grow-diag-final) (Koehn et al., 2007)",o,0,207,p,1,0.61929554,False,0.37562174,0.61929554,0.0050827283
"and Gildea, 2007; Zhang et al., 2006; Gildea, Satta, and Zhang, 2006)",o,0,208,o,0,0.96397424,True,0.96397424,0.02692846,0.009097309
"(2008)], and distributional methods [e.g., Bergsma et al",o,0,209,o,0,0.96859956,True,0.96859956,0.024660356,0.0067401202
"9.1 Training Methodology Given a training set, we first run a variant of IBM alignment model 1 (Brown et al., 1993) for 100 iterations, and then initialize Model I with the learned parameter values",o,0,210,o,0,0.95742965,True,0.95742965,0.038822155,0.003748229
"In this method, the decision list (DL) learning algorithm (Yarowsky, 1995) is used",o,0,211,o,0,0.95044106,True,0.95044106,0.04400595,0.005553054
"This was used, for example, by (Thelen and Riloff, 2002; Collins and Singer, 1999) in information extraction, and by (Smith and Eisner, 2005) in POS tagging",o,0,212,o,0,0.96000576,True,0.96000576,0.03697439,0.0030198905
"For the mean field approximation, propagating the error all the way back through the structure of the graphical model requires a more complicated calculation, but it can still be done efficiently (see (Titov and Henderson, 2007) for details)",p,1,213,o,0,0.40579933,False,0.40579933,0.20622729,0.38797343
"The features used by the POS tagger, some of which are different to those from Collins (2002) and are specific to Chinese, are shown in Table 2",o,0,214,o,0,0.9270754,True,0.9270754,0.043871004,0.029053655
"Collins and Roark (2004) used the averaged perceptron (Collins, 2002a)",o,0,215,o,0,0.9635606,True,0.9635606,0.029118327,0.007321041
"Using Maximum Entropy (Berger, et al. 1996) classifiers I built a parser that achieves a throughput of over 200 sentences per second, with a small loss in accuracy of about 23 %",o,0,216,o,0,0.81292707,True,0.81292707,0.16808496,0.018987969
"Barzilay and Lee (2003) proposed to apply multiple-sequence alignment (MSA) for traditional, sentence-level PR",o,0,217,o,0,0.9673798,True,0.9673798,0.02814472,0.0044754846
"For details please refer to (Wu 1995, Wu 1997)",o,0,218,o,0,0.9585758,True,0.9585758,0.03696779,0.0044564605
"This is in contrast to work by researchers such as Schiitze and Pedersen (1992), Brown et al (1992) and Futrelle and Gauch (1995), where it is often the most frequent words in the lexicon which are clustered, predominantly with the purpose of determining their grammatical classes",o,0,219,o,0,0.6969547,True,0.6969547,0.21952079,0.08352437
"For efficiency reasons we report results on sentences of length 30 words or less.10 The syntax-based method gives a BLEU (Papineni et al., 2002) score of 25.04, a 0.46 BLEU point gain over Pharoah",o,0,220,o,0,0.5634996,True,0.5634996,0.12975666,0.30674365
"The first is to align the words using a standard word alignement technique, such as the Refined Method described in (Och and Ney, 2003) (the intersection of two IBM Viterbi alignments, forward and reverse, enriched with alignments from the union) and then generate bi-phrases by combining together individual alignments that co-occur in the same pair of sentences",o,0,221,o,0,0.95590127,True,0.95590127,0.040115237,0.0039835996
"3 MaxEnt Model and Features 3.1 MaxEnt Model for NOR The principle of maximum entropy (MaxEnt) model is that given a collection of facts, choose a model consistent with all the facts, but otherwise as uniform as possible (Berger et al., 1996)",o,0,222,o,0,0.95285124,True,0.95285124,0.039103873,0.008044952
"2.2 Co-occurrence-based approaches The second class of algorithms uses cooccurrence statistics (Hindle 1990, Lin 1998)",o,0,223,o,0,0.96430755,True,0.96430755,0.032962568,0.002729785
"3.1 A History-Based Model The history-based (HB) approach which incorporates more context information has worked well in parsing (Collins, 1997; Charniak, 2000)",p,1,224,p,1,0.907128,True,0.07020683,0.907128,0.022665193
"1 Introduction Most recent approaches in SMT, eg (Koehn et al., 2003; Chiang, 2005), use a log-linear model to combine probabilistic features",o,0,225,o,0,0.509623,True,0.509623,0.48533678,0.005040273
"5We use deterministic sampling, which is useful for reproducibility and for minimum error rate training (Och, 2003)",o,0,226,o,0,0.8942954,True,0.8942954,0.102566235,0.003138335
"2 Related Work The Yarowsky algorithm (Yarowsky, 1995), originally proposed for word sense disambiguation, makes the assumption that it is very unlikely for two occurrences of a word in the same discourse to have different senses",o,0,227,o,0,0.91462994,True,0.91462994,0.06876466,0.01660544
"2.2 Closed Challenge Setting The organization provided training, development and test sets derived from the standard sections of the Penn TreeBank (Marcus et al. , 1993) and PropBank (Palmer et al. , 2005) corpora",o,0,228,o,0,0.96212435,True,0.96212435,0.034210578,0.0036650104
"Decoding with an SCFG (e.g. , translating from Chinese to English using the above grammar) can be cast as a parsing problem (see Section 3 for details), in which case we need to binarize a synchronous rule with more than two nonterminals to achieve polynomial time algorithms (Zhang et al. , 2006)",o,0,229,o,0,0.934317,True,0.934317,0.057244714,0.008438331
"Recall that the log likelihood of our model is:  d parenleftBigg Lorig(Dd;d) i (d,i ,i)2 2 2d parenrightBigg  i (,i)2 2 2 We now introduce a new variable d = d , and plug it into the equation for log likelihood:  d parenleftBigg Lorig(Dd;d +) i (d,i)2 2 2d parenrightBigg  i (,i)2 2 2 The result is the model of (Daume III, 2007), where the d are the domain-specific feature weights, and d are the domain-independent feature weights",o,0,230,o,0,0.9604552,True,0.9604552,0.034553785,0.004991027
im and Hovy (2007) predict the results of an election by analyzing forums discussing the election,o,0,231,o,0,0.95651174,True,0.95651174,0.039736208,0.0037519566
"In addition, Wu (1997) used a stochastic inversion transduction grammar to simultaneously parse the sentence pairs to get the word or phrase alignments",o,0,232,o,0,0.9565493,True,0.9565493,0.03960218,0.0038485916
"We annotated with the BIO tagging scheme used in syntactic chunkers (Ramshaw and Marcus, 1995)",o,0,233,o,0,0.9711699,True,0.9711699,0.02505393,0.0037761189
"Both left-corner strategy (Ratnaparkhi, 1997; Roark, 2001; Prolo, 2003; Henderson, 2003; Collins and Roark, 2004) and head-corner strategy (Henderson, 2000; Yamada and Matsumoto, 2003) were employed in incremental parsing",o,0,234,o,0,0.96629214,True,0.96629214,0.027744876,0.005963011
"We use only the words that are content words (nouns, verbs, or adjectives) and not in the stopword list used in ROUGE (Lin, 2004)",o,0,235,o,0,0.94619393,True,0.94619393,0.025289195,0.028516829
"Since then, supervised learning from sense-tagged corpora has since been used by several researchers: Zernik (1990, 1991), Hearst (1991), Leacock, Towell, and Voorhees (1993), Gale, Church, and Yarowsky (1992d, 1993), Bruce and Wiebe (1994), Miller et al",o,0,236,o,0,0.7937338,True,0.7937338,0.20245895,0.0038072392
"2 Syntactic-oriented evaluation metrics We investigated the following metrics oriented on the syntactic structure of a translation output:  POSBLEU The standard BLEU score (Papineni et al., 2002) calculated on POS tags instead of words;  POSP POS n-gram precision: percentage of POS ngrams in the hypothesis which have a counterpart in the reference;  POSR Recall measure based on POS n-grams: percentage of POS n-grams in the reference which are also present in the hypothesis;  POSF POS n-gram based F-measure: takes into account all POS n-grams which have a counter29 part, both in the reference and in the hypothesis",o,0,237,o,0,0.9685725,True,0.9685725,0.02619886,0.0052286005
"Some methods which can offer powerful reordering policies have been proposed like syntax based machine translation (Yamada and Knight, 2001) and Inversion Transduction Grammar (Wu, 1997)",p,1,238,p,1,0.91641587,True,0.07609213,0.91641587,0.0074919537
his upper bound is consistent with the upper limit of 50% found by Daume III and Marcu (2005) which takes into account stemming difference,o,0,239,o,0,0.90291715,True,0.90291715,0.042044826,0.05503797
"For example, Church and Hanks (1990) describe the use of the mutual information index for this purpose (cf",o,0,240,o,0,0.964911,True,0.964911,0.028581187,0.006507871
"On the other hand, according to the data-driven approach, a frequency-based language model is acquired from corpora and has the forms of ngrams (Church, 1988; Cutting et al. , 1992), rules (Hindle, 1989; Brill, 1995), decision trees (Cardie, 1994; Daelemans et al. , 1996) or neural networks (Schmid, 1994)",o,0,241,o,0,0.96435344,True,0.96435344,0.031101428,0.0045450376
.1 Candidate NPs Noun phrases were extracted using Ramshaw and Marcus's base NP chunker [Ramshaw and Marcus (1995),o,0,242,o,0,0.9648565,True,0.9648565,0.03143933,0.0037042447
"The BLEU metric (Papineni et al. , 2002) in MT has been particularly successful; for example MT05, the 2005 NIST MT evaluation exercise, used BLEU-4 as the only method of evaluation",p,1,243,p,1,0.9078124,True,0.07824067,0.9078124,0.01394689
ee Yarowsky (1995) for detail,o,0,244,o,0,0.9576736,True,0.9576736,0.038119335,0.004207096
"(Mann and Yarowsky, 2003; Chen and Martin, 2007; Baron and Freedman, 2008)",o,0,245,o,0,0.96528304,True,0.96528304,0.028725147,0.0059917895
ne approach constructs automatic thesauri by computing the similarity between words based on their distribution in a corpus (Hindle 1990; Lin 1998,o,0,246,o,0,0.9633895,True,0.9633895,0.033428352,0.003182182
 Related Work One of the first works that use statistical methods to detect implicit discourse relations is that of Marcu and Echihabi (2002,o,0,247,p,1,0.7127242,False,0.2791068,0.7127242,0.008168984
"1993; Chang et al. , 1992; Collins and Brooks, 1995; Fujisaki, 1989; Hindle and Rooth, 1991; Hindle and Rooth, 1993; Jelinek et al. , 1990; Magerman and Marcus, 1991; Magerman, 1995; Ratnaparkhi et al. , 1994; Resnik, 1993; Su and Chang, 1988)",o,0,248,o,0,0.95486736,True,0.95486736,0.02692925,0.018203456
"2 Discriminative Reordering Model Basic reordering models in phrase-based systems use linear distance as the cost for phrase movements (Koehn et al., 2003)",o,0,249,o,0,0.9608254,True,0.9608254,0.034707695,0.004466919
"We tuned Pharaohs four parameters using minimum error rate training (Och, 2003) on DEV.12 We obtained an increase of 0.8 9As in the POS features, we map each phrase pair to its majority constellation",o,0,250,o,0,0.9482566,True,0.9482566,0.045987982,0.005755368
"Specifically, aspect rating as an interesting topic has also been widely studied (Titov and McDonald, 2008a; Snyder and Barzilay, 2007; Goldberg and Zhu, 2006)",o,0,251,p,1,0.52451986,False,0.4674297,0.52451986,0.00805043
" Statistical Phrase-based Translation (Koehn et al. , 2003): Here phrase-based means subsequence-based, as there is no guarantee that the phrases learned by the model will have any relation to what we would think of as syntactic phrases",o,0,252,o,0,0.9222494,True,0.9222494,0.04221735,0.03553322
"7 Independently, Cutting et aL (1992) quote a performance of 800 words per second for their part-of-speech tagger based on hidden Markov models",o,0,253,o,0,0.93512374,True,0.93512374,0.0543552,0.01052101
"Although grammatical function and empty nodes annotation expressing long-distance dependencies are provided in Treebanks such as the Penn Treebank (Marcus et al. , 1993), most statistical Treebank trained parsers fully or largely ignore them 1, which entails two problems: first, the training cannot profit from valuable annotation data",o,0,254,n,2,0.79087186,False,0.16116646,0.04796164,0.79087186
"With these linguistic annotations, we expect the LABTG to address two traditional issues of standard phrase-based SMT (Koehn et al., 2003) in a more effective manner",n,2,255,o,0,0.49864262,False,0.49864262,0.4321718,0.06918555
"P (d)  P L (d) (4) Statistical approaches to language modeling have been used in much NLP research, such as machine translation (Brown et al. , 1993) and speech recognition (Bahl et al. , 1983)",o,0,256,o,0,0.82634944,True,0.82634944,0.17152897,0.0021216073
"They are not used in LN, but they are known to be useful for WSD (Tanaka et al., 2007; Magnini et al., 2002)",o,0,257,o,0,0.8610345,True,0.8610345,0.08522275,0.05374275
"We evaluate the string chosen by the log-linear model against the original treebank string in terms of exact match and BLEU score (Papineni et al., 821 Syntactic feature Type Definites Definite descriptions SIMPLE DEF simple definite descriptions POSS DEF simple definite descriptions with a possessive determiner (pronoun or possibly genitive name) DEF ATTR ADJ definite descriptions with adjectival modifier DEF GENARG definite descriptions with a genitive argument DEF PPADJ definite descriptions with a PP adjunct DEF RELARG definite descriptions including a relative clause DEF APP definite descriptions including a title or job description as well as a proper name (e.g. an apposition) Names PROPER combinations of position/title and proper name (without article) BARE PROPER bare proper names Demonstrative descriptions SIMPLE DEMON simple demonstrative descriptions MOD DEMON adjectivally modified demonstrative descriptions Pronouns PERS PRON personal pronouns EXPL PRON expletive pronoun REFL PRON reflexive pronoun DEMON PRON demonstrative pronouns (not: determiners) GENERIC PRON generic pronoun (man  one) DA PRON da-pronouns (darauf, daruber, dazu, ) LOC ADV location-referring pronouns TEMP ADV,YEAR Dates and times Indefinites SIMPLE INDEF simple indefinites NEG INDEF negative indefinites INDEF ATTR indefinites with adjectival modifiers INDEF CONTRAST indefinites with contrastive modifiers (einige  some, andere  other, weitere  further, ) INDEF PPADJ indefinites with PP adjuncts INDEF REL indefinites with relative clause adjunct INDEF GEN indefinites with genitive adjuncts INDEF NUM measure/number phrases INDEF QUANT quantified indefinites Table 5: An inventory of interesting syntactic characteristics in IS phrases Label 1 (+ features) Label 2 (+ features) B/A Total D-GIVEN-PRONOUN INDEF-REL 0 19 PERS PRON 39 INDEF ATTR 23 DA PRON 25 SIMPLE INDEF 17 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-PRONOUN D-GIVEN-CATAPHOR 0.1 11 PERS PRON 39 SIMPLE DEF 13 DA PRON 25 DA PRON 10 DEMON PRON 19 GENERIC PRON 11 D-GIVEN-REFLEXIVE NEW 0.11 31 REFL PRON 54 SIMPLE INDEF 113 INDEF ATTR 53 INDEF NUM 32 INDEF PPADJ 26 INDEF GEN 25  Table 6: IS asymmetric pairs augmented with syntactic characteristics 822 2002)",o,0,258,o,0,0.9726394,True,0.9726394,0.024039444,0.003321199
"A variety of approaches have been investigated for speech summarization, for example, maximum entropy, conditional random fields, latent semantic analysis, support vector machines, maximum marginal relevance (Maskey and Hirschberg, 2003; Hori et al., 2003; Buist et al., 2005; Galley, 2006; Murray et al., 2005; Zhang et al., 2007; Xie and Liu, 2008)",o,0,259,o,0,0.9596093,True,0.9596093,0.03668493,0.00370575
"There has been considerable skepticism over whether WSD will actually improve performance of applications, but we are now starting to see improvement in performance due to WSD in cross-lingual information retrieval (Clough and Stevenson, 2004; Vossen et al., 2006) and machine translation (Carpuat and Wu, 2007; Chan et al., 2007) and we hope that other applications such as question-answering, text simplication and summarisation might also benet as WSD methods improve",p,1,260,p,1,0.50183254,True,0.47004893,0.50183254,0.028118579
"The Duluth Word Alignment System is a Perl implementation of IBM Model 2 (Brown et al. , 1993)",o,0,261,o,0,0.95805043,True,0.95805043,0.034845904,0.007103613
"After this conversion, we had 1000 positive and 1000 negative examples for each domain, the same balanced composition as the polarity dataset (Pang et al. , 2002)",o,0,262,o,0,0.9058874,True,0.9058874,0.06303902,0.031073535
"Most systems for automatic role-semantic analysis have used constituent syntax as in the Penn Treebank (Marcus et al., 1993), although there has also been much research on the use of shallow syntax (Carreras and Mrquez, 2004) in SRL",o,0,263,o,0,0.8371075,True,0.8371075,0.15867634,0.004216211
"The results are comparable to other results reported using the Inside/Outside method (Ramshaw and Marcus, 1995) (see Table 7",o,0,264,o,0,0.90742177,True,0.90742177,0.076263726,0.016314473
"Similarly, (Barzilay and Lee, 2003) and (Shinyanma et al. , 2002) learn sentence level paraphrase templates from a corpus of news articles stemming from different news source",o,0,265,o,0,0.96207905,True,0.96207905,0.034464646,0.0034562715
"Among all possible target strings, we will choose the one with the highest probability which is given by Bayes' decision rule (Brown et al 1993):,~ = argmaxP,'(e\]~lfg~)} = argmax {P,'(ef)",o,0,266,o,0,0.94622284,True,0.94622284,0.047224816,0.0065523377
"In the field of eomputationa.1 linguistics, mutual information \[Brown et al. , 1988\], 2 \[Church and Hanks, 1990\], or a likelihood ratio test \[Dunning, 199a\] are suggested",o,0,267,o,0,0.9562267,True,0.9562267,0.04065151,0.0031217248
"Using the log-linear form to model p(e|f) gives us the flexibility to introduce overlapping features that can represent global context while decoding (searching the space of candidate translations) and rescoring (ranking a set of candidate translations before performing the argmax operation), albeit at the cost of the traditional source-channel generative model of translation proposed in (Brown et al. , 1993)",o,0,268,n,2,0.76613736,False,0.17618117,0.05768145,0.76613736
"Given a weight vector w, the score wf(x,y) ranks possible labelings of x, and we denote by Yk,w(x) the set of k top scoring labelings for x. We use the standard B,I,O encoding for named entities (Ramshaw and Marcus, 1995)",o,0,269,o,0,0.93185884,True,0.93185884,0.059659068,0.008482139
"Most previous work on compositionality of MWEs either treat them as collocations (Smadja, 1993), or examine the distributional similarity between the expression and its constituents (McCarthy et al. , 2003; Baldwin et al. , 2003; Bannard et al. , 2003)",o,0,270,o,0,0.9607699,True,0.9607699,0.03151995,0.007710165
"Inspired by the conjunction and appositive structures, Riloff and Shepherd (1997), Roark and Charniak (1998) used cooccurrence statistics in local context to discover sibling relations",o,0,271,o,0,0.9612617,True,0.9612617,0.034059376,0.0046788454
"To compare the performance of different taggers learned by different mechanisms, one can measure the precision, recall and F-measure, given by precision = # correct predictions# predicted gene mentions recall = # correct predictions# true gene mentions F-measure = a96a15a14 precision a14 recallprecision a44 recall In our evaluation, we compared the proposed semi-supervised learning approach to the state of the art supervised CRF of McDonald and Pereira (2005), and also to self-training (Celeux and Govaert 1992; Yarowsky 1995), using the same feature set as (McDonald and Pereira 2005)",o,0,272,o,0,0.7175008,True,0.7175008,0.25846958,0.024029678
"However, other types of nonlocal information have also been shown to be effective (Finkel et al. , 2005) and we will examine the effectiveness of other non-local information which can be embedded into label information",o,0,273,p,1,0.7512032,False,0.23305303,0.7512032,0.015743723
"This decomposition applies both to discriminative linear models and to generative models such as HMMs and CRFs, in which case the linear sum corresponds to log likelihood assigned to the input/output pair by the model (for details see (Roth, 1999) for the classi cation case and (Collins, 2002) for the structured case)",o,0,274,o,0,0.9689775,True,0.9689775,0.027243918,0.0037786486
"Note that although the source of the data is the same as in Section 5, as Yarowsky (1995) did",o,0,275,o,0,0.8428326,True,0.8428326,0.02987209,0.1272953
"All features encountered in the training data are ranked in the DL (best evidence first) according to the following loglikelihood ratio (Yarowsky, 1995): Log Pr(reading i jfeature k ) P j6=i Pr(reading j jfeature k ) We estimated probabilities via maximum likelihood, adopting a simple smoothing method (Martinez and Agirre, 2000): 0.1 is added to both the denominator and numerator",o,0,276,o,0,0.9562907,True,0.9562907,0.039994646,0.0037146362
"This alignment representation is a generalization of the baseline alignments described in (Brown et al. , 1993) and allows for many-to-many alignments",o,0,277,o,0,0.9377541,True,0.9377541,0.047754377,0.0144915525
"To tackle this problem, we defined 2The best results of Collins and Roark (2004) (LR=88.4%, LP=89.1% and F=88.8%) are achieved when the parser utilizes the information about the final punctuation and the look-ahead",o,0,278,p,1,0.593233,False,0.39210308,0.593233,0.014663947
"POS tagging and phrase chunking in English were done using the trained systems provided with the fnTBL Toolkit (Ngai and Florian, 2001); both were trained from the annotated Penn Treebank corpus (Marcus et al. , 1993)",o,0,279,o,0,0.9591128,True,0.9591128,0.0372479,0.003639295
"Probabilistic models where probabilities are assigned to the CFG backbone of the unification-based grammar have been developed (Kasper et al. , 1996; Briscoe and Carroll, 1993; Kiefer et al. , 2002), and the most probable parse is found by PCFG parsing",o,0,280,o,0,0.94512,True,0.94512,0.051040053,0.0038399238
"3.1 Generation using PHARAOH PHARAOH (Koehn et al. , 2003) is an SMT system that uses phrases as basic translation units",o,0,281,o,0,0.96287286,True,0.96287286,0.0344489,0.002678229
"For this reason, name classification has been studied in solving the named entity extraction task in the NLP and information extraction communities (see, for example, (Collins and Singer, 1999; Cucerzan and Yarowsky, 1999) and various approaches reported in the MUC conferences (MUC-6, 1995))",o,0,282,o,0,0.88082385,True,0.88082385,0.11447201,0.004704106
"The K&M model creates a packed parse forest of all possible compressions that are grammatical with respect to the Penn Treebank (Marcus et al. , 1993)",o,0,283,o,0,0.9568654,True,0.9568654,0.034305084,0.008829653
"Furthermore, Bikel (2004) provides evidence that lexical information (in the form of bi-lexical dependencies) only makes a small contribution to the performance of parsing models such as Collinss (1997)",o,0,284,n,2,0.42010316,False,0.35497355,0.22492334,0.42010316
"(Farach et al. , 1995; Wyner, in press) describe a novel algorithm for entropy estimation for which they claim very fast convergence time; using no more than about five pages of text, they can achieve nearly the same accuracy as (Brown et al. , 1992)",o,0,285,o,0,0.5336444,True,0.5336444,0.35323444,0.113121234
"We used minimum error rate training (Och, 2003) and the A* beam search decoder implemented by Koehn (Koehn et al., 2003)",o,0,286,o,0,0.9668063,True,0.9668063,0.029250313,0.0039434065
"(Wu, 1997; Yamada and Knight, 2001; Gildea, 2003; Melamed, 2004; Graehl and Knight, 2004; Galley et al. , 2006)",o,0,287,o,0,0.96594363,True,0.96594363,0.02631982,0.007736559
"The model weights of the transducer are tuned based on the development set using a grid-based line search, and the translation results are evaluated based on a single Chinese reference6 using BLEU-4 (Papineni et al., 2002)",o,0,288,o,0,0.97138065,True,0.97138065,0.024326945,0.004292389
"This similarity score is computed as a max over a number of component scoring functions, some based on external lexical resources, including:  various string similarity functions, of which most are applied to word lemmas  measures of synonymy, hypernymy, antonymy, and semantic relatedness, including a widelyused measure due to Jiang and Conrath (1997), based on manually constructed lexical resources such as WordNet and NomBank  a function based on the well-known distributional similarity metric of Lin (1998), which automatically infers similarity of words and phrases from their distributions in a very large corpus of English text The ability to leverage external lexical resources both manually and automatically constructedis critical to the success of MANLI",p,1,289,p,1,0.86857045,True,0.12343033,0.86857045,0.007999257
"This formulation is similar to the energy minimization framework, which is commonly used in image analysis (Besag, 1986; Boykov et al. , 1999) and has been recently applied in natural language processing (Pang and Lee, 2004)",o,0,290,o,0,0.772063,True,0.772063,0.22490267,0.0030343696
"7.1.3 Similarity via pagerank Pagerank (Page et al., 1998) is the celebrated citation ranking algorithm that has been applied to several natural language problems from summarization (Erkan and Radev, 2004) to opinion mining (Esuli and Sebastiani, 2007) to our task of lexical relatedness (Hughes and Ramage, 2007)",o,0,291,p,1,0.87904817,False,0.11598363,0.87904817,0.0049682045
"(Elhadad et al., 2001; Clarke and Lapata, 2007; Madnani et al., 2007))",o,0,292,o,0,0.97181064,True,0.97181064,0.022157038,0.006032308
"The class labeling system in our experiment is IOB2 (Sang, 2000), which is a variation of IOB (Ramshaw and Marcus, 1995)",o,0,293,o,0,0.97361743,True,0.97361743,0.0208584,0.005524228
"The main reason behind this lies in the difference between the two corpora used: Penn Treebank (Marcus et al. , 1993) and EDR corpus (EDR, 1995)",o,0,294,o,0,0.6247858,True,0.6247858,0.33507752,0.040136717
"While Galley (2004) describes extracting treeto-string rules from 1-best trees, Mi and Huang et al",o,0,295,o,0,0.9526883,True,0.9526883,0.04078512,0.0065266206
"The HWC metrics compare dependency and constituency trees for both reference and machine translations (Liu and Gildea, 2005)",o,0,296,o,0,0.964139,True,0.964139,0.02873316,0.0071278447
"The first constraints are based on inversion transduction grammars (ITG) (Wu, 1995; Wu, 1997)",o,0,297,o,0,0.96864355,True,0.96864355,0.02858207,0.0027743818
"Distortion models were first proposed by (Brown et al. , 1993) in the so-called IBM Models",o,0,298,o,0,0.7820288,True,0.7820288,0.21421275,0.0037584284
"optimization approaches which aim at selecting those examples that optimize some (algorithm-dependent) objective function, such as prediction variance (Cohn et al. , 1996), and heuristic methods with uncertainty sampling (Lewis and Catlett, 1994) and query-by-committee (QBC) (Seung et al. , 1992) just to name the most prominent ones",o,0,299,o,0,0.879516,True,0.879516,0.11644268,0.004041271
"(Ramshaw and Marcus, 1995) shows that baseNP recognition (Fz=I =92.0) is easier than finding both NP and VP chunks (Fz=1=88.1) and that increasing the size of the training data increases the performance on the test set",p,1,300,n,2,0.4917099,False,0.35201028,0.1562799,0.4917099
"The unlabeled data for English we use is the union of the Penn Treebank tagged WSJ data (Marcus et al., 1993) and the BLLIP corpus.5 For the rest of the languages we use only the text of George Orwells novel 1984, which is provided in morphologically disambiguated form as part of MultextEast (but we dont use the annotations)",o,0,301,o,0,0.9256896,True,0.9256896,0.05853792,0.015772587
"a22 a14 is the sufficient statistic of a16 a14 . Then, we can rewrite a2a24a3 a10a27 a42a7 a25 as: a5a7a6a9a8a11a10 a23 a3 a10 a7 a15 a27 a25a18a17a26a25 a12a28a27 a5a7a6a29a8a30a10 a23 a3 a10 a7 a15 a27 a25a18a17 . 3 Loss Functions for Label Sequences Given the theoretical advantages of discriminative models over generative models and the empirical support by (Klein and Manning, 2002), and that CRFs are the state-of-the-art among discriminative models for label sequences, we chose CRFs as our model, and trained by optimizing various objective functions a31 a3 a10a36 a25 with respect to the corpus a36 . The application of these models to the label sequence problems vary widely",o,0,302,o,0,0.59242797,True,0.59242797,0.37583536,0.031736627
"Normally, one would eliminate the redundant structures produced by the grammar in (1) by replacing it with the canonical form grammar (Wu, 1997), which has the following form: S  A | B | C A  [AB] | [BB] | [CB] | [AC] | [BC] | [CC] B  AA |BA|CA| AC |BC|CC C  e/f (2) By design, this grammar allows only one struc147 a0 a1 a2 a0 a3 a4 a2 a5 a1 a6 a7 a8 a6 a8 a9 a8 a2 a8 a10 a8 a1 a2 a3 a6 a8 a4 a7 a8 a6 a8 a9 a8 a8 a11 a12 a11 a0 a1 a2 a0 a3 a4 a2 a5 a1 a6 a7 a8 a6 a8 a9 a8 a0 a1 a2 a0 a3 a4 a2 a5 a1 a6 a7 a8 a6 a8 a9 a8 a0 a1 a2 a0 a3 a4 a2 a5 a1 a6 a7 a8 a6 a8 a9 a8 a13 a11 Figure 3: An example of how dependency trees interact with ITGs",o,0,303,o,0,0.9518144,True,0.9518144,0.036227386,0.011958196
"Furthermore, use of the self-training techniques described in (McClosky et al. , 2006) raise this to 87.8% (an error reduction of 28%) again without any use of labeled Brown data",p,1,304,o,0,0.7348104,False,0.7348104,0.11118381,0.15400583
olan (1994) described a heuristic approach to forming unlabeled clusters of closely related senses in a MR,o,0,305,o,0,0.9481581,True,0.9481581,0.048859317,0.002982621
"Predicate argument structures, which consist of complements (case filler nouns and case markers) and verbs, have also been used in the task of noun classification (Hindle 1990)",o,0,306,o,0,0.85322434,True,0.85322434,0.14412807,0.0026475424
"In general the training set is the parsed Wall Street Journal (Marcus et al, 1993), with few exceptions, and the size of the training samples is around 10-20,000 test cases",o,0,307,o,0,0.8683674,True,0.8683674,0.107357115,0.02427547
"F-me. 1 CBC-NER system M 71.67 23.47 35.36CBC-NER system A 70.66 32.86 44.86 2 XIP NER 77.77 56.55 65.48 XIP + CBC M 78.41 60.26 68.15 XIP + CBC A 76.31 60.48 67.48 3 Stanford NER 67.94 68.01 67.97 Stanford + CBC M 69.40 71.07 70.23 Stanford + CBC A 70.09 72.93 71.48 4 GATE NER 63.30 56.88 59.92 GATE + CBC M 66.43 61.79 64.03 GATE + CBC A 66.51 63.10 64.76 5 Stanford + XIP 72.85 75.87 74.33 Stanford + XIP + CBC M 72.94 77.70 75.24 Stanford + XIP + CBC A 73.55 78.93 76.15 6 GATE + XIP 69.38 66.04 67.67 GATE + XIP + CBC M 69.62 67.79 68.69 GATE + XIP + CBC A 69.87 69.10 69.48 7 GATE + Stanford 63.12 69.32 66.07 GATE + Stanford + CBC M 65.09 72.05 68.39 GATE + Stanford + CBC A 65.66 73.25 69.25 Table 1: Results given by different hybrid NER systems and coupled with the CBC-NER system corpora (CoNLL, MUC6, MUC7 and ACE): ner-eng-ie.crf-3-all2008-distsim.ser.gz (Finkel et al., 2005) (line 3 in Table 1),  GATE NER or in short GATE (Cunningham et al., 2002) (line 4 in Table 1),  and several hybrid systems which are given by the combination of pairs taken among the set of the three last-mentioned NER systems (lines 5 to 7 in Table 1)",o,0,308,o,0,0.94264394,True,0.94264394,0.031988863,0.025367131
aume III (2007) further augments the feature space on the instances of both domain,o,0,309,o,0,0.8797049,True,0.8797049,0.09608405,0.024211144
n the LFG-based generation algorithm presented by Cahill and van Genabith (2006) complex named entities (i.e. those consisting of more than one word token) and other multi-word units can be fragmented in the surface realizatio,o,0,310,o,0,0.95087546,True,0.95087546,0.045516573,0.0036080389
"6 Related Work The most relevant previous works include word sense translation and translation disambiguation (Li & Li 2003; Cao & Li 2002; Koehn and Knight 2000; Kikui 1999; Fung et al. , 1999), frame semantic induction (Green et al. , 2004; Fung & Chen 2004), and bilingual semantic mapping (Fung & Chen 2004; Huang et al. 2004; Ploux & Ji, 2003, Ngai et al. , 2002; Palmer & Wu 1995)",o,0,311,p,1,0.5773961,False,0.40585238,0.5773961,0.016751528
"In one experiment, it has to be performed on the basis of the gold-standard, assumed-perfect POS taken directly from the training data, the Penn Treebank (Marcus et al. , 1993), so as to abstract from a particular POS tagger and to provide an upper bound",o,0,312,o,0,0.8989932,True,0.8989932,0.08370029,0.017306464
or placing the head the center function center(i) (Brown et al. [1993] uses the notation circledot i ) is used: the average position of the source words with which the target word e i1 is aligne,o,0,313,o,0,0.9671631,True,0.9671631,0.021577103,0.011259837
"3.1 System Tuning Minimum error training (Och, 2003) under BLEU (Papineni et al., 2001) was used to optimise the feature weights of the decoder with respect to the dev2006 development set",o,0,314,o,0,0.9509911,True,0.9509911,0.039603435,0.009405492
"Hanks and Church (1990) proposed using pointwise mutual information to identify collocations in lexicography; however, the method may result in unacceptable collocations for low-count pairs",n,2,315,o,0,0.45587406,False,0.45587406,0.09989805,0.44422787
"1 Introduction The use of various synchronous grammar based formalisms has been a trend for statistical machine translation (SMT) (Wu, 1997; Eisner, 2003; Galley et al., 2006; Chiang, 2007; Zhang et al., 2008)",o,0,316,o,0,0.6964031,True,0.6964031,0.3009853,0.0026116734
"Beyond WordNet (Fellbaum, 1998), a wide range of resources has been developed and utilized, including extensions to WordNet (Moldovan and Rus, 2001; Snow et al., 2006) and resources based on automatic distributional similarity methods (Lin, 1998; Pantel and Lin, 2002)",o,0,317,o,0,0.9139558,True,0.9139558,0.08239562,0.0036486045
"(1993b), this model is symmetric, because both word bags are generated together from a joint probability distribution",o,0,318,o,0,0.9481534,True,0.9481534,0.039240208,0.012606389
"3.2.2 Alignment Error Rate Since MT systems are usually built on the union of the two sets of alignments (Koehn et al., 2003), we consider the union of alignments in the two directions as well as those in each direction",o,0,319,o,0,0.9567146,True,0.9567146,0.035539985,0.0077453973
ean and Riloff (2004) proposed the use of caseframe networks as a kind of contextual role knoweldge for anaphora resolutio,o,0,320,o,0,0.95893776,True,0.95893776,0.037980255,0.0030820402
"1 Introduction Distributional Similarity has been an active research area for more than a decade (Hindle, 1990), (Ruge, 1992), (Grefenstette, 1994), (Lee, 1997), (Lin, 1998), (Dagan et al. , 1999), (Weeds and Weir, 2003)",o,0,321,o,0,0.6227146,True,0.6227146,0.36786684,0.009418558
"We further note that our results are different from that of (Hughes and Ramage, 2007) as they use extensive feature engineering and weight tuning during the graph generation process that we have not been able to reproduce",o,0,322,n,2,0.7532809,False,0.21751127,0.029207869,0.7532809
"Minimum error rate training was used to tune the model feature weights (Och, 2003)",o,0,323,o,0,0.9616731,True,0.9616731,0.03341669,0.004910279
"32 7.3 Unknown Words and Parts of Speech When the parser encounters an unknown word, the first-best tag delivered by Ratnaparkhis (1996) tagger is used",o,0,324,o,0,0.6159433,True,0.6159433,0.36386675,0.020189974
"6 Related Work Other work combining supervised and unsupervised learning for parsing includes (Charniak, 1997), (Johnson and Riezler, 2000), and (Schmid, 2002)",o,0,325,o,0,0.92768157,True,0.92768157,0.06452412,0.0077942917
"The third baseline, COMP is the document compression system developed by Daume III and Marcu (2002), which compresses documents by cutting out constituents in a combined syntax and discourse tree",o,0,326,o,0,0.95770323,True,0.95770323,0.03967416,0.0026225506
"The structure of the graphical model resembles IBM Model 1 (Brown et al., 1993) in which each target (record) word is assigned one or more source (text) words",o,0,327,o,0,0.97170097,True,0.97170097,0.023768349,0.0045307344
"By 17 0 10 20 30 40 50 60 70 80 90 100 10000 100000 1e+06 1e+07 Test Set Items with Translations (%) Training Corpus Size (num words) unigrams bigrams trigrams 4-grams Figure 1: Percent of unique unigrams, bigrams, trigrams, and 4-grams from the Europarl Spanish test sentences for which translations were learned in increasingly large training corpora increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993)",n,2,328,o,0,0.38900045,False,0.38900045,0.23286122,0.37813836
"We obtained word alignments of the training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diagfinal-and (Koehn et al., 2003)",o,0,329,o,0,0.96325576,True,0.96325576,0.032602653,0.004141675
"F (Cahill et al. , 2004) overall 95.98 57.86 72.20 73.00 40.28 51.91 90.16 54.35 67.82 65.54 36.16 46.61 args only 98.64 42.03 58.94 82.69 30.54 44.60 86.36 36.80 51.61 66.08 24.40 35.64 Basic Model overall 92.44 91.28 91.85 63.87 62.15 63.00 63.12 62.33 62.72 42.69 41.54 42.10 args only 89.42 92.95 91.15 60.89 63.45 62.15 47.92 49.81 48.84 31.41 32.73 32.06 Basic Model with Subject Path Constraint overall 92.16 91.36 91.76 63.72 62.20 62.95 75.96 75.30 75.63 50.82 49.61 50.21 args only 89.04 93.08 91.02 60.69 63.52 62.07 66.15 69.15 67.62 42.77 44.76 44.76 Table 7: Evaluation of trace insertion and antecedent recovery for C04 algorithm, our basic algorithm and basic algorithm with the subject path constraint",o,0,330,o,0,0.86886334,True,0.86886334,0.05269136,0.07844523
"1http://www.nist.gov/speech/tests/ace/ 49 Bootstrapping techniques have been used for such diverse NLP problems as: word sense disambiguation (Yarowsky, 1995), named entity classification (Collins and Singer, 1999), IE pattern acquisition (Riloff, 1996; Yangarber et al., 2000; Yangarber, 2003; Stevenson and Greenwood, 2005), document classification (Surdeanu et al., 2006), fact extraction from the web (Pasca et al., 2006) and hyponymy relation extraction (Kozareva et al., 2008)",o,0,331,o,0,0.7663402,True,0.7663402,0.23009707,0.003562749
herefore in Collins (1997) grammar rules are already factorized into a set of probabilitie,o,0,332,o,0,0.9287044,True,0.9287044,0.060978655,0.010316974
.2 Data sparseness Another facet of the general trade-off identified by Rapp (2002) pertains to how limitations in862 herent in the combination of data and cooccurrence retrieval method are manifes,o,0,333,o,0,0.7918072,True,0.7918072,0.17330115,0.03489165
"3 Length Model: Dynamic Programming Given the word fertility de nitions in IBM Models (Brown et al. , 1993), we can compute a probability to predict phrase length: given the candidate target phrase (English) eI1, and a source phrase (French) of length J, the model gives the estimation of P(J|eI1) via a dynamic programming algorithm using the source word fertilities",o,0,334,o,0,0.9638825,True,0.9638825,0.03207694,0.004040466
"(Lin, 2004b)",o,0,335,o,0,0.9675167,True,0.9675167,0.027305981,0.0051771975
"joint likelihood (JL) productdisplay i p parenleftBig xi,yi | vector parenrightBig conditional likelihood (CL) productdisplay i p parenleftBig yi | xi,vector parenrightBig classification accuracy (Juang and Katagiri, 1992) summationdisplay i (yi, y(xi)) expected classification accuracy (Klein and Manning, 2002) summationdisplay i p parenleftBig yi | xi,vector parenrightBig negated boosting loss (Collins, 2000)  summationdisplay i p parenleftBig yi | xi,vector parenrightBig1 margin (Crammer and Singer, 2001)  s.t. bardbl vectorbardbl  1;i,y negationslash= yi, vector  (vectorf(xi,yi )  vectorf(xi,y))   expected local accuracy (Altun et al. , 2003) productdisplay i productdisplay j p parenleftBig lscriptj(Y ) = lscriptj(yi ) | xi,vector parenrightBig Table 1: Various supervised training criteria",o,0,336,o,0,0.9742398,True,0.9742398,0.019915948,0.0058441814
"The combination is significantly better than (Shen et al., 2007) at a very high level, but more importantly, Shens results (currently representing the replicable state-of-the-art in POS tagging) have been significantly surpassed also by the semisupervised Morce (at the 99 % confidence level)",n,2,337,n,2,0.66591984,True,0.1974293,0.13665085,0.66591984
ollins (1999) falls back to the POS tagging of Ratnaparkhi (1996) for words seen fewer than 5 times in the training corpu,o,0,338,o,0,0.9066506,True,0.9066506,0.06548542,0.027863992
"Some researchers (Hindle, 1990; Grefenstette, 1994; Lin, 1998) classify terms by similarities based on their distributional syntactic patterns",o,0,339,o,0,0.97139084,True,0.97139084,0.025001574,0.0036075388
"Congress of the Italian Association for Artificial Intelligence, Palermo, 1991 B. Boguraev, Building a Lexicon: the Contribution of Computers, IBM Report, T.J. Watson Research Center, 1991 M. Brent, Automatic Aquisition of Subcategorization frames from Untagged Texts, in (ACL, 1991) N. Calzolari, R. Bindi, Acquisition of Lexical Information from Corpus, in (COLING 1990) K. W. Church, P. Hanks, Word Association Norms, Mutual Information, and Lexicography, Computational Linguistics, vol",o,0,340,o,0,0.96208185,True,0.96208185,0.03297694,0.0049412344
e-ranking 1 uses the score of the rst model as a feature in addition to the non-local features as in Collins (2002b,o,0,341,o,0,0.94632435,True,0.94632435,0.03940428,0.014271284
"3.2.1 Factored Treelet Translation Labels of nodes at the t-layer are not atomic but consist of more than 20 attributes representing various linguistic features.3 We can consider the attributes as individual factors (Koehn and Hoang, 2007)",o,0,342,o,0,0.92894363,True,0.92894363,0.059108745,0.011947623
"Recently, some kinds of learning techniques have been applied to cumulatively acquire exemplars form large corpora (Yarowsky, 1994, 1995)",o,0,343,o,0,0.74225336,True,0.74225336,0.25204623,0.005700478
"S  S0,n Si,k  Si,j Sj,k Si1,i  pii Figure 1: A grammar for a large neighborhood of permutations, given one permutation pi of length n. The Si,k rules are instantiated for each 0  i < j < k  n, and the Si1,i rules for each 0 <in. We say that two permutations are neighbors iff they can be aligned by an Inversion Transduction Grammar (ITG) (Wu, 1997), which is a familiar reordering device in machine translation",o,0,344,o,0,0.75276273,True,0.75276273,0.2365206,0.010716632
"Two major research topics in this field are Named Entity Recognition (NER) (N. Wacholder and Choi, 1997; Cucerzan and Yarowsky, 1999) and Word Sense Disambiguation (WSD) (Yarowsky, 1995; Wilks and Stevenson, 1999)",o,0,345,o,0,0.66192216,True,0.66192216,0.33153778,0.0065401527
"1 Introduction Estimating the degree of semantic relatedness between words in a text is deemed important in numerous applications: word-sense disambiguation (Banerjee and Pedersen, 2003), story segmentation (Stokes et al. , 2004), error correction (Hirst and Budanitsky, 2005), summarization (Barzilay and Elhadad, 1997; Gurevych and Strube, 2004)",o,0,346,o,0,0.50030863,True,0.50030863,0.49544656,0.0042447965
"The judges had an acceptable 0.74 mean  agreement (Carletta, 1996) for the assignment of the primary class, but a meaningless 0.21 for the secondary class (they did not even agree on which lemmata were polysemous)",o,0,347,n,2,0.5585649,False,0.40706164,0.034373462,0.5585649
"Consider the lexical model pw(ry|rx), defined following Koehn et al (2003), with a denoting the most frequent word alignment observed for the rule in the training set",o,0,348,o,0,0.9485898,True,0.9485898,0.045900363,0.005509859
"4.2 Building a Human Performance Model We adopt the evaluation approach that a good content selection strategy should perform similarly to humans, which is the view taken by existing summarization evaluation schemes such as ROUGE (Lin, 2004) and the Pyramid method (Nenkova et al., 2007)",o,0,349,o,0,0.7554272,True,0.7554272,0.22593607,0.01863674
"5.2 Evaluation Metrics The commonly used criteria to evaluate the translation results in the machine translation community are: WER (word error rate), PER (positionindependent word error rate), BLEU (Papineni et al. , 2002), and NIST (Doddington, 2002)",o,0,350,p,1,0.7132178,False,0.27902746,0.7132178,0.0077547263
"However, because these estimates are too sparse to be relied upon, we use interpolated estimates consisting of mixtures of successively lowerorder estimates (as in Placeway et al. 1993)",o,0,351,o,0,0.87203735,True,0.87203735,0.085943796,0.042018812
"The simple model 1 (Brown et al. , 1993) for the translation of a SL sentence d = dldt in a TL sentence e = el em assumes that every TL word is generated independently as a mixture of the SL words: m l P(e\[d),,~ H ~ t(ej\[di) (2) j=l i=O In the equation above t(ej\[di) stands for the probability that ej is generated by di",o,0,352,o,0,0.9638582,True,0.9638582,0.031287223,0.004854609
"The mapping typically is made to try to give the most favorable mapping in terms of accuracy, typically using a greedy assignment (Haghighi and Klein, 2006)",o,0,353,o,0,0.86014014,True,0.86014014,0.11505112,0.02480876
"Formally, by distributional similarity (or co-occurrence similarity) of two words w 1 and w 2 , we mean that they tend to occur in similar contexts, for some definition of context; or that the set of words that w 1 tends to co-occur with is similar to the set that w 2 tends to co-occur with; or that if w 1 is substituted for w 2 in a context, its plausibility (Weeds 2003; Weeds and Weir 2005) is unchanged",o,0,354,o,0,0.95329654,True,0.95329654,0.02914062,0.017562842
"Here, ppicker shows the accuracy when phrases are extracted by using the N-best phrase alignment method described in Section 4.1, while growdiag-final shows the accuracy when phrases are extracted using the standard phrase extraction algorithm described in (Koehn et al. , 2003)",o,0,355,o,0,0.93402,True,0.93402,0.05291457,0.0130653875
"Under certain precise conditions, as described in (Abney, 2004), we can analyze Algorithm 1 as minimizing the entropy of the distribution over translations of U. However, this is true only when the functions Estimate, Score and Select have very prescribed definitions",o,0,356,o,0,0.7988674,True,0.7988674,0.12532371,0.075808816
"This shows that hypothesis features are either not discriminative enough, or that the reranking model is too weak This performance gap can be mainly attributed to two problems: optimization error and modeling error (see Figure 1).1 Much work has focused on developing better algorithms to tackle the optimization problem (e.g. MERT (Och, 2003)), since MT evaluation metrics such as BLEU and PER are riddled with local minima and are difficult to differentiate with respect to re-ranker parameters",o,0,357,o,0,0.6056495,True,0.6056495,0.22661875,0.16773173
ne example of the 450 latter problem is the following: in (Smadja 1993) the nature of a syntactic link between two associated words is detected a posterior,o,0,358,o,0,0.9528189,True,0.9528189,0.040982865,0.0061982595
"For content selection, discourse-level considerations were proposed by Daume III and Marcu (2002), who explored the use of Rhetorical Structure Theory (Mann and Thompson, 1988)",o,0,359,o,0,0.96883494,True,0.96883494,0.027401658,0.0037633632
"4 Features For our experiments we use the features proposed, motivated and described in detail by (Nenkova and Louis, 2008)",o,0,360,o,0,0.945413,True,0.945413,0.050856832,0.0037302137
"This knowledge is represented in axiomatic form, using the notation proposed in (Hobbs et al. , 1993) and previously implemented in TACITUS",o,0,361,o,0,0.9525862,True,0.9525862,0.04115017,0.0062636714
"We use Entropy Regularization (ER) (Jiao et al., 2006) to leverage unlabeled instances.7 We weight the ER term by choosing the best8 weight in {103,102,101,1,10} multiplied by #labeled#unlabeled for each data set and query selection method",o,0,362,o,0,0.91894794,True,0.91894794,0.07411748,0.0069345124
"The first is identifying words and phrases that are associated with subjectivity, for example, that think is associated with private states and that beautiful is associated with positive sentiments (e.g. , (Hatzivassiloglou and McKeown, 1997; Wiebe, 2000; Kamps and Marx, 2002; Turney, 2002; Esuli and Sebastiani, 2005))",o,0,363,o,0,0.96231073,True,0.96231073,0.033921923,0.0037673379
"2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, provideageneralpurposemachinelearningtechnique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification",p,1,364,p,1,0.8040809,True,0.19079953,0.8040809,0.005119513
xperimentation The corpus used in shallow parsing is extracted from the PENN TreeBank (Marcus et al. 1993) of 1 million words (25 sections) by a program provided by Sabine Buchholz from Tilburg Universit,o,0,365,o,0,0.9594719,True,0.9594719,0.037714884,0.002813282
"We prepare the corpus by passing it through Adwait Ratnaparkhis part-of-speech tagger (Ratnaparkhi, 1996) (trained on the Penn Treebank WSJ corpus) and then running Steve Abneys chunker (Abney, 1997) over the entire text",o,0,366,o,0,0.9652246,True,0.9652246,0.030464139,0.0043112505
"(3) () () 0 log 2 log A LH LH     = 1 Problems for an unscaled log  approach Although log  identifies collocations much better than competing approaches (Dunning 1993) in terms of its recall, it suffers from its relatively poor precision rates",p,1,367,n,2,0.83706456,False,0.11752063,0.04541483,0.83706456
"2.2 Three Treebanks The Treebanks that we used in this paper are the English Penn Treebank II (Marcus et al. , 1993), the Chinese Penn Treebank (Xia et al. , 2000b), and the Korean Penn Treebank (Chung-hye Han, 2000)",o,0,368,o,0,0.9667072,True,0.9667072,0.029256241,0.0040365085
"Och and Ney (2003) proposed Model 6, a log-linear combination of IBM translation models and HMM model",o,0,369,o,0,0.9649002,True,0.9649002,0.029603535,0.005496194
"In the recent years, there have been a number of papers considering this or similar problems: (Brown et al. , 1990), (Dagan et al. , 1993), (Kay et al. , 1993), (Fung et al. , 1993)",o,0,370,o,0,0.8515004,True,0.8515004,0.119419746,0.02907989
"The size of the development set used to generate 1 and 2 (1000 sentences) compensates the tendency of the unsmoothed MERT algorithm to overfit (Och, 2003) by providing a high ratio between number of variables and number of parameters to be estimated",n,2,371,o,0,0.54076576,False,0.54076576,0.2599695,0.19926472
"For now, we consider it to be one where:  Every foreign word is aligned exactly once (Brown et al., 1993)",o,0,372,o,0,0.9513961,True,0.9513961,0.041879315,0.0067246645
"Other commonly used measures include kappa (Carletta 1996) and relative utility (Radev, Jing, and Budzikowska 2000), both of which take into account the performance of a summarizer that randomly picks passages from the original document to produce an extract",o,0,373,p,1,0.69312656,False,0.29869285,0.69312656,0.008180551
"The other approach is to estimate a single score or likelihood of a translation with rich features, for example, with the maximum entropy (MaxEnt) method as in (Carpuat and Wu, 2007; Ittycheriah and Roukos, 2007; He et al., 2008)",o,0,374,o,0,0.9409287,True,0.9409287,0.049203765,0.009867536
"This is based on the idea from (Ratnaparkhi, 1996) that rare words in the training set are similar to unknown words in the test set, and can be used to learn how to tag the unknown words that will be encountered during testing",o,0,375,o,0,0.9531501,True,0.9531501,0.04201162,0.0048383283
"Even the creators of BLEU point out that it may not correlate particularly well with human judgment at the sentence level (Papineni et al. , 2002)",n,2,376,n,2,0.81858504,True,0.13057065,0.050844334,0.81858504
"We measure this association using pointwise Mutual Information (MI) (Church and Hanks, 1990)",o,0,377,o,0,0.9694551,True,0.9694551,0.026764425,0.003780511
"(Ueffing et al., 2007; Haffari et al., 2009) show that treating U+ as a source for a new feature function in a loglinear model for SMT (Och and Ney, 2004) allows us to maximally take advantage of unlabeled data by finding a weight for this feature using minimum error-rate training (MERT) (Och, 2003)",o,0,378,o,0,0.6282755,True,0.6282755,0.34393057,0.027793849
"Unlike Choueka (1988), Church and Hanks (1990) identify as collocations both interrupted and uninterrupted sequences of words",p,1,379,o,0,0.9583809,False,0.9583809,0.029822841,0.011796282
"The row labelled Precision shows the precision of the extracted information (i.e. , how many entries are correct, according to a human annotator) estimated by random sampling and manual evaluation of 1% of the data for each table, similar to (Fleischman et al. , 2003)",o,0,380,o,0,0.94604486,True,0.94604486,0.0413891,0.0125660775
"Using the values computed above: p1 = k1n 1 p2 = k2n 2 p = k1+k2n 1+n2 Taking these probabilities to be binomially distributed, the log likelihood statistic (Dunning, 1993) is given by: 2 log = 2[log L(p1;k1;n1)+log L(p2;k2;n2) log L(p;k1;n2) log L(p;k2;n2)] where, log L(p;n;k)=k log p+(n k) log(1 p) According to this statistic, the greater the value of 2 log for a particular pair of observed frame and verb, the more likely that frame is to be valid SF of the verb",o,0,381,o,0,0.93862784,True,0.93862784,0.043755755,0.01761645
"(Ramshaw and Marcus, 1995) represent chunking as tagging problem and the CoNLL2000 shared task (Kim Sang and Buchholz, 2000) is now the standard evaluation task for chunking English",o,0,382,o,0,0.91626644,True,0.91626644,0.08029737,0.003436212
"3.3 BLEU Score The BLEU score (Papineni et al. , 2002) measures the agreement between a hypothesiseI1 generated by the MT system and a reference translation eI1",o,0,383,o,0,0.9644344,True,0.9644344,0.025130466,0.010435095
"Second, it can be applied to control the quality of parallel bilingual sentences mined from the Web, which are critical sources for a wide range of applications, such as statistical machine translation (Brown et al. , 1993) and cross-lingual information retrieval (Nie et al. , 1999)",o,0,384,o,0,0.6519951,True,0.6519951,0.3435773,0.0044275643
"2 Statistical Word Alignment Statistical translation models (Brown, et al. 1993) only allow word to word and multi-word to word alignments",n,2,385,n,2,0.8139686,True,0.15197244,0.034058977,0.8139686
"We use a statistical POS tagging system built on Arabic Treebank data with MaxEnt framework (Ratnaparkhi, 1996)",o,0,386,o,0,0.96532905,True,0.96532905,0.03187897,0.0027920215
"4 Analysis of Experimental Data Most of the existing research in computational linguistics that uses human annotators is within the framework of classification, where an annotator decides, for every test item, on an appropriate tag out of the pre-specified set of tags (Poesio and Vieira, 1998; Webber and Byron, 2004; Hearst, 1997; Marcus et al. , 1993)",o,0,387,o,0,0.91817003,True,0.91817003,0.07910076,0.00272924
"Our conception of the task is inspired by Ramshaw and Marcus representation of text chunking as a tagging problem (Ramshaw and Marcus, 1995) . The information that can be used to train the system appears in columns 1 to 8 of Table 1",o,0,388,o,0,0.89681613,True,0.89681613,0.09310372,0.010080165
"For this reason, each preposition and verb was assigned a weight based on the proportion of occurrences of that word in the Penn Treebank (Marcus et al. , 1993) which are labelled with a spatial meaning",o,0,389,o,0,0.9550288,True,0.9550288,0.037535653,0.0074355514
"Since the DUC 2004 evaluation, Lin (2004) has concluded that certain ROUGE metrics correlate better with human judgments than others, depending on the summarisation task being evaluated, i.e. single document, headline, or multi-document summarisation",o,0,390,o,0,0.6738988,True,0.6738988,0.20229173,0.12380949
"660 2 Statistical Coreference Resolution Model Our coreference system uses a binary entity-mention model PL( je, m) (henceforth link model ) to score the action of linking a mention m to an entity e. In our implementation, the link model is computed as PL(L = 1je, m) max mprimee PL(L = 1je, mprime, m), (1) where mprime is one mention in entity e, and the basic model building block PL(L = 1je, mprime, m) is an exponential or maximum entropy model (Berger et al. , 1996): PL(Lje, mprime, m) = exp braceleftbig summationtext i igi(e, m prime, m, L)bracerightbig Z(e, mprime, m), (2) where Z(e, mprime, m) is a normalizing factor to ensure that PL( je, mprime, m) is a probability, fgi(e, mprime, m, L)g are features and fig are feature weights",o,0,391,o,0,0.9341004,True,0.9341004,0.057220966,0.008678711
"(Cutting et al. , 1992))",o,0,392,o,0,0.9681161,True,0.9681161,0.026160955,0.0057229972
"One heuristic approach is to adapt the self-training algorithm (Yarowsky, 1995) to our model",o,0,393,o,0,0.9610496,True,0.9610496,0.035374314,0.0035761115
"To estimate the parameters of the MEMM+pred model we turn to the successful Maximum Entropy (Berger et al., 1996) parameter estimation method",p,1,394,p,1,0.8631963,True,0.12200953,0.8631963,0.01479421
"The first work on SMT done at IBM (Brown et al. , 1990; Brown et al. , 1992; Brown et al. , 1993; Berger et al. , 1994), used a noisy-channel model, resulting in what Brown et al",o,0,395,o,0,0.8660983,True,0.8660983,0.12942731,0.004474405
"This is seen in that each time we check for the nearest intersection to the current 1-best for some n-best list l, we Algorithm 1 Och (2003)s line search method to find the global minimum in the loss, lscript, when starting at the point w and searching along the direction d using the candidate translations given in the collection of n-best lists L. Input: L, w, d, lscript I {} for l L do for e  l do m{e} e.features d b{e} e.features w end for bestn argmaxel m{e}{b{e} breaks ties} loop bestn+1 = argminel max parenleftBig 0, b{bestn}b{e}m{e}m{bestn} parenrightBig intercept  max parenleftBig 0, b{bestn}b{bestn+1}m{bestn+1}m{bestn} parenrightBig if intercept > 0 then add(I, intercept) else break end if end loop end for add(I, max(I)+2epsilon1) ibest = argminiI evallscript(L,w+(iepsilon1)d) return w+(ibest epsilon1)d must calculate its intersection with all other candidate translations that have yet to be selected as the 1-best",o,0,396,o,0,0.9202589,True,0.9202589,0.064881034,0.014860081
"We tune all feature weights automatically (Och, 2003) to maximize the BLEU (Papineni et al., 2002) score on the dev set",o,0,397,o,0,0.9471799,True,0.9471799,0.043424793,0.009395283
"This was recently followed by (Matsuzaki et al., 2005; Petrov et al., 2006) who introduce state-of-the-art nearly unlexicalized PCFG parsers",p,1,398,p,1,0.7729728,True,0.20733295,0.7729728,0.019694157
"The abduction-based approach (Hobbs et al. , 1988) has provided a simple and elegant way to realize such a task",p,1,399,p,1,0.90461576,True,0.0889589,0.90461576,0.0064253085
"2 Related Work The most commonly used similarity measures are based on the WordNet lexical database (eg Budanitsky and Hirst 2006, Hughes and Ramage 2007) and a number of such measures have been made publicly available (Pedersen et-al 2004)",o,0,400,p,1,0.8621048,False,0.13259596,0.8621048,0.0052993274
"4.3 Using Unlabeled Data for Parsing Recent studies on parsing indicate that the use of unlabeled data by self-training can help parsing on the WSJ data, even when labeled data is relatively large (McClosky et al., 2006a; Reichart and Rappoport, 2007)",o,0,401,p,1,0.6370971,False,0.33621874,0.6370971,0.026684172
"We use the standard minimum error-rate training (Och, 2003) to tune the feature weights to maximize the systems BLEU score on the dev set",o,0,402,o,0,0.94599587,True,0.94599587,0.04705813,0.006946068
"We also cannot use prior graph construction methods for the document level (such as physical proximity of sentences, used in Pang and Lee (2004)) at the word sense level",o,0,403,n,2,0.6036027,False,0.3700575,0.026339779,0.6036027
"The idea caught on very quickly: Suhm and Waibel (1994), Mast et aL (1996), Warnke et al",o,0,404,p,1,0.66316736,False,0.33054352,0.66316736,0.0062891394
"First, for each verb occurrence subjects and objects were extracted from a parsed corpus (Collins 1997)",o,0,405,o,0,0.96179295,True,0.96179295,0.034758553,0.0034485017
"In particular, we use a randomly-selected corpus the first five columns as information-like. consisting of a 6.7 million word subset of the TREC Similarly, since the last four columns share databases (DARPA, 1993-1997)",o,0,406,o,0,0.9495124,True,0.9495124,0.047308076,0.0031795187
"The words with the highest association probabilities are chosen as acquired words for entity e. 4.1 Base Model I Using the translation model I (Brown et al., 1993), where each word is equally likely to be aligned with each entity, we have p(w|e) = 1(l + 1)m mproductdisplay j=1 lsummationdisplay i=0 p(wj|ei) (1) where l and m are the lengths of entity and word sequences respectively",o,0,407,o,0,0.9610318,True,0.9610318,0.034184244,0.0047839815
"In fact, a limitation of the experiments described in this paper is that the loglinear weights for the glass-box techniques were optimized for BLEU using Ochs algorithm (Och, 2003), while the linear weights for 55 black-box techniques were set heuristically",o,0,408,n,2,0.59664214,False,0.3463231,0.05703478,0.59664214
"Our chunks and functions are based on the annotations in the third release of the Penn Treebank (Marcus et al. , 1993)",o,0,409,o,0,0.96944314,True,0.96944314,0.025721502,0.0048352876
"An additional translation set called the Maximum BLEU set is employed by the SMT system to train the weights associated with the components of its log-linear model (Och, 2003)",o,0,410,o,0,0.9561051,True,0.9561051,0.03898437,0.004910538
"Dredze et al. also indicated that unlabeled dependency parsing is not robust to domain adaptation (Dredze et al., 2007)",o,0,411,n,2,0.63090074,False,0.2965648,0.072534524,0.63090074
"Our hierarchical system is Hiero (Chiang, 2007), modified to construct rules from a small sample of occurrences of each source phrase in training as described by Lopez (2008b)",o,0,412,o,0,0.9615234,True,0.9615234,0.035115525,0.003361102
"These three parsers have given the best reported parsing results on the Penn Treebank Wall Street Journal corpus (Marcus et al. , 1993)",o,0,413,p,1,0.7804524,False,0.15370832,0.7804524,0.065839335
"2.2 Evaluation of Acquisition Algorithms Many methods for automatic acquisition of rules have been suggested in recent years, ranging from distributional similarity to finding shared contexts (Lin and Pantel, 2001; Ravichandran and Hovy, 2002; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004; Sekine, 2005)",o,0,414,o,0,0.9439276,True,0.9439276,0.053644218,0.0024282208
"More specifically, by using translation probabilities, we can rewrite equation (11) and (12) as follow: nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull (13) nullnullnullnullnull null nullnull null nullnullnull null null nullnullnullnull null nullnull null null nullnull null   nullnull null null | null null null null nullnull null nullnull null nullnull null null null null nullnull null nullnull null  null null 1nullnull null nullnull null null null nullnull|nullnull  (14) where nullnullnullnull|null null null  denotes the probability that topic term null  is the translation of null null . In our experiments, to estimate the probability nullnullnullnull|null null null , we used the collections of question titles and question descriptions as the parallel corpus and the IBM model 1 (Brown et al., 1993) as the alignment model",o,0,415,o,0,0.93405,True,0.93405,0.054351643,0.0115982955
"One of the popular statistical machine translation paradigms is the phrase-based model (PBSMT) (Marcu et al., 2002; Koehn et al., 2003; Och et al., 2004)",o,0,416,p,1,0.9397778,False,0.051318467,0.9397778,0.008903672
"There have been many statistical measures which estimate co-occurrence and the degree of association in previous researches, such as mutual information (Church 1990, Sporat 1990), t-score (Church 1991), dice matrix (Smadja 1993, 1996)",o,0,417,o,0,0.85117656,True,0.85117656,0.14448592,0.0043376065
"The PropBank superimposes an annotation of semantic predicate-argument structures on top of the Penn Treebank (PTB) (Marcus et al. , 1993; Marcus et al. , 1994)",o,0,418,o,0,0.9733575,True,0.9733575,0.020499486,0.0061430526
"In fact, we still have a question as to whether SS-CRF-MER is really scalable in practical time for such a large amount of unlabeled data as used in our experiments, which is about 680 times larger than that of (Jiao et al. , 2006)",o,0,419,n,2,0.8631324,False,0.10014684,0.036720734,0.8631324
"For example, (Daume III, 2007) shows that training a learning algorithm on the weighted union of different data sets (which is basically what we did) performs almost as well as more involved domain adaptation approaches",p,1,420,p,1,0.5053968,True,0.37111273,0.5053968,0.12349049
"This method led to improvement in the decoding speed as well as the output accuracy for English POS tagging (Ratnaparkhi, 1996)",p,1,421,p,1,0.787418,True,0.19466853,0.787418,0.017913526
"3.1 Definition The following set-up, adapted from Collins (2002), was used for all three discriminative training methods: 266  Training data is a set of input-output pairs",o,0,422,o,0,0.9480381,True,0.9480381,0.047797244,0.004164767
"three models in (Collins, 1997) are susceptible to the O(n 3) method (cf",n,2,423,o,0,0.90200627,False,0.90200627,0.06578931,0.032204363
"This represents the translation probability of a phrase when it is decomposed into a series of independent word-for-word translation steps (Koehn et al. , 2003), and has proven a very effective feature (Zens and Ney, 2004; Foster et al. , 2006)",o,0,424,p,1,0.91066796,False,0.06973626,0.91066796,0.01959572
"INTRODUCTION Word associations have been studied for some time in the fields of psycholinguistics (by testing human subjects on words), linguistics (where meaning is often based on how words co-occur with each other), and more recently, by researchers in natural language processing (Church and Hanks, 1990; Hindle and Rooth, 1990; Dagan, 1990; McDonald et al. , 1990; Wilks et al. , 1990) using statistical measures to identify sets of associated words for use in various natural language processing tasks",o,0,425,o,0,0.86361796,True,0.86361796,0.13439442,0.0019875679
"Indeed, as for the voted perceptron of Collins (2002), we can get performance gains by reducing the support threshold for features to be included in the model",p,1,426,o,0,0.6150943,False,0.6150943,0.32923627,0.05566947
" The morphological processing in PairClass (Minnen et al., 2001) is more sophisticated than in Turney (2006)",n,2,427,n,2,0.87392074,True,0.08986706,0.036212195,0.87392074
"Titov and McDonald (2008b) proposed a joint model of text and aspect ratings which utilizes a modified LDA topic model to build topics that are representative of ratable aspects, and builds a set of sentiment predictors",o,0,428,o,0,0.9699776,True,0.9699776,0.026977042,0.0030453054
"(1990, 1993), these models have non-uniform linguistically motivated structure, at present coded by hand",o,0,429,o,0,0.86296344,True,0.86296344,0.07758987,0.059446655
"2.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy (Berger et al. , 1996) model",o,0,430,o,0,0.9502779,True,0.9502779,0.042627797,0.0070943134
nalternativeembeddingisthatusedbyTurney (2008) in his PairClass system (see Section 6,o,0,431,o,0,0.9541059,True,0.9541059,0.04261704,0.0032770596
"To deal with this question, we use ATIS p-o-s trees as found in the Penn Treebank (Marcus et al. , 1993)",o,0,432,o,0,0.9526926,True,0.9526926,0.04299775,0.004309642
"For example, in IBM Model 1 the lexicon probability of source word f given target word e is calculated as (Och and Ney, 2003): p(f|e) = summationtext k c(f|e;e k,fk) summationtext k,f c(f|e;e k,fk) (1) c(f|e;ek,fk) = summationdisplay ek,fk P(ek,fk)summationdisplay a P(a|ek,fk) (2) summationdisplay j (f,fkj )(e,ekaj) Therefore, the distribution of P(ek,fk) will affect the alignment results",o,0,433,o,0,0.9675043,True,0.9675043,0.027966818,0.004528823
"3 The Framework 3.1 The Algorithm Our transductive learning algorithm, Algorithm 1, is inspired by the Yarowsky algorithm (Yarowsky, 1995; Abney, 2004)",o,0,434,o,0,0.9664179,True,0.9664179,0.029218938,0.0043632
"Some of these have been previously employed for various tasks by Gabrilovich and Markovitch, (2006); Overell and Ruger (2006), Cucerzan (2007), and Suchanek et al",o,0,435,o,0,0.90384763,True,0.90384763,0.09206374,0.004088685
"(Donaway et al. , 2000, Hirao et al. , 2005, Lin et al. , 2003, Lin, 2004, Hori et al. , 2003) and manual method",o,0,436,o,0,0.96964633,True,0.96964633,0.023671811,0.006681833
"The idea of topic signature terms was introduced by Lin and Hovy (Lin and Hovy, 2000) in the context of single document summarization, and was later used in several multi-document summarization systems (Conroy et al., 2006; Lacatusu et al., 2004; Gupta et al., 2007)",o,0,437,o,0,0.9274415,True,0.9274415,0.070373476,0.0021850714
"Finally, the translation model can be formalized as the following optimization problem argmax logPr(D;) s.t. mwsummationdisplay j=1 Pr(wj|ok) = 1,k This optimization problem can be solved by the EM algorithm (Brown et al. , 1993)",p,1,438,o,0,0.9398252,False,0.9398252,0.055796955,0.0043778303
"Lins measure Lin (1998) proposed a symmetrical measure: Par Lin (s  t)= summationtext fF s F t (w(s,f)+w(t,f)) summationtext fF s w(s,f)+ summationtext fF t w(t,f) , where F s and F t denote sets of features with positive weights for words s and t, respectively",o,0,439,o,0,0.968946,True,0.968946,0.027566265,0.0034877462
"To compare the output of their shallow parser with the output of the well-known Collins (1997) parser, Li and Roth applied the chunklink conversion script to extract the shallow constituents from the output of the Collins parser on WSJ section 00",p,1,440,o,0,0.6617708,False,0.6617708,0.3068517,0.0313775
"Alternatively, order is modelled in terms of movement of automatically induced hierarchical structure of sentences (Chiang, 2005; Wu, 1997)",o,0,441,o,0,0.9632766,True,0.9632766,0.031040166,0.0056832777
"Then, h(s)  h(s) + Lmax, s  S. This epsilon1-admissible heuristic (Ghallab and Allard, 1982) bounds our search error by Lmax.3 3 Bitext Parsing In bitext parsing, one jointly infers a synchronous phrase structure tree over a sentence ws and its translation wt (Melamed et al. , 2004; Wu, 1997)",o,0,442,o,0,0.96363294,True,0.96363294,0.030968368,0.0053986027
"64 Table 1: Subjects of """"employ"""" with highest likelihood ratio word freq logA word freq logA bRG 64 50.4 plant 14 31.0 company 27 28.6 operation 8 23.0 industry 9 14.6 firm 8 13.5 pirate 2 12.1 unit 9 9.32 shift 3 8.48 postal service 2 7.73 machine 3 6.56 corporation 3 6.47 manufacturer 3 6.21 insurance company 2 6.06 aerospace 2 5.81 memory device 1 5.79 department 3 5.55 foreign office 1 5.41 enterprise 2 5.39 pilot 2 5.37 *ORG includes all proper names recognized as organizations The logA column are their likelihood ratios (Dunning, 1993)",o,0,443,o,0,0.9518154,True,0.9518154,0.043501694,0.004682902
"Current tree-based models that integrate linguistics and statistics, such as GHKM (Galley et al., 2004), are not able to generalize well from a single phrase pair",n,2,444,n,2,0.836233,True,0.12097921,0.042787716,0.836233
"Word segmentation and POS tagging in a joint process have received much attention in recent research and have shown improvements over a pipelined fashion (Ng and Low, 2004; Nakagawa and Uchimoto, 2007; Zhang and Clark, 2008; Jiang et al., 2008a; Jiang et al., 2008b)",p,1,445,p,1,0.7987972,True,0.19271879,0.7987972,0.008484027
"As described in Section 3 we retrieved neighbors using Lins (1998) similarity measure on a RASP parsed (Briscoe and Carroll, 2002) version of the BNC",o,0,446,o,0,0.97360194,True,0.97360194,0.022961298,0.0034367223
"Recently, (Shen et al., 2008) introduced an approach for incorporating a dependency-based language model into SMT",o,0,447,o,0,0.86985326,True,0.86985326,0.12519193,0.004954795
"Early experiments with syntactically-informed phrases (Koehn et al., 2003), and syntactic reranking of K-best lists (Och et al., 2004) produced mostly negative results",o,0,448,o,0,0.5947109,True,0.5947109,0.36071038,0.044578653
"(Zhang et al. , 2006) binarize grammars into CNF normal form, while (Watanabe et al. , 2006) allow only Griebach-Normal form grammars",o,0,449,o,0,0.8761823,True,0.8761823,0.044266254,0.07955147
"The third column reports the BLEU score (Papineni et al. , 2002) along with 95% confidence interval",o,0,450,o,0,0.9606635,True,0.9606635,0.030557986,0.008778554
"Recent work (Talbot and Osborne, 2007b) has demonstrated that randomized encodings can be used to represent n-gram counts for LMs with signficant space-savings, circumventing information-theoretic constraints on lossless data structures by allowing errors with some small probability",p,1,451,o,0,0.500697,False,0.500697,0.48529217,0.014010812
"A few studies (Carpuat and Wu, 2007; Ittycheriah and Roukos, 2007; He et al., 2008; Hasan et al., 2008) addressed this defect by selecting the appropriate translation rules for an input span based on its context in the input sentence",o,0,452,o,0,0.92594236,True,0.92594236,0.06134337,0.012714284
u (1997) and Alshawi et a,o,0,453,o,0,0.9688913,True,0.9688913,0.025984498,0.0051241512
"(Matsuzaki et al. , 2005; Koo and Collins, 2005))",o,0,454,o,0,0.9742367,True,0.9742367,0.019964566,0.0057986835
any 412 Turney Similarity of Semantic Relations researchers have argued that metaphor is the heart of human thinking (Lakoff and Johnson 1980; Hofstadter and the Fluid Analogies Research Group 1995; Gentner et al. 2001; French 2002,o,0,455,o,0,0.928156,True,0.928156,0.06556574,0.006278343
"In the meantime, synchronous parsing methods efficiently process the same bitext phrases while building their bilingual constituents, but continue to be employed primarily for word-to-word analysis (Wu, 1997)",o,0,456,o,0,0.5018343,True,0.5018343,0.45469967,0.043466084
"4.2 Translation Results The evaluation metrics used in our experiments are WER (Word Error Rate), PER (Positionindependent word Error Rate) and BLEU (BiLingual Evaluation Understudy) (Papineni et al. , 2002)",o,0,457,o,0,0.9736328,True,0.9736328,0.022970438,0.003396791
"The ROUGE (Lin, 2004) suite of metrics are n-gram overlap based metrics that have been shown to highly correlate with human evaluations on content responsiveness",p,1,458,p,1,0.926561,True,0.069930054,0.926561,0.0035089192
"First, such a system makes use of lexical information when modeling reordering (Lopez, 2008), which has previously been shown to be useful in German-to-English translation (Koehn et al., 2008)",p,1,459,p,1,0.73637056,True,0.25849038,0.73637056,0.0051391604
"(Blitzer et al., 2006; Jiang and Zhai, 2007)",o,0,460,o,0,0.96864563,True,0.96864563,0.026226439,0.0051278574
"Discriminative taggers and chunkers have been the state-of-the-art for more than a decade (Ratnaparkhi, 1996; Sha and Pereira, 2003)",p,1,461,p,1,0.9229916,True,0.071312614,0.9229916,0.005695802
"The noun phrases in this data set are the same as in the Treebank and therefore the baseNPs in this data set are slightly different from the ones in the (Ramshaw and Marcus, 1995) data sets",o,0,462,o,0,0.9375858,True,0.9375858,0.025917783,0.03649643
"These problems include collocation discovery (Pearce, 2001), smoothing and estimation (Brown et al. , 1992; Clark and Weir, 2001) and question answering (Pasca and Harabagiu, 2001)",o,0,463,o,0,0.9660688,True,0.9660688,0.028096287,0.0058349175
"Table look-up using an explicit translation lexicon is sufficient and preferable for many multilingual NLP applications, including """"crummy"""" MT on the World Wide Web (Church & I-Iovy, 1993), certain machine-assisted translation tools (e.g",o,0,464,o,0,0.528586,True,0.528586,0.45345005,0.017963996
hang and Clark (2008) indicated that their results cannot directly compare to the results of Shi and Wang (2007) due to different experimental setting,o,0,465,n,2,0.78135526,False,0.18805106,0.030593744,0.78135526
"Finally, we are investigating several avenues for using this system output for Machine Translation (MT) including: (1) aiding word alignment for other MT system (Wang et al., 2007); and (2) aiding the creation various MT models involving analyzed text, e.g., (Gildea, 2004; Shen et al., 2008)",o,0,466,o,0,0.9513428,True,0.9513428,0.040726278,0.007930889
"Their systems output was an ordered list of possible parts according to some statistical metrics (e.g., the log-likelihood metric (Dunning 1993))",o,0,467,o,0,0.96477026,True,0.96477026,0.031016275,0.004213511
"Given a set of terms with unknown sentiment orientation, Turney (2002) then uses the PMI-IR algorithm (Turney 2001) to issue queries to the web and determine, for each of these terms, its pointwise mutual information (PMI) with the two seed words across a large set of documents",o,0,468,o,0,0.9653872,True,0.9653872,0.03079623,0.0038164712
he principal training method is an adaptation of averaged perceptron learning as described by Collins (2002,o,0,469,o,0,0.92778236,True,0.92778236,0.06920645,0.0030111691
"By using 8-bit floating point quantization 1 , N-gram language models are compressed into 10 GB, which is comparable to a lossy representation (Talbot and Brants, 2008)",o,0,470,o,0,0.955909,True,0.955909,0.04017682,0.0039142193
"From the extracted n-grams, those with a flequc'ncy of 3 or more were kept (other approaches get rid of n-grams of such low frequencies (Smadja, 1993))",o,0,471,o,0,0.9186001,True,0.9186001,0.06013142,0.021268474
"It is sometimes assumed that estimates of entropy (e.g. , Shannon's estimate that English is 75% redundant, Brown et al's (1992) upper bound of 1.75 bits per character for printed English) are directly 3There are some cases where words are deliberately misspelled in order to get better output from the synthesizer, such as coyote spelled kiote",o,0,472,o,0,0.82085764,True,0.82085764,0.12586628,0.053276025
"Parameters were tuned with MERT algorithm (Och, 2003) on the NIST evaluation set of 2003 (MT03) for both the baseline systems and the system combination model",o,0,473,o,0,0.96970356,True,0.96970356,0.025640622,0.0046558445
"5 Related work Cutting introduced grouping of words into equiva.lence classes based on the set of possible tags to reduce the number of the parameters (Cutting et al. , 1992) . Schmid used tile equivaleuce classes for smoothing",o,0,474,o,0,0.9577248,True,0.9577248,0.037900392,0.004374922
"Mathematical details are fully described in (Brown et al. , 1993)",o,0,475,o,0,0.9320747,True,0.9320747,0.061838266,0.0060870466
"We run the decoder with its default settings (maximum phrase length 7) and then use Koehn's implementation of minimum error rate training (Och, 2003) to tune the feature weights on the de2 The full name of HTRDP is National High Technology Research and Development Program of China, also named as 863 Program",o,0,476,o,0,0.9529388,True,0.9529388,0.042825498,0.0042356425
"It can be applied to complicated models such IBM Model-4 (Brown et al. , 1993)",o,0,477,o,0,0.7395645,True,0.7395645,0.25359765,0.0068378113
"6 Coding reliability The reliability of the annotation was evaluated using the kappa statistic (Carletta, 1996)",o,0,478,o,0,0.96715885,True,0.96715885,0.028238077,0.004602992
"In general, they can be divided into two major categories, namely lexicalized models (Collins 1997, 1999; Charniak 1997, 2000) and un-lexicalized models (Klein and Manning 2003; Matsuzaki et al. 2005; Petrov et al. 2006; Petrov and Klein 2007)",o,0,479,o,0,0.94761187,True,0.94761187,0.049082167,0.0033060096
"For Japanese, dependency trees are trimmed instead of full parse trees (Takeuchi and Matsumoto, 2001; Oguro et al., 2002; Nomoto, 2008) 1 This parsing approach is reasonable because the compressed output is grammatical if the 1 Hereafter, we refer these compression processes as tree trimming. input is grammatical, but it offers only moderate compression rates",p,1,480,o,0,0.776633,False,0.776633,0.087391466,0.13597557
"Generation of paraphrase examples was also investigated (Barzilay and Lee, 2003; Quirk et al. , 2004)",o,0,481,o,0,0.9661089,True,0.9661089,0.029490843,0.00440031
everal sentiment information retrieval models were proposed in the framework of probabilistic language models by Eguchi and Lavrenko (2006,o,0,482,o,0,0.9579361,True,0.9579361,0.038930506,0.0031334192
"Linear weights are assigned to each of the transducers features using an averaged perceptron for structure prediction (Collins, 2002)",o,0,483,o,0,0.9688025,True,0.9688025,0.027268939,0.003928463
"This can be done by smoothing the observed frequencies 7 (Church and Mercer 1993) or by class-based methods (Brown et al. 1991; Pereira and Tishby 1992; Pereira, Tishby, and Lee 1993; Hirschman 1986; Resnik 1992; Brill et al. 1990; Dagan, Marcus, and Markovitch 1993)",o,0,484,o,0,0.9562604,True,0.9562604,0.03810318,0.005636376
"Semantic collocations are harder to extract than cooccurrence patterns--the state of the art does not enable us to find semantic collocations automatically t. This paper however argues that if we take advantage of lexicai paradigmatic behavior underlying the lexicon, we can at least achieve semi-automatic extraction of semantic collocations (see also Calzolari and Bindi (1990) I But note the important work by Hindle \[HindlegO\] on extracting semantically similar nouns based on their substitutability in certain verb contexts",p,1,485,o,0,0.47937834,False,0.47937834,0.47425634,0.04636536
"2 Related Work Recently, several successful attempts have been made at using supervised machine learning for word alignment (Liu et al. , 2005; Taskar et al. , 2005; Ittycheriah and Roukos, 2005; Fraser and Marcu, 2006)",p,1,486,p,1,0.8209903,True,0.16909035,0.8209903,0.009919432
"(Papineni et al. , 2002)",o,0,487,o,0,0.9679576,True,0.9679576,0.02548845,0.0065539707
"For the named entity features, we used a fairly standard feature set, similar to those described in (Finkel et al., 2005)",o,0,488,o,0,0.8755072,True,0.8755072,0.12076497,0.0037278025
"This is a problem with other direct translation models, such as IBM model 1 used as a direct model rather than a channel model (Brown et al., 1993)",n,2,489,n,2,0.5470329,True,0.38040164,0.07256549,0.5470329
"Modeling reordering as the inversion in order of two adjacent blocks is similar to the approach taken by the Inverse Transduction Model (ITG) (Wu, 1997), except that here we are not limited to a binary tree",o,0,490,o,0,0.91524047,True,0.91524047,0.04446813,0.040291477
"While transfer learning was proposed more than a decade ago (Thrun, 1996; Caruana, 1997), its application in natural language processing is still a relatively new territory (Blitzer et al., 2006; Daume III, 2007; Jiang and Zhai, 2007a; Arnold et al., 2008; Dredze and Crammer, 2008), and its application in relation extraction is still unexplored",o,0,491,n,2,0.82360405,False,0.14737596,0.029020043,0.82360405
uch an approach contrasts with the log-linear HMM/Model-4 combination proposed by Och and Ney (2003,o,0,492,o,0,0.9356603,True,0.9356603,0.05656239,0.0077773323
"3 Perceptron Reranking As Collins (2002) observes, perceptron training involves a simple, on-line algorithm, with few iterations typically required to achieve good performance",p,1,493,o,0,0.66827375,False,0.66827375,0.3074556,0.02427066
"In the geometric interpolation above, the weight n controls the relative veto power of the n-gram approximation and can be tuned using MERT (Och, 2003) or a minimum risk procedure (Smith and Eisner, 2006)",o,0,494,o,0,0.95985985,True,0.95985985,0.030839581,0.009300504
"Automatically creating or extending taxonomies for specific domains is then a very interesting area of research (OSullivan et al., 1995; Magnini and Speranza, 2001; Snow et al., 2006)",p,1,495,o,0,0.603578,False,0.603578,0.39007998,0.006342108
"We run Maximum BLEU (Och, 2003) for 25 iterations individually for each system",o,0,496,o,0,0.926712,True,0.926712,0.06382249,0.009465545
ote in passing that the ratio 1.04-1.08/99.7% compares very favourably with other systems; c.f. 3.0/99.3% by POST (Weischedel et al. 1993) and 1.04/97.6% or 1.09/98.6% by de Marcken (1990,o,0,497,p,1,0.47136083,False,0.30009103,0.47136083,0.22854815
"Such transformations are typically denoted as paraphrases in the literature, where a wealth of methods for their automatic acquisition were proposed (Lin and Pantel, 2001; Shinyama et al. , 2002; Barzilay and Lee, 2003; Szpektor et al. , 2004)",o,0,498,o,0,0.82710564,True,0.82710564,0.16689193,0.0060023507
n efficient algorithm for performing this tuning for a larger number of model parameters can be found in Och (2003,p,1,499,p,1,0.8360032,True,0.15862185,0.8360032,0.0053749937
"The algorithm to acquire the lexicon, implemented in the ARIOSTQLEX system, has been extensively described in \[Basili et al, 1993c\]",o,0,500,p,1,0.67184097,False,0.32456395,0.67184097,0.003595032
"They have been employed in word sense disambiguation (Diab and Resnik, 2002), automatic construction of bilingual dictionaries (McEwan et al. , 2002), and inducing statistical machine translation models (Koehn et al. , 2003)",o,0,501,o,0,0.9028507,True,0.9028507,0.0938676,0.0032817267
"However, work in that direction has so far addressed only parse reranking (Collins and Duffy, 2002; Riezler et al. , 2002)",n,2,502,o,0,0.46025088,False,0.46025088,0.09300476,0.44674438
"The translation quality is evaluated by BLEU metric (Papineni et al. , 2002), as calculated by mteval-v11b.pl 6 with case-sensitive matching of n-grams",o,0,503,o,0,0.97081685,True,0.97081685,0.025426803,0.0037563597
"Introduction There has been considerable recent interest in the use of statistical methods for grouping words in large on-line corpora into categories which capture some of our intuitions about the reference of the words we use and the relationships between them (e.g. Brown et al. , 1992; Schiitze, 1993)",o,0,504,o,0,0.8546842,True,0.8546842,0.1422752,0.0030406162
"Further, it has been shown (Weeds et al. 2005; Weeds and Weir 2005) that performance of Lins distributional similarity score decreases more significantly than other measures for low frequency nouns",o,0,505,n,2,0.43125728,False,0.40970415,0.15903848,0.43125728
"In this sense, instead of measuring only the categorial agreement between annotators with the kappa statistic (Carletta, 1996) or the performance of a system in terms of precision/recall, we could take into account the hierarchical organization of the categories or concepts by making use of measures considering the hierarchical distance between two concepts such as proposed by (Hahn and Schnattinger, 1998) or (Madche et al. , 2002)",o,0,506,o,0,0.94456095,True,0.94456095,0.0380371,0.017401904
"Regression has also been used to order sentences in extractive summarization (Biadsy et al., 2008)",o,0,507,o,0,0.92542344,True,0.92542344,0.071465604,0.0031109836
"The core technology of the proposed method, i.e., the automatic evaluation of translations, was developed in research aiming at the efficient development of Machine Translation (MT) technology (Su et al. , 1992; Papineni et al. , 2002; NIST, 2002)",o,0,508,p,1,0.5907042,False,0.40203926,0.5907042,0.007256527
"Besides relative frequencies, lexical weights (Koehn et al., 2003) are widely used to estimate how well the words in f translate the words in e. To do this, one needs first to estimate a lexical translation probability distribution w(e|f) by relative frequency from the same word alignments in the training corpus: w(e|f) = count(f,e)summationtext e count(f,e) (3) Note that a special source NULL token is added to each source sentence and aligned to each unaligned target word",p,1,509,o,0,0.8648534,False,0.8648534,0.12371492,0.011431676
"Obviously, these productions are not in the normal form of an ITG, but with the method described in (Wu, 1997), they can be normalized",o,0,510,o,0,0.88459086,True,0.88459086,0.08961964,0.02578954
"Our approach to statistical machine translation differs from the model proposed in (Brown et al. , 1993) in that:  We compute the joint model P(Ws, WT) from the bilanguage corpus to account for the direct mapping of the source sentence Ws into the target sentence I?VT that is ordered according to the  source language word order",o,0,511,o,0,0.91630876,True,0.91630876,0.04350997,0.040181242
"1 Introduction Chinese Word Segmentation (CWS) has been witnessed a prominent progress in the last three Bakeoffs (Sproat and Emerson, 2003), (Emerson, 2005), (Levow, 2006)",p,1,512,p,1,0.93210214,True,0.059817776,0.93210214,0.00808003
"5 Parsing experiments 5.1 Data and setup We used the standard partitions of the Wall Street Journal Penn Treebank (Marcus et al. , 1993); i.e., sections 2-21 for training, section 22 for development and section 23 for evaluation",o,0,513,o,0,0.96966124,True,0.96966124,0.026579628,0.0037592235
"It is also possible to train statistical models using unlabeled data with the expectation maximization algorithm (Cutting et al. , 1992)",o,0,514,o,0,0.9527809,True,0.9527809,0.042110845,0.0051083136
"First, several of the best-performing parsers on the WSJ treebank (e.g. , Ratnaparkhi 1997; Charniak 1997, 2000; Collins 1997, 1999; Henderson 2003) are cases of history-based models",p,1,515,p,1,0.8397421,True,0.13363099,0.8397421,0.026626926
"4 Structural Correspondence Learning SCL (Structural Correspondence Learning) (Blitzer et al., 2006; Blitzer et al., 2007; Blitzer, 2008) is a recently proposed domain adaptation technique which uses unlabeled data from both source and target domain to learn correspondences between features from different domains",o,0,516,o,0,0.79385906,True,0.79385906,0.20328343,0.0028575163
"Independently, in AI an effort arose to encode large amounts of commonsense knowledge (Hayes, 1979; Hobbs and Moore, 1985; Hobbs et al. 1985)",o,0,517,o,0,0.9086526,True,0.9086526,0.08631116,0.0050361925
"Unknown words were not identified in (McClosky et al. , 2006a) as a useful predictor for the benefit of self-training",o,0,518,o,0,0.57441324,True,0.57441324,0.094114415,0.33147234
"Furthermore, we use averaged weights (Collins, 2002; Freund and Schapire, 1999) in Algorithm 1",o,0,519,o,0,0.9619946,True,0.9619946,0.035032097,0.0029734173
"It was later applied by (Dunning, 1993) as a way to determine if a sequence of N words (Ngram) came from an independently distributed sample",o,0,520,o,0,0.9253546,True,0.9253546,0.07031805,0.004327295
"These tags are drawn from a tagset which is constructed by extending each argument label by three additional symbols a11 a24 a35 a24a4a12, following (Ramshaw and Marcus, 1995)",o,0,521,o,0,0.96470314,True,0.96470314,0.031790316,0.003506551
"3 GM Representation of IBM MT Models In this section we present a GM representation for IBM model 3 (Brown et al. , 1993) in fig",o,0,522,o,0,0.95771104,True,0.95771104,0.03342558,0.008863387
"3ThePOS taggers The two POS taggers used in the experiments are TNT, a publicly available Markov model tagger (Brants, 2000), and a reimplementation of the maximum entropy (ME) tagger MXPOST (Ratnaparkhi, 1996)",o,0,523,o,0,0.94543487,True,0.94543487,0.047979772,0.0065853545
"The final SMT system performance is evaluated on a uncased test set of 3071 sentences using the BLEU (Papineni et al., 2002), NIST (Doddington, 2002) and METEOR (Banerjee and Lavie, 2005) scores",o,0,524,o,0,0.9527021,True,0.9527021,0.042692218,0.004605591
"This program differs from earlier work in its almost complete lack of hand-crafting, relying instead on a very small corpus of Penn Wall Street Journal Tree-bank text (Marcus et al. , 1993) that has been marked with co-reference information",o,0,525,o,0,0.5547761,True,0.5547761,0.087907,0.3573169
"2.2 Maximum Entropy Models Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as 928 log-linear and exponential learning models, provide a general purpose machine learning technique for classification and prediction which has been successfully applied to natural language processing including part of speech tagging, named entity recognition etc. Maximum entropy models can integrate features from many heterogeneous information sources for classification",p,1,526,p,1,0.8020597,True,0.1923754,0.8020597,0.0055649052
"As with conventional smoothing methods (Koehn et al. , 2003; Foster et al. , 2006), triangulation increases the robustness of phrase translation estimates",o,0,527,o,0,0.4378791,True,0.4378791,0.23917033,0.32295063
"Like Haghighi and Klein (2007), we give our model information about the basic types of pronouns in English",o,0,528,o,0,0.9429737,True,0.9429737,0.053224914,0.0038013887
"82 Chen and Chang Topical Clustering Dolan (1994) maintains the position that intersense relations are mostly idiosyncratical, thereby making it difficult to characterize them in a general way so as to identify them",o,0,529,n,2,0.46563226,False,0.45953384,0.074833915,0.46563226
"A similar soft projection of dependencies was used in supervised machine translation by Smith and Eisner (2006), who used a source sentences dependency paths to bias the generation of its translation",o,0,530,o,0,0.9601754,True,0.9601754,0.03603617,0.0037884603
"Some methods parse two flat strings at once using a bitext grammar (Wu, 1997)",o,0,531,o,0,0.9632199,True,0.9632199,0.03306031,0.0037196928
"This results in two forbidden alignment structures, shown in Figure 1, called inside-out transpositions in (Wu, 1997)",o,0,532,o,0,0.94130784,True,0.94130784,0.044620704,0.014071412
"A pipage approach (Ageev and Sviridenko, 2004) has been proposed for MCKP, but we do not use this algorithm, since it requires costly partial enumeration and solutions to many linear relaxation problems",o,0,533,n,2,0.8009475,False,0.1639986,0.03505398,0.8009475
"We first added sister-head dependencies for NPs (following Collinss (1997) original proposal) and then for PPs, which are flat in Negra, and thus similar in structure to NPs (see Section 2.2)",o,0,534,o,0,0.95037913,True,0.95037913,0.041252635,0.0083682025
"are combined in a log-linear model to obtainthescoreforthetranslationeforaninputsentence f: score(e,f) = exp summationdisplay i i hi(e,f) (1) The weights of the components i are set by a discriminative training method on held-out development data (Och, 2003)",o,0,535,o,0,0.96136063,True,0.96136063,0.034778994,0.0038604024
"The full model yields a stateof-the-art BLEU (Papineni et al., 2002) score of 0.8506 on Section 23 of the CCGbank, which is to our knowledge the best score reported to date 410 using a reversible, corpus-engineered grammar",p,1,536,p,1,0.6541121,True,0.23678806,0.6541121,0.10909981
"(Cutting et al. , 1992; Feldweg, 1995)), the tagger for grammatical functions works with lexical (1) Selbst besucht ADV VVPP himself visited hat Peter Sabine VAFIN NE NE has Peter Sabine 'Peter never visited Sabine himself' l hie ADV never Figure 2: Example sentence and contextual probability measures PO.(') depending on the category of a mother node (Q)",o,0,537,o,0,0.9551774,True,0.9551774,0.034902934,0.009919616
"1 Introduction Machine translation systems based on probabilistic translation models (Brown et al. , 1993) are generally trained using sentence-aligned parallel corpora",o,0,538,o,0,0.95661765,True,0.95661765,0.040593736,0.002788526
"Therefore, structure divergence and parse errors are two of the major issues that may largely compromise the performance of syntax-based SMT (Zhang et al., 2008a; Mi et al., 2008)",o,0,539,o,0,0.6298803,True,0.6298803,0.2555219,0.11459776
his second expression is similar to that used in [Marcus 1995,o,0,540,o,0,0.96097696,True,0.96097696,0.033207543,0.00581551
"Tillmann and Zhang (2006), Liang et al",o,0,541,o,0,0.95926136,True,0.95926136,0.029872112,0.01086661
"In the absence of an annotated corpus, dependencies can be derived by other means, e.g. part413 of-speech probabilities can be approximated from a raw corpus as in (Cutting et al. , 1992), word-sense dependencies can be derived as definition-based similarities, etc. Label dependencies are set as weights on the arcs drawn between corresponding labels",o,0,542,o,0,0.9434999,True,0.9434999,0.048184272,0.008315747
"5 Discussion As stated above, we aim to build an unsupervised generative model for named entity clustering, since such a model could be integrated with unsupervised coreference models like Haghighi and Klein (2007) for joint inference",o,0,543,o,0,0.94523543,True,0.94523543,0.05081005,0.0039545684
"While in this paper we evaluated our framework on the discovery of concepts, we have recently proposed fully unsupervised frameworks for the discovery of different relationship types (Davidov et al., 2007; Davidov and Rappoport, 2008a; Davidov and Rappoport, 2008b)",o,0,544,o,0,0.928438,True,0.928438,0.062262245,0.009299755
"http://duc.nist.gov</title> <date>2004</date> <journal>Journal of the Association for Computing Machinery</journal> <volume>16</volume> <pages>264--285</pages> <contexts> <context> (Voorhees and Harman, 1999), Message Understanding Conferences (MUC) (Chinchor et al, 1993), TIPSTER SUMMAC Text Summarization Evaluation (Mani et al, 1998), Document Understanding Conference (DUC) (DUC, 2004), and Text Summarization Challenge (TSC) (Fukushima and Okumura, 2001), have attested the importance of this topic",o,0,545,p,1,0.59848326,False,0.39096472,0.59848326,0.010551971
"Automated evaluation metrics that rate system behaviour based on automatically computable properties have been developed in a number of other fields: widely used measures include BLEU (Papineni et al., 2002) for machine translation and ROUGE (Lin, 2004) for summarisation, for example",o,0,546,p,1,0.8913335,False,0.105884366,0.8913335,0.0027820482
"We used a bottom-up, CKY-style decoder that works with binary xRs rules obtained via a synchronous binarization procedure (Zhang et al. , 2006)",o,0,547,o,0,0.9511919,True,0.9511919,0.04537082,0.0034372404
"1 Introduction Conditional Maximum Entropy models have been used for a variety of natural language tasks, including Language Modeling (Rosenfeld, 1994), partof-speech tagging, prepositional phrase attachment, and parsing (Ratnaparkhi, 1998), word selection for machine translation (Berger et al. , 1996), and finding sentence boundaries (Reynar and Ratnaparkhi, 1997)",o,0,548,o,0,0.92346495,True,0.92346495,0.07426391,0.0022712273
"In Step 3, a simple perceptron update (Collins, 2002) is performed",o,0,549,o,0,0.9438767,True,0.9438767,0.049910787,0.0062124664
"Importantly, this Bayesian approach facilitates the incorporation of sparse priors that result in a more practical distribution of tokens to lexical categories (Johnson, 2007)",o,0,550,p,1,0.72722906,False,0.24803202,0.72722906,0.024739029
"We discriminatively trained our parser in an on-line fashion using a variant of the voted perceptron (Collins, 2002; Collins and Roark, 2004; Crammer and Singer, 2003)",o,0,551,o,0,0.9614426,True,0.9614426,0.03477135,0.0037860586
"4 Extended Minimum Error Rate Training Minimum error rate training (Och, 2003) is widely used to optimize feature weights for a linear model (Och and Ney, 2002)",p,1,552,p,1,0.79625815,True,0.20034495,0.79625815,0.0033969984
"The triplet lexicon model presented in this work can also be interpreted as an extension of the standard IBM model 1 (Brown et al., 1993) with an additional trigger",o,0,553,o,0,0.89611155,True,0.89611155,0.055388585,0.048499864
ollins (2002) proposed a Perceptron like learning algorithm to solve sequence classification in the traditional left-to-right orde,o,0,554,o,0,0.94717765,True,0.94717765,0.04792906,0.0048932745
"Nevertheless, EM sometimes fails to find good parameter values.2 The reason is that EM tries to assign roughly the same number of word tokens to each of the hidden states (Johnson, 2007)",o,0,555,n,2,0.56199455,False,0.36161286,0.076392666,0.56199455
"alpha 0 0.1 0.2 0.3 0.4 0.5 Freq=2 13555 13093 12235 11061 10803 10458 Freq=3 4203 3953 3616 3118 2753 2384 Freq=4 1952 1839 1649 1350 1166 960 Freq=5 1091 1019 917 743 608 511 Freq>2 2869 2699 2488 2070 1666 1307 TOTAL 23670 22603 20905 18342 16996 15620 alpha 0.6 0.7 0.8 0.9 1.0 Freq=2 10011 9631 9596 9554 9031 Freq=3 2088 1858 1730 1685 1678 Freq=4 766 617 524 485 468 Freq=5 392 276 232 202 189 Freq>2 1000 796 627 517 439 TOTAL 14257 13178 12709 12443 11805 Table 7: Number of extracted MWUs by frequency 6.2 Qualitative Analysis As many authors assess (Frank Smadja, 1993; John Justeson and Slava Katz, 1995), deciding whether a sequence of words is a multiword unit or not is a tricky problem",o,0,556,o,0,0.9660533,True,0.9660533,0.02947295,0.004473714
"In the proposed method, the statistical machine translation (SMT) (Brown et al., 1993) is deeply incorporated into the question answering process, instead of using the SMT as the preprocessing before the mono-lingual QA process as in the previous work",o,0,557,o,0,0.6943533,True,0.6943533,0.062262528,0.24338414
"For example, minimum entropy regularization (Grandvalet and Bengio, 2004; Jiao et al., 2006), aims to maximize the conditional likelihood of labeled data while minimizing the conditional entropy of unlabeled data: summationdisplay i logp(y(i)|x(i)) 122bardblbardbl2H(y|x) (3) This approach generally would result in sharper models which can be data-sensitive in practice",o,0,558,o,0,0.707412,True,0.707412,0.27259848,0.019989498
"To prune away those pairs, we used the log-likelihood-ratio algorithm (Dunning, 1993) to compute the degree of association between the verb and the noun in each pair",o,0,559,o,0,0.96052843,True,0.96052843,0.03568166,0.003789853
"By increasing the size of the basic unit of translation, phrase-based machine translation does away with many of the problems associated with the original word-based formulation of statistical machine translation (Brown et al. , 1993), in particular:  The Brown et al",n,2,560,n,2,0.6001518,True,0.2902853,0.10956292,0.6001518
"Charniak (1997) and Johnson (1998) annotated each node with its parent and grandparent nonterminals, to more precisely reflect its outside context",o,0,561,o,0,0.95474607,True,0.95474607,0.034062378,0.01119152
"A conditional maximum entropy model q(xjw) for p has the parametric form (Berger et al. , 1996; Chi, 1998; Johnson et al. , 1999): q(xjw) = exp T f (x) y2Y(w) exp(T f (y)) (1) where  is a d-dimensional parameter vector and T f (x) is the inner product of the parameter vector and a feature vector",o,0,562,o,0,0.97309476,True,0.97309476,0.023416262,0.0034890242
he work most similar in spirit to ours that of Turney (2002,o,0,563,o,0,0.8722636,True,0.8722636,0.11291757,0.014818796
"3 Automatic Evaluation of MT Quality We utilize BLEU (Papineni et al. , 2002) for the automatic evaluation of MT quality in this paper",o,0,564,o,0,0.9688448,True,0.9688448,0.027478978,0.0036762224
"On the other hand, the thesaurus-based method of Yarowsky (1992) may suffer from loss of information (since it is semi-class-based) as well as data sparseness (since H Classes used in Resnik (1992) are based on the WordNet taxonomy while classes of Brown et al",o,0,565,o,0,0.55168414,True,0.55168414,0.088274926,0.360041
"Ranking algorithms, such as Kleinbergs HITS algorithm (Kleinberg, 1999) or Googles PageRank (Brin and Page, 1998), have been traditionally and successfully used in Web-link analysis (Brin and Page, 1998), social networks, and more recently in text processing applications (Mihalcea and Tarau, 2004), (Mihalcea et al. , 2004), (Erkan and Radev, 2004)",o,0,566,p,1,0.9293707,False,0.066474095,0.9293707,0.0041551623
"DeNero and Klein (2007) focus on alignment and do not present MT results, while May and Knight (2007) takesthesyntacticre-alignmentasaninputtoanEM algorithm where the unaligned target words are insertedintothetemplatesandminimumtemplatesare combinedintobiggertemplates(Galleyetal.,2006)",n,2,567,o,0,0.918063,False,0.918063,0.030181432,0.051755648
"This can be done in a supervised (Yarowsky, 1994), a semi-supervised (Yarowsky, 1995) or a fully unsupervised way (Pantel & Lin, 2002)",o,0,568,o,0,0.9386313,True,0.9386313,0.05202173,0.0093469275
"The mutual information Ml(x,y) is defined as the following formula (Church and Hanks, 1990)",o,0,569,o,0,0.96786994,True,0.96786994,0.027129857,0.005000174
"(Hakkani-Tur et al. , 2000)), and Basque (Ezeiza et al. , 1998), which pose quite different and in the end less severe problems, there have been attempts at solving this problem for some of the highly inflectional European languages, such as (Daelemans et al. , 1996), (Erjavec et al. , 1999) (Slovenian), (Hajic and Hladka, 1997), (Hajic and Hladka, 1998) (Czech) and (Hajic, 2000) (five Central and Eastern European languages), but so far no system has reached in the absolute terms a performance comparable to English tagging (such as (Ratnaparkhi, 1996)), which stands around or above 97%",p,1,570,o,0,0.518276,False,0.518276,0.2582305,0.22349352
"Our baseline uses Giza++ alignments (Och and Ney, 2003) symmetrized with the grow-diag-final-and heuristic (Koehn et al., 2003)",o,0,571,o,0,0.9729221,True,0.9729221,0.023414964,0.0036629643
"6.1.2 ROUGE evaluation Table 4 presents ROUGE scores (Lin, 2004) of each of human-generated 250-word surveys against each other",o,0,572,o,0,0.9602465,True,0.9602465,0.033657566,0.00609592
"First, we use the standard approach of greedily assigning each of the learned classes to the POS tag with which it has the greatest overlap, and then computing tagging accuracy (Smith and Eisner, 2005; Haghighi and Klein, 2006).8 Additionally, we compute the mutual information of the learned clusters with the gold tags, and we compute the cluster F-score (Ghosh, 2003)",o,0,573,o,0,0.87903285,True,0.87903285,0.09824025,0.022726892
"It differs from the many approaches where (1) is defined by a stochastic synchronous grammar (Wu, 1997; Alshawi et al. , 2000; Yamada and Knight, 2001; Eisner, 2003; Gildea, 2003; Melamed, 2004) and from transfer-based systems defined by context-free grammars (Lavie et al. , 2003)",o,0,574,o,0,0.9414359,True,0.9414359,0.047077764,0.011486313
"The production weights are estimated either by heuristic counting (Koehn et al., 2003) or using the EM algorithm",o,0,575,o,0,0.9699673,True,0.9699673,0.02687845,0.0031542373
"1 Introduction Early works, (Gale and Church, 1993; Brown et al. , 1993), and to a certain extent (Kay and R6scheisen, 1993), presented methods to ex~.:'~.ct bi'_.'i~gua",o,0,576,o,0,0.9498228,True,0.9498228,0.046601232,0.0035759974
"Bayesian approaches can also improve performance (Goldwater and Griffiths, 2007; Johnson, 2007; Kurihara and Sato, 2006)",o,0,577,p,1,0.584054,False,0.38944396,0.584054,0.026501995
"The features used in NLG2 are described in the next section, and the feature weights aj, obtained from the Improved Iterative Scaling algorithm (Berger et al. , 1996), are set to maximize the likelihood of the training data",o,0,578,o,0,0.924433,True,0.924433,0.06783783,0.007729165
"Li and Roth demonstrated that their shallow parser, trained to label shallow constituents along the lines of the well-known CoNLL2000 task (Sang and Buchholz, 2000), outperformed the Collins parser in correctly identifying these constituents in the Penn Wall Street Journal (WSJ) Treebank (Marcus et al. , 1993)",o,0,579,n,2,0.56225514,False,0.2396264,0.19811842,0.56225514
"2.4 Maximum Entropy Classifier Maximum Entropy Models (Berger et al., 1996) seek to maximise the conditional probability of classes, given certain observations (features)",o,0,580,o,0,0.90675634,True,0.90675634,0.08032216,0.01292156
"5Since the test data of (Svore et al., 2007) is not publicly available we were unable to carry out a more detailed comparison",n,2,581,n,2,0.8999854,True,0.08227815,0.01773643,0.8999854
"This is known as cost-based abduction (Hobbs et al. , 1988)",o,0,582,o,0,0.94864994,True,0.94864994,0.040240888,0.011109208
"Section 4 describes the online training procedure and compares it to the well known perceptron training algorithm (Collins, 2002)",o,0,583,p,1,0.7913079,False,0.17171827,0.7913079,0.03697384
"In our framework, we employ a simple HMM-based tagger, where the most probable tag sequence, a29a30, given the words, a31, is output (Weischedel et al. , 1993): a29 a30 a20a22a32a34a33a36a35a38a37a39a32a41a40 a42 a43a45a44 a30a47a46 a31a49a48a17a20a22a32a34a33a50a35a38a37a39a32a41a40 a42 a43a45a44 a31 a46a30 a48 a43a51a44 a30 a48 Since we do not have enough data which is manually tagged with part-of-speech tags for our applications, we used Penn Treebank (Marcus et al. , 1994) as our training set",o,0,584,o,0,0.93959326,True,0.93959326,0.055674337,0.004732395
"Note, that for our example the effect of the uniform additional conditioning on mother grammatical function has the same effect as the generation grammar transform of (Cahill and van Genabith, 2006), but without the need for the gramF-Struct Feats Grammar Rules {PRED=PRO,NUM=SG PER=3, GEN=FEM, SUBJ} PRP(=)  she {PRED=PRO,NUM=SG PER=3, GEN=FEM, OBJ} PRP(=)  her Table 7: Lexical item rules",o,0,585,o,0,0.9148351,True,0.9148351,0.038787547,0.046377305
"Further work will look at how to integrate probabilities such as p(clv, r) into a model of dependency structure, similar to that of Collins (1996) and Collins (1997), which can be used \['or parse selection",o,0,586,o,0,0.94345963,True,0.94345963,0.053070642,0.003469758
"Discriminative, context-specific training seems to yield a better set of similar predicates, e.g. the highest-ranked contexts for DSPcooc on the verb join,3 lead 1.42, rejoin 1.39, form 1.34, belong to 1.31, found 1.31, quit 1.29, guide 1.19, induct 1.19, launch (subj) 1.18, work at 1.14 give a better SIMS(join) for Equation (1) than the top similarities returned by (Lin, 1998a): participate 0.164, lead 0.150, return to 0.148, say 0.143, rejoin 0.142, sign 0.142, meet 0.142, include 0.141, leave 0.140, work 0.137 Other features are also weighted intuitively",o,0,587,n,2,0.3990117,False,0.3602131,0.24077521,0.3990117
"Either pruning (Stolcke, 1998; Church et al., 2007) or lossy randomizing approaches (Talbot and Brants, 2008) may result in a compact representation for the application run-time",o,0,588,o,0,0.91098386,True,0.91098386,0.08305522,0.005960941
"1 Introduction There is a pressing need for a consensus on a taskoriented level of semantic representation that can enable the development of powerful new semantic analyzers in the same way that the Penn Treebank (Marcus et al. , 1993) enabled the development of statistical syntactic parsers (Collins, 1999; Charniak, 2001)",p,1,589,p,1,0.51915884,True,0.4708566,0.51915884,0.009984541
"After that, we used three types of methods for performing a symmetrization of IBM models: intersection, union, and refined methods (Och and Ney, 2003)",o,0,590,o,0,0.93527657,True,0.93527657,0.05962988,0.0050934306
"These 30 questions are determined by growing a classification tree on the word vocabulary as described in (Brown et al. , 1992)",o,0,591,o,0,0.9659516,True,0.9659516,0.029272655,0.0047757137
"First, it recognizes non-recursive Base Noun Phrase (BNP) (our specifications for BNP resemble those in Ramshaw and Marcus 1995)",o,0,592,o,0,0.9670564,True,0.9670564,0.026433904,0.006509614
"In the Penn Treebank (Marcus et al. , 1993), null elements, or empty categories, are used to indicate non-local dependencies, discontinuous constituents, and certain missing elements",o,0,593,o,0,0.96872455,True,0.96872455,0.024645481,0.006630003
"Previous studies (Abney, 1997; Johnson et al. , 1999; Riezler et al. , 2000; Malouf and van Noord, 2004; Kaplan et al. , 2004; Miyao and Tsujii, 2005) defined a probabilistic model of unification-based grammars including HPSG as a log-linear model or maximum entropy model (Berger et al. , 1996)",o,0,594,o,0,0.97128403,True,0.97128403,0.02470758,0.0040083695
"1 Introduction Since 1995, a few statistical parsing algorithms (Magerman, 1995; Collins, 1996 and 1997; Charniak, 1997; Rathnaparki, 1997) demonstrated a breakthrough in parsing accuracy, as measured against the University of Pennsylvania TREEBANK as a gold standard",o,0,595,p,1,0.87094593,False,0.123104915,0.87094593,0.0059491703
"For the word alignment, we apply standard techniques derived from statistical machine translation using the well-known IBM alignment models (Brown et al. , 1993) implemented in the opensource tool GIZA++ (Och, 2003)",p,1,596,p,1,0.6532122,True,0.3382208,0.6532122,0.008567
"Among these advances, forest-based modeling (Mi et al., 2008; Mi and Huang, 2008) and tree sequence-based modeling (Liu et al., 2007; Zhang et al., 2008a) are two interesting modeling methods with promising results reported",p,1,597,p,1,0.88458836,True,0.10871033,0.88458836,0.006701356
"This is a particularly exciting area in computational linguistics as evidenced by the large number of contributions in these special issues: Biber (1993), Brent (1993), Hindle and Rooth (this issue), Pustejovsky et al",o,0,598,p,1,0.88065696,False,0.10896956,0.88065696,0.0103735775
"Many statistical taggers and parsers have been trained on it, e.g. Ramshaw and Marcus (1995), Srinivas (1997) and Alshawi and Carter (1994)",o,0,599,o,0,0.9027321,True,0.9027321,0.09285246,0.004415466
"3 A Categorization of Block Styles In (Brown et al. , 1993), multi-word cepts (which are realized in our block concept) are discussed and the authors state that when a target sequence is sufficiently different from a word by word translation, only then should the target sequence should be promoted to a cept",o,0,600,o,0,0.9310573,True,0.9310573,0.058730204,0.010212633
"Measures of attributional similarity have been studied extensively, due to their applications in problems such as recognizing synonyms (Landauer and Dumais 1997), information retrieval (Deerwester et al. 1990), determining semantic orientation (Turney 2002), grading student essays (Rehder et al. 1998), measuring textual cohesion (Morris and Hirst 1991), and word sense disambiguation (Lesk 1986)",o,0,601,p,1,0.7185473,False,0.27729532,0.7185473,0.0041573914
"However, evaluations on the widely used WSJ corpus of the Penn Treebank (Marcus et al. , 1993) show that the accuracy of these parsers still lags behind the state-of-theart",p,1,602,n,2,0.6517426,False,0.18777885,0.16047856,0.6517426
"2 We illustrate the rule extraction with an example from the tree-to-tree translation model based on tree sequence alignment (Zhang et al, 2008a) without losing of generality to most syntactic tree based models",o,0,603,o,0,0.83381176,True,0.83381176,0.12515894,0.0410294
"For example, 10 million words of the American National Corpus (Ide et al. , 2002) will have manually corrected POS tags, a tenfold increase over the Penn Treebank (Marcus et al. , 1993), currently used for training POS taggers",n,2,604,n,2,0.6458108,True,0.27803114,0.076158084,0.6458108
"Automatic methods for this often make use of lexicons of words tagged with positive and negative semantic orientation (Turney, 2002; Wilson et al., 2005; Pang and Lee, 2008)",o,0,605,o,0,0.96568364,True,0.96568364,0.03143461,0.0028817079
"(Grenager et al. , 2005) and (Haghighi and Klein, 2006) also report results for semi-supervised learning for these domains",o,0,606,o,0,0.9243266,True,0.9243266,0.0654948,0.010178488
"Although some early systems for web-page analysis induce rules at character-level (e.g., such as WIEN (Kushmerick et al., 1997) and DIPRE (Brin, 1998)), most recent approaches for set expansion have used either tokenized and/or parsed free-text (Carlson et al., 2009; Talukdar et al., 2006; Snow et al., 2006; Pantel and Pennacchiotti, 2006), or have incorporated heuristics for exploiting HTML structures that are likely to encode lists and tables (Nadeau et al., 2006; Etzioni et al., 2005)",o,0,607,o,0,0.92452925,True,0.92452925,0.07192139,0.0035494217
"Cutting et al. 1992), local rules (e.g. Hindle 1989) and neural networks (e.g. Schmid 1994)",o,0,608,o,0,0.96459955,True,0.96459955,0.02798515,0.0074153263
"Our technique is based on a novel Gibbs sampler that draws samples from the posterior distributionofaphrase-basedtranslationmodel(Koehn et al., 2003) but operates in linear time with respect to the number of input words (Section 2)",o,0,609,o,0,0.9396108,True,0.9396108,0.056372937,0.0040164064
"We use the log likelihood ratio (LLR) (Dunning 1993) given by -2log 2 (H o (p;k 1,n 1,k 2,n 2 )/H a (p 1,p 2 ;n 1,k 1,n 2,k 2 )) LLR measures the extent to which a hypothesized model of the distribution of cell counts, H a, differs from the null hypothesis, H o (namely, that the percentage of documents containing this term is the same in both corpora)",o,0,610,o,0,0.9603361,True,0.9603361,0.028964259,0.010699672
" prime 1 1 1 0.5 0.5 1 0.5 0.5 0.1 0.1 0.1 0.0001 0.0001 0.1 0.0001 0.0001 Further, we ran each setting of each estimator at least 10 times (from randomly jittered initial starting points) for at least 1,000 iterations, as Johnson (2007) showed that some estimators require many iterations to converge",o,0,611,o,0,0.72643256,True,0.72643256,0.102503166,0.17106433
"It was found to produce automated scores, which strongly correlate with human judgements about translation fluency (Papineni et al. , 2002)",p,1,612,o,0,0.61096376,False,0.61096376,0.37566942,0.013366774
Note that conditioning on the rules parent is needed to disallow the structure [NP [NP PP] PP]; see Johnson [1997] for further discussion,o,0,613,o,0,0.89603853,True,0.89603853,0.063004,0.040957473
eNero and Klein (2007) use a syntaxbased distance in an HMM word alignment model to favor syntax-friendly alignment,o,0,614,o,0,0.9193806,True,0.9193806,0.07132905,0.009290326
"Entropy, used in some part-of-speech tagging systems (Ratnaparkhi, 1996), is a measure of how much information is necessary to separate data",o,0,615,o,0,0.92316306,True,0.92316306,0.06712725,0.009709633
"Using a vector-based topic identification process (Salton, 1971; Chu-Carroll and Carpenter, 1999), these keywords are used to determine a set of likely values (including null) for that attribute",o,0,616,o,0,0.9717495,True,0.9717495,0.02423243,0.0040181307
"A similar approach was taken in (Weischedel et al. , 1993) where an unknown word was guessed given the probabilities for an unknown word to be of a particular POS, its capitalisation feature and its ending",o,0,617,o,0,0.95368904,True,0.95368904,0.040776912,0.00553407
"For example, factored translation models (Koehn and Hoang, 2007) retain the simplicity of phrase-based SMT while adding the ability to incorporate additional features",p,1,618,o,0,0.67502284,False,0.67502284,0.28652132,0.0384559
"Furthermore, good results have been produced in other areas of NLP research using maximum entropy techniques (Berger et al. , 1996; Koeling, 2001; Ratnaparkhi, 1997a)",p,1,619,p,1,0.7944832,True,0.19689533,0.7944832,0.008621459
"Information extraction approaches that infer labeled relations either require substantial handcreated linguistic or domain knowledge, e.g., (Craven and Kumlien 1999) (Hull and Gomez 1993), or require human-annotated training data with relation information for each domain (Craven et al. 1998)",o,0,620,o,0,0.8864853,True,0.8864853,0.047582254,0.06593251
"This score measures the precision of unigrams, bigrams, trigrams and fourgrams with respect to a reference translation with a penalty for too short sentences (Papineni et al. , 2002)",o,0,621,o,0,0.895953,True,0.895953,0.07099501,0.03305204
"The second one needs no labeled data for the new domain (Blitzer et al., 2007; Tan et al., 2007; Andreevskaia and Bergler, 2008; Tan et al., 2008; Tan et al., 2009)",o,0,622,o,0,0.9030689,True,0.9030689,0.036767967,0.060163062
"3.4) 3.1 Probabilistic model In the probabilistic formulation (Snow et al., 2006), the task of learning taxonomies from a corpus is seen as a probability maximization problem",o,0,623,o,0,0.94248736,True,0.94248736,0.049837515,0.007675057
"Unlexicalized parsers, on the other hand, achieved accuracies almost equivalent to those of lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al. , 2005; Petrov et al. , 2006)",o,0,624,o,0,0.6160573,True,0.6160573,0.12001272,0.26392993
"The query tions, the syntax, semantics, and abstract knowledge representation have type declarations (Crouch and King, 2008) which help to detect malformed representations",o,0,625,o,0,0.9410199,True,0.9410199,0.05329649,0.0056836256
"The lexicalized PCFG that sits behind Model 2 of (Collins, 1997) has rules of the form P ~ LnLn-I""""'"""" LIHRI"""""""".Rn-IRn (1) S(will-MD) NP(AppI,~NNP) VP(wilI-MD) NNP I Apple MD VP (buy-VB) VB PRT(out-RP) NP(Microsoft--NNP) I \[ I buy RP NNP I I out Microsoft Figure 1: A sample sentence with parse tree",o,0,626,o,0,0.9640194,True,0.9640194,0.03116285,0.004817636
"Expectation Evaluation is the soul of parameter estimation (Brown et al. , 1993), (Al-Onaizan et al. , 1999)",o,0,627,o,0,0.8709575,True,0.8709575,0.116954,0.012088438
"Several frameworks for finding translation equivalents or translation units in machine translation, such as \[Chang and Su 1993, Isabelle et al.1993\] and other example-based MT approaches, might be used to select the preferred mapping",o,0,628,o,0,0.9607742,True,0.9607742,0.03483703,0.004388851
"For example, (Brown et al., 1993) suggested two different methods: using only the alignment with the maximum probability, the so-called Viterbi alignment, or generating a set of alignments by starting from the Viterbi alignment and making changes, which keep the alignment probability high",o,0,629,o,0,0.9338886,True,0.9338886,0.055164337,0.01094703
"(1991), Yarowsky (1995) and others",o,0,630,o,0,0.96862185,True,0.96862185,0.024451097,0.006927123
"In the nal step, we score our translations with 4-gram BLEU (Papineni et al. , 2002)",o,0,631,o,0,0.95904934,True,0.95904934,0.03445691,0.0064936536
"(Macken et al., 2008) showed that the results for French-English were competitive to state-of-the-art alignment systems",p,1,632,p,1,0.71886307,True,0.23372278,0.71886307,0.04741416
"For subproblem (a), we have devised a new method, based on LPR, which has some good properties not shared by the methods proposed so far (Alshawi and Carter, 1995; Chang et al. , 1992; Collins and Brooks, 1995; Hindle and Rooth, 1991; Ratnaparkhi et al. , 1994; Resnik, 1993)",o,0,633,o,0,0.4899399,True,0.4899399,0.21409115,0.29596892
"MET (Och, 2003) iterative parameter estimation under IBM BLEU is performed on the development set",o,0,634,o,0,0.9656075,True,0.9656075,0.030407479,0.003984943
he feasibility of such post-parse deepening (for a statistical parser) is demonstrated by Cahill et al (2004,o,0,635,o,0,0.66357815,True,0.66357815,0.3230865,0.013335373
"Then the initial precision is 1(Yarowsky, 1995), citing (Yarowsky, 1994), actually uses a superficially different score that is, however, a monotone transform of precision, hence equivalent to precision, since it is used only for sorting",o,0,636,o,0,0.89877707,True,0.89877707,0.051933333,0.04928968
"We implemented these models within an maximum entropy framework (Berger et al. , 1996; Ristad, 1997; Ristad, 1998)",o,0,637,o,0,0.9572025,True,0.9572025,0.034628566,0.008168972
"The words we want to aggregate for text analysis are not rigorous synonyms, but the role is the same, so we have to consider the syntactic relation based on the assumptions that words with the same role tend to modify or be modified by similar words (Hindle, 1990; Strzalkowski, 1992)",o,0,638,o,0,0.95393175,True,0.95393175,0.03081418,0.015254124
illmann and Zhang (2006) present a procedure to directly optimize the global scoring function used by a phrasebased decoder on the accuracy of the translation,o,0,639,o,0,0.92623824,True,0.92623824,0.06604011,0.0077216043
"This algorithm is proved to converge (i.e. , there are no more updates) in the separable case (Collins, 2002a).1 Thatis,ifthereexistweightvectorU (with ||U|| = 1),  (> 0), and R (> 0) that satisfy: i,y  Y|xi| (xi,yi)U (xi,y)U  , i,y  Y|xi| ||(xi,yi)(xi,y)||  R, the number of updates is at most R2/2",o,0,640,o,0,0.9140842,True,0.9140842,0.07521141,0.010704424
"The trees may be learned directly from parallel corpora (Wu, 1997), or provided by a parser trained on hand-annotated treebanks (Yamada and Knight, 2001)",o,0,641,o,0,0.95560366,True,0.95560366,0.040452674,0.0039436584
"However, in the coarse-grained task, the sense inventory was first clustered semi-automatically with each cluster representing an equivalence class over senses (Navigli, 2006)",o,0,642,o,0,0.939283,True,0.939283,0.051454496,0.009262521
"Transformation-based error-driven learning has been applied to a number of natural language problems, including part of speech tagging, prepositional phrase attachment disambiguation, speech generation and syntactic parsing \[Brill, 1992; Brill, 1994; Ramshaw and Marcus, 1994; Roche and Schabes, 1995; Brill and Resnik, 1994; Huang et al. , 1994; Brill, 1993a; Brill, 1993b\]",o,0,643,o,0,0.8718831,True,0.8718831,0.12572938,0.0023875427
"But because we want the insertion state a1a16a20 to model digressions or unseen topics, we take the novel step of forcing its language model to be complementary to those of the other states by setting a2 a3a27a38 a21 a8 a8 a4 a8 a24 a26a11a28a30a29a6 a39a41a40a43a42a45a44a16a46 a1a48a47a1a50a49 a20 a2 a3 a26a17a21 a8a9a8 a4 a8 a24 a51a53a52a55a54a57a56 a21 a39a58a40a43a42a45a44a16a46 a1a59a47a1a50a49 a20 a2 a3a27a26a11a21a50a60 a4 a8 a24a30a24 a17 4Following Barzilay and Lee (2003), proper names, numbers and dates are (temporarily) replaced with generic tokens to help ensure that clusters contain sentences describing the same event type, rather than same actual event",o,0,644,o,0,0.92317027,True,0.92317027,0.06538892,0.011440831
.4 Related work and issues for future research Smadja (1992) and van der Eijk (1993) describe term translation methods that use bilingual texts that were aligned at the sentence leve,o,0,645,o,0,0.9593876,True,0.9593876,0.036246948,0.004365431
"Distributional approaches, on the other hand, rely on text corpora, and model relatedness by comparing the contexts in which two words occur, assuming that related words occur in similar context (e.g., Hindle (1990), Lin (1998), Mohammad and Hirst (2006))",o,0,646,o,0,0.96282756,True,0.96282756,0.029921008,0.0072514573
"Unlike (Le Nguyen & Ho, 2004), one interesting idea proposed by (Barzilay & Lee, 2003) is to cluster similar pairs of paraphrases to apply multiplesequence alignment",o,0,647,o,0,0.7582699,True,0.7582699,0.23307304,0.0086571295
ne such model is the IBM Model 1 (Brown et al. 1993,o,0,648,o,0,0.8357202,True,0.8357202,0.16059405,0.0036857196
"The table also shows the popular BLEU (Papineni et al. , 2002) and NIST2 MT metrics",p,1,649,p,1,0.8818346,True,0.10056466,0.8818346,0.01760076
"They first extract English collocations using the Xtract systetn (Smadja, 1993), and theu look for French coutlterparts",o,0,650,o,0,0.96043694,True,0.96043694,0.03660022,0.0029628107
"The difference between MWA and bilingual word alignment (Brown et al., 1993) is that the MWA method works on monolingual parallel corpus instead of bilingual corpus used by bilingual word alignment",o,0,651,o,0,0.8712591,True,0.8712591,0.043229423,0.08551146
"MTTK provides implementations of various alignment, models including IBM Model-1, Model-2 (Brown et al. , 1993), HMM-based word-to-word alignment model (Vogel et al. , 1996; Och and Ney, 2003) and HMM-based word-to-phrase alignment model (Deng and Byrne, 2005)",o,0,652,o,0,0.96465445,True,0.96465445,0.031293966,0.0040516076
ch (2003) shows that setting those weights should take into account the evaluation metric by which the MT system will eventually be judge,o,0,653,o,0,0.9056465,True,0.9056465,0.06387421,0.030479293
"It is available in several formats, and in this paper, we use the Penn Treebank (Marcus et al. , 1993) format of NEGRA",o,0,654,o,0,0.90162206,True,0.90162206,0.09123366,0.007144228
"3 The M&E Framework We model two RSRs, Cause and Contrast, adopting the de nitions of Marcu and Echihabi (2002) (henceforth M&E) for their Cause-ExplanationEvidence and Contrast relations, respectively",o,0,655,o,0,0.9676816,True,0.9676816,0.029020606,0.0032978228
"The smoothing methods proposed in the literature (overviews are provided by Dagan, Lee, and Pereira (1999) and Lee (1999)) can be generally divided into three types: discounting (Katz 1987), class-based smoothing (Resnik 1993; Brown et al. 1992; 364 Computational Linguistics Volume 28, Number 3 Pereira, Tishby, and Lee 1993), and distance-weighted averaging (Grishman and Sterling 1994; Dagan, Lee, and Pereira 1999)",o,0,656,o,0,0.95989305,True,0.95989305,0.03583205,0.004274894
"We used the Penn Treebank WSJ corpus (Marcus et al. , 1993) to perform the empirical evaluation of the considered approaches",o,0,657,o,0,0.96863526,True,0.96863526,0.02707188,0.004292816
"Following previous work on using global features of candidate structures to learn a ranking model (Collins, 2002), the global (i.e. , partition-based) features we consider here are simple functions of the local features that capture the relationship between NP pairs",o,0,658,o,0,0.95612013,True,0.95612013,0.04025197,0.0036279394
"61 Distributional cluster (Brown et al. , 1992): tie, jacket, suit Word 'tie' (7 alternatives) 0.0000 0.0000 0.0000 1.0000 0.0000 0.0000 0.0000 draw, standoff, tie, stalemate affiliation, association, tie, tie-up: a social or business relationship tie, crosstie, sleeper: subconcept of brace, bracing necktie, tie link, linkup, tie, tie-in: something that serves to join or link drawstring, string, tie: cord used as a fastener tie, tie beam: used to prevent two rafters, e.g., from spreading apart Word 'jacket' (4 alternatives) 0.0000 book jacket, dust cover: subeoncept of promotional material 0.0000 jacket crown, jacket: artificial crown fitted over a broken or decayed tooth 0.0000 jacket: subconceptofwrapping, wrap, wrapper 1.0000 jacket: a short coat Word 'suit' (4 alternatives) 0.0000 suit, suing: subconcept of entreaty, prayer, appeal 1.0000 suit, suit of clothes: subconcept of garment 0.0000 suit: any of four sets of13"""" cards in a paek 0.0000 legal action, action, case, lawsuit, suit: a judicial proceeding This cluster was derived by Brown et al. using a modification of their algorithm, designed to uncover """"semantically sticky"""" clusters",o,0,659,o,0,0.96787393,True,0.96787393,0.023393204,0.00873287
"A boundary-based model of co-occurrence assumes that both halves of the bitext have been segmented into s segments, so that segment Ui in one half of the bitext and segment Vi in the other half are mutual translations, 1 < i < s. Under the boundary-based model of co-occurrence, there are several ways to compute co-occurrence counts cooc(u, v) between word types u and v. In the models of Brown, Della Pietra, Della Pietra, and Mercer (1993), reviewed in Section 4.3, s COOC(R, V) = ~ ei(u) .j~(V), (12) i=1 where ei and j5 are the unigram frequencies of u and v, respectively, in each aligned text segment i. For most translation models, this method produces suboptimal results, however, when ei(u) > 1 and )~(v) > 1",o,0,660,o,0,0.543797,True,0.543797,0.2697912,0.18641183
"We can then use this newly identified set to: (1) use Turneys method to find the orientation for the terms and employ the terms and their scores in a classifier, and (2) use Turneys method to find the orientation for the terms and add the new terms as additional seed terms for a second iteration As opposed to Turney (2002), we do not use the web as a resource to find associations, rather we apply the method directly to in-domain data",o,0,661,o,0,0.8929287,True,0.8929287,0.044804975,0.062266327
"Such techniques include Gibbs sampling (Finkel et al. , 2005), a general-purpose Monte Carlo method, and integer linear programming (ILP), (Roth and Yih, 2005), a general-purpose exact framework for NP-complete problems",o,0,662,o,0,0.9525656,True,0.9525656,0.044945385,0.0024890308
"Some researchers then tried to automatically extract paraphrase rules (Lin and Pantel, 2001; Barzilay and Lee, 2003; Zhao et al., 2008b), which facilitates the rule-based PG methods",o,0,663,o,0,0.94376916,True,0.94376916,0.05097955,0.005251298
"A phrase-based translation model is one of the modern approaches which exploits a phrase, a contiguous sequence of words, as a unit of translation (Koehn et al. , 2003; Zens and Ney, 2003; Tillman, 2004)",o,0,664,p,1,0.60270405,False,0.39142177,0.60270405,0.0058741826
"This can be seen as a simplified version of (Rosti et al., 2007b)",o,0,665,o,0,0.9620921,True,0.9620921,0.032888845,0.005019101
"A similar view underlies the class-based methods cited in Section 2.4.3 (Brown et al. 1992; Pereira and Tishby 1992; Pereira, Tishby, and Lee 1993)",o,0,666,o,0,0.9274179,True,0.9274179,0.06288472,0.009697396
"Good partof-speech results can be obtained using only the preceding category (Weischedel et al. , 1993), which is what we will be using",o,0,667,p,1,0.668364,False,0.3031736,0.668364,0.02846237
"7 Automated Sense Labelling of Discourse Connectives The focus here is on automated sense labelling of discourse connectives (Elwell and Baldridge, 2008; Marcu and Echihabi, 2002; Pitler et al., 2009; Wellner and Pustejovsky, 2007; Wellner, 679 Total Density of Intra-Sentential Intra-Sentential Total Intra-Sentential Intra-Sentential Subordinating Coordinating Discourse Genre Sentences Connectives Connectives/Sentence Conjunctions Conjunctions Adverbials ESSAYS 4774 1397 0.293 808 (57.8%) 438 (31.4%) 151 (10.8%) SUMMARIES 2118 275 0.130 166 (60.4%) 99 (36.0%) 10 (3.6%) LETTERS 739 200 0.271 126 (63.0%) 56 (28.0%) 18 (9.0%) NEWS 40095 9336 0.233 5514 (59.1%) 3015 (32.3%) 807 (8.6%) Figure 4: Distribution of Explicit Intra-Sentential Connectives",o,0,668,o,0,0.9590375,True,0.9590375,0.027959973,0.013002595
"The baseline score using all phrase pairs was 59.11 (BLEU, Papineni et al. , 2002) with a 95% confidence interval of [57.13, 61.09]",o,0,669,o,0,0.96436,True,0.96436,0.026295923,0.0093441075
"1 Introduction Current methods for large-scale information extraction take advantage of unstructured text available from either Web documents (Banko et al., 2007; Snow et al., 2006) or, more recently, logs of Web search queries (Pasca, 2007) to acquire useful knowledge with minimal supervision",o,0,670,o,0,0.7465879,True,0.7465879,0.2478873,0.00552489
"Furthermore, training corpora for information extraction are typically annotated with domain-specific tags, in contrast to general-purpose annotations such as part-of-speech tags or noun-phrase bracketing (e.g. , the Brown Corpus \[Francis and Kucera, 1982\] and the Penn Treebank \[Marcus et al. , 1993\])",o,0,671,o,0,0.9694929,True,0.9694929,0.023587307,0.006919824
"To make sense tagging more precise, it is advisable to place constraint on the translation counterpart c of w. SWAT considers only those translations c that has been linked with w based the Competitive Linking Algorithm (Melamed 1997) and logarithmic likelihood ratio (Dunning 1993)",o,0,672,o,0,0.8922091,True,0.8922091,0.091983184,0.015807705
"In this work we use the averaged perceptron algorithm (Collins, 2002) since it is an online algorithm much simpler and orders of magnitude faster than Boosting and MaxEnt methods",p,1,673,n,2,0.8287963,False,0.11627105,0.054932613,0.8287963
"Our baseline method for ambiguity resolution is the Collins parser as implemented by Bikel (Collins, 1997; Bikel, 2004)",o,0,674,o,0,0.955829,True,0.955829,0.04039228,0.0037786847
"Models of that form include hidden Markov models (Rabiner, 1989; Bikel et al. , 1999) as well as discriminative tagging models based on maximum entropy classification (Ratnaparkhi, 1996; McCallum et al. , 2000), conditional random fields (Lafferty et al. , 2001; Sha and Pereira, 2003), and large-margin techniques (Kudo and Matsumoto, 2001; Taskar et al. , 2003)",o,0,675,o,0,0.96749276,True,0.96749276,0.029267509,0.0032397273
"Note that the translation direction is inverted from what would be normally expected; correspondingly the models built around this equation are often called invertedtranslationmodels (Brown et al. 1990, 1993)",o,0,676,o,0,0.95903826,True,0.95903826,0.026888864,0.014072904
"As a follow-up to the work described in this paper we developed a method that utilizes the unlabeled NPs in the corpus using a structured rule learner (Stoyanov and Cardie, 2006)",o,0,677,o,0,0.93006253,True,0.93006253,0.06531659,0.004620784
"Synchronous binarization (Zhang et al. , 2006) solves this problem by simultaneously binarizing both source and target-sides of a synchronous rule, making sure of contiguous spans on both sides whenever possible",p,1,678,o,0,0.7965973,False,0.7965973,0.19407406,0.009328589
"2 Bidirectional Dependency Networks When building probabilistic models for tag sequences, we often decompose the global probability of sequences using a directed graphical model (e.g. , an HMM (Brants, 2000) or a conditional Markov model (CMM) (Ratnaparkhi, 1996))",o,0,679,o,0,0.96606743,True,0.96606743,0.03139341,0.0025391448
"(2007) presented a history-based generation model to overcome some of the inappropriate independence assumptions in the basic generation model of (Cahill and van Genabith, 2006)",n,2,680,o,0,0.7152748,False,0.7152748,0.13988642,0.14483872
"Though several algorithms (Brown et al. , 1992; Pereira, Tishby, and Lee, 1993) have been proposed 100( 9o( 80( 4O( 20( 1000 goo 80~ 41111 2@ 5 10 15 20 25 30 5 10 15 20 25 30 iteration of EM iteration of EM (a) (b) Figure 1: Plots of (a) training and (b) test perplexity versus number of iterations of the EM algorithm, for the aggregate Markov model with C = 32 classes",o,0,681,o,0,0.9527772,True,0.9527772,0.039658446,0.0075643286
"Here, we use the hidden Markov model (HMM) alignment model (Vogel, Ney, and Tillmann 1996) and Model 4 of Brown et al",o,0,682,o,0,0.9687783,True,0.9687783,0.025956107,0.0052655837
"1.2.2 SPECIFIC SYNTACTIC AND SEMANTIC ASSUMPTIONS The basic scheme, or some not too distant relative, is the one used in many large-scale implemented systems; as examples, we can quote TEAM (Grosz et al. 1987), PUNDIT (Dahl et al. 1987), TACITUS (Hobbs et al. 1988), MODL (McCord 1987), CLE (Alshawi et al. 1989), and SNACK-85 (Rayner and Banks 1986)",o,0,683,o,0,0.7429917,True,0.7429917,0.25205067,0.0049575875
"We have implemented a parallel version of our GIS code using the MPICH library (Gropp et al. , 1996), an open-source implementation of the Message Passing Interface (MPI) standard",o,0,684,o,0,0.9567668,True,0.9567668,0.039985258,0.0032479137
"(McDonald and Satta, 2007; Smith and Smith, 2007)",o,0,685,o,0,0.9700824,True,0.9700824,0.021695133,0.008222491
"The model scaling factors M1 are optimized with respect to the BLEU score as described in (Och, 2003)",o,0,686,o,0,0.96348256,True,0.96348256,0.029806435,0.006711064
"One promising approach extends standard Statistical Machine Translation (SMT) techniques (e.g. , Brown et al. , 1993; Och & Ney, 2000, 2003) to the problems of monolingual paraphrase identification and generation",o,0,687,p,1,0.8146793,False,0.17869933,0.8146793,0.0066213184
"We used MXPOST (Ratnaparkhi, 1996), and in order to discover more general patterns, we map the tag set down after tagging, e.g. NN, NNP, NNPS and NNS all map to NN",o,0,688,o,0,0.9550764,True,0.9550764,0.040888604,0.0040349523
"This formula follows the convention of (Brown et al. , 1993) in letting so designate the null state",o,0,689,o,0,0.94947565,True,0.94947565,0.039285336,0.0112389615
"1 Introduction The Maximum Entropy (ME) statistical framework (Darroch and Ratcliff, 1972; Berger et al. , 1996) has been successfully deployed in several NLP tasks",p,1,690,p,1,0.8852547,True,0.11074853,0.8852547,0.003996763
"The acquisition of clues is a key technology in these research efforts, as seen in learning methods for document-level SA (Hatzivassiloglou and McKeown, 1997; Turney, 2002) and for phraselevel SA (Wilson et al., 2005; Kanayama and Nasukawa, 2006)",o,0,691,o,0,0.58425033,True,0.58425033,0.40986893,0.0058808234
"5.2 Results We use a Maximum Entropy (ME) classi er (Manning and Klein, 2003) which allows an e cient combination of many overlapping features",p,1,692,o,0,0.8079301,False,0.8079301,0.18545195,0.006617966
"3 Surface Realisation from f-Structures Cahill and van Genabith (2006) present a probabilistic surface generation model for LFG (Kaplan, 1995)",o,0,693,o,0,0.96758825,True,0.96758825,0.027697435,0.004714241
"7.2 Minimum-Risk Training Adjusting  or  changes the distribution p. Minimum error rate training (MERT) (Och, 2003) tries to tune  to minimize the BLEU loss of a decoder that chooses the most probable output according to p",o,0,694,o,0,0.93784827,True,0.93784827,0.0450247,0.01712704
"Also, PMI-IR is useful for calculating semantic orientation and rating reviews (Turney, 2002)",o,0,695,o,0,0.5922215,True,0.5922215,0.3975987,0.010179788
2 This problem is also a central concern in the work by Bean and Riloff (1999,o,0,696,o,0,0.6669576,True,0.6669576,0.29122996,0.041812494
"While we have observed reasonable results with both G 2 and Fisher's exact test, we have not yet discussed how these results compare to the results that can be obtained with a technique commonly used in corpus linguistics based on the mutual information (MI) measure (Church and Hanks 1990): I(x,y) --log 2 P(x,y) (4) P(x)P(y) In (4), y is the seed term and x a potential target word",o,0,697,o,0,0.6277288,True,0.6277288,0.3493837,0.02288736
"1 Introduction Phrase-based method (Koehn et al., 2003; Och and Ney, 2004; Koehn et al., 2007) and syntaxbased method (Wu, 1997; Yamada and Knight, 2001; Eisner, 2003; Chiang, 2005; Cowan et al., 2006; Marcu et al., 2006; Liu et al., 2007; Zhang et al., 2007c, 2008a, 2008b; Shen et al., 2008; Mi and Huang, 2008) represent the state-of-the-art technologies in statistical machine translation (SMT)",p,1,698,p,1,0.85858464,True,0.12687165,0.85858464,0.0145437345
"As the most concise definition we take the first sentence of each article, following (Kazama and Torisawa, 2007)",o,0,699,o,0,0.70076424,True,0.70076424,0.2744232,0.02481259
"Co-occurrence information between neighboring words and words in the same sentence has been used in phrase extraction (Smadja, 1993; Fung and Wu, 1994), phrasal translation (Smadja et al. , 1996; Kupiec, 1993; Wu, 1995; Dagan and Church, 1994), target word selection (Liu and Li, 1997; Tanaka and Iwasaki, 1996), domain word translation (Fung and Lo, 1998; Fung, 1998), sense disambiguation (Brown et al. , 1991; Dagan et al. , 1991; Dagan and Itai, 1994; Gale et al. , 1992a; Gale et al. , 1992b; Gale et al. , 1992c; Shiitze, 1992; Gale et al. , 1993; Yarowsky, 1995), and even recently for query translation in cross-language IR as well (Ballesteros and Croft, 1998)",o,0,700,o,0,0.96589494,True,0.96589494,0.029778197,0.004326903
"Starting with bilingualphrasepairsextractedfromautomatically aligned parallel text (Och and Ney, 2004; Koehn et al., 2003), these PSCFG approaches augment each contiguous (in source and target words) phrase pair with a left-hand-side symbol (like the VP in the example above), and perform a generalization procedure to form rules that include nonterminal symbols",o,0,701,o,0,0.9686186,True,0.9686186,0.027618833,0.0037625227
"(Cutting et al. , 1992) and (Feldweg, 1995))",o,0,702,o,0,0.9627528,True,0.9627528,0.030842042,0.006405144
ata set (Sang & Buchholz 2000; Ramshow & Marcus 1995,o,0,703,o,0,0.9715219,True,0.9715219,0.02037111,0.008107025
"The recent work of (Haghighi and Klein, 2006) and (Quirk et al., 2005) were also sources of inspiration",o,0,704,o,0,0.5421061,True,0.5421061,0.4476696,0.010224211
"An alternative would be using a vector space model for classi cation where calltypes and utterances are represented as vectors including word a2 -grams (Chu-Carroll and Carpenter, 1999)",o,0,705,o,0,0.9578534,True,0.9578534,0.03997207,0.0021745116
"Others try to accommodate both syntactic and lexical differences between the candidate translation and the reference, like CDER (Leusch et al. , 2006), which employs a version of edit distance for word substitution and reordering; METEOR (Banerjee and Lavie, 2005), which uses stemming and WordNet synonymy; and a linear regression model developed by (Russo-Lassner et al. , 2005), which makes use of stemming, WordNet synonymy, verb class synonymy, matching noun phrase heads, and proper name matching",o,0,706,o,0,0.96459943,True,0.96459943,0.031519566,0.0038809807
"For a given choice of q and f, the IIS algorithm (Berger et al. , 1996) can be used to find maximum likelihood values for the parameters ~",o,0,707,o,0,0.95376277,True,0.95376277,0.042301152,0.003936061
"Minimum Error Rate Training (MERT) (Och, 2003) under BLEU criterion is used to estimate 20 feature function weights over the larger development set (dev1)",o,0,708,o,0,0.9364262,True,0.9364262,0.048378624,0.015195161
"Full discriminative parser training faces signi cant algorithmic challenges in the relationship between parsing alternatives and feature values (Geman and Johnson, 2002) and in computing feature expectations",o,0,709,o,0,0.9041435,True,0.9041435,0.089282244,0.0065742466
"TheChinesesentencefromtheselected pair is used as the single reference to tune and evaluate the MT system with word-based BLEU-4 (Papineni et al., 2002)",o,0,710,o,0,0.9661873,True,0.9661873,0.029871872,0.0039408817
"Section 4 compares our results to Itindle's ones (Hindle, 1990)",o,0,711,o,0,0.95045096,True,0.95045096,0.03878222,0.010766805
"The first one is a hypotheses testing approach (Gale and Church, 1991; Melamed, 2001; Tufi 2002) while the second one is closer to a model estimating approach (Brown et al. , 1993; Och and Ney, 2000)",o,0,712,o,0,0.9293659,True,0.9293659,0.05104191,0.019592121
"3.2 Learning Algorithm For learning coreference decisions, we used a Maximum Entropy (Berger et al. , 1996) model",o,0,713,o,0,0.9497917,True,0.9497917,0.042913947,0.0072943647
"Uses for k-best lists include minimum Bayes risk decoding (Goodman, 1998; Kumar and Byrne, 2004), discriminative reranking (Collins, 2000; Charniak and Johnson, 2005), and discriminative training (Och, 2003; McClosky et al., 2006)",o,0,714,o,0,0.9548379,True,0.9548379,0.035792135,0.009370048
" Most existing work to capture labelconsistency, has attempted to create all parenleftbign2parenrightbig pairwise dependencies between the different occurrences of an entity, (Finkel et al. , 2005; Sutton and McCallum, 2004), where n is the number of occurrences of the given entity",o,0,715,o,0,0.925074,True,0.925074,0.065732054,0.009193949
"Approaches include word substitution systems (Brown et al. , 1993), phrase substitution systems (Koehn et al. , 2003; Och and Ney, 2004), and synchronous context-free grammar systems (Wu and Wong, 1998; Chiang, 2005), all of which train on string pairs and seek to establish connections between source and target strings",o,0,716,o,0,0.9640626,True,0.9640626,0.03294012,0.0029973206
"using the BLEU metric (Papineni et al., 2002)",o,0,717,o,0,0.9764947,True,0.9764947,0.017479349,0.0060259714
"As other researchers pursued efficient default unification (Bouma, 1990; Russell et al. , 1991; Copestake, 1993), we also propose another definition of default unification, which we call lenient default unification",o,0,718,o,0,0.77344286,True,0.77344286,0.21134429,0.015212856
"We just assign these rules a constant score trained using our implementation of Minimum Error Rate Training (Och, 2003b), which is 0.7 in our system",o,0,719,o,0,0.95466715,True,0.95466715,0.03677775,0.008555026
"This paper explores an alternative approach to parsing, based on the perceptron training algorithm introduced in Collins (2002)",o,0,720,o,0,0.92236197,True,0.92236197,0.067520805,0.010117255
"However, one of the major limitations of these advances is the structured syntactic knowledge, which is important to global reordering (Li et al., 2007; Elming, 2008), has not been well exploited",o,0,721,n,2,0.8226077,False,0.10384499,0.07354729,0.8226077
"Other linear time algorithms for rank reduction are found in the literature (Zhang et al., 2008), but they are restricted to the case of synchronous context-free grammars, a strict subclass of the LCFRS with f = 2",o,0,722,o,0,0.88152677,True,0.88152677,0.10783272,0.0106404545
kanohara and Tsujii (2007) generate ill-formed sentences by sampling a probabilistic language model and end up with pseudo-negative examples which resemble machine translation output more than they do learner text,o,0,723,o,0,0.9432866,True,0.9432866,0.04364671,0.013066783
"The table in Figure 9 shows a comparison of different systems for which tagging accuracies have been reported previously for the 17-tagset case (Goldberg et al., 2008)",o,0,724,o,0,0.922051,True,0.922051,0.067844994,0.010103973
"We are encoding the knowledge as axioms in what is for the most part a first-order logic, described by Hobbs (1985a), although quantification over predicates is sometimes convenient",o,0,725,o,0,0.75924855,True,0.75924855,0.115331165,0.12542024
"This sort of problem can be solved in principle by conditional variants of the Expectation-Maximization algorithm (Baum et al. , 1970; Dempster et al. , 1977; Meng and Rubin, 1993; Jebara and Pentland, 1999)",o,0,726,o,0,0.8621622,True,0.8621622,0.12991305,0.007924746
"Movie and product reviews have been the main focus of many of the recent studies in this area (Pang and Lee 2002, Pang et al. 2004, Turney 2002, Turney and Littman 2002)",o,0,727,o,0,0.8536285,True,0.8536285,0.14106251,0.005309077
"Their weights are calculated by deleted interpolation (Brown et al. , 1992)",o,0,728,o,0,0.9684891,True,0.9684891,0.02396318,0.0075477166
"The data set consisting of 249,994 TFSs was generated by parsing the Figure 3: The size of Dpi; for the size of the data set 800 bracketed sentences in the Wall Street Journal corpus (the first 800 sentences in Wall Street Journal 00) in the Penn Treebank (Marcus et al. , 1993) with the XHPSG grammar (Tateisi et al. , 1998)",o,0,729,o,0,0.96480465,True,0.96480465,0.029894738,0.0053006215
"By contrast, alternative approaches, like Collins (1997), apply an additional transformation to each tree in the tree-bank, splitting each rule into small parts, which finally results in a new grammar covering many more sentences than the explicit one",o,0,730,o,0,0.8872953,True,0.8872953,0.087827325,0.024877382
"Comparing the LFG-based evaluation method with other popular metrics: BLEU, NIST, General Text Matcher (GTM) (Turian et al. , 2003), Translation Error Rate (TER) (Snover et al. , 2006)1, and METEOR (Banerjee and Lavie, 2005), we show that combining dependency representations with paraphrases leads to a more accurate evaluation that correlates better with human judgment",o,0,731,p,1,0.7694269,False,0.19430424,0.7694269,0.036268823
"Once we obtain the augmented phrase table, we should run the minimum-error-rate training (Och, 2003) with the augmented phrase table such that the model parameters are properly adjusted",o,0,732,o,0,0.919003,True,0.919003,0.07322261,0.0077743395
"Our approach is closely related to previous CoTraining methods (Yarowsky, 1995; Blum and Mitchell, 1998; Goldman and Zhou, 2000; Collins and Singer, 1999)",o,0,733,o,0,0.8333569,True,0.8333569,0.14108168,0.025561493
"Such a lexicon can be used, e.g., to classify individual sentences or phrases as subjective or not, and as bearing positive or negative sentiments (Pang et al., 2002; Kim and Hovy, 2004; Wilson et al., 2005a)",o,0,734,o,0,0.96739274,True,0.96739274,0.028907659,0.0036995024
"Introduction Log-linear models have been applied to a number of problems in NLP, for example, POS tagging (Ratnaparkhi 1996; Lafferty, McCallum, and Pereira 2001), named entity recognition (Borthwick 1999), chunking (Koeling 2000), and parsing (Johnson et al. 1999)",o,0,735,o,0,0.89835757,True,0.89835757,0.09735852,0.004283905
"They use a conditional model, based on Collins (1996), which, as the authors acknowledge, has a number of theoretical deficiencies; thus the results of Clark et al. provide a useful baseline for the new models presented here",o,0,736,o,0,0.8362431,True,0.8362431,0.14005765,0.023699235
"Itowever, Harris' methodology implies also to simplify and transform each parse tree 2, so as to obtain so-called """"elementary sentences"""" exhibiting the main conceptual classes for the domain (Sager lIa'or instance, Hindle (Hindle, 1990) needs a six million word corpus in order to extract noun similarities from predicate-argunlent structures",o,0,737,o,0,0.94396985,True,0.94396985,0.046883605,0.009146539
"For example it has been used to measure centrality in hyperlinked web pages networks (Brin and Page, 1998; Kleinberg, 1998), lexical networks (Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Kurland and Lee, 2005; Kurland and Lee, 2006), and semantic networks (Mihalcea et al., 2004)",o,0,738,o,0,0.96251786,True,0.96251786,0.034846377,0.0026357349
"We experimented with two independent, arguably complementary techniques for clustering and aligning  a predicate argument based approach that extracts more general templates containing one predicate and a ROUGE (Lin, 2004) based 265 approach that can extract templates containing multiple verbs",o,0,739,o,0,0.8421911,True,0.8421911,0.14422268,0.01358619
"Our features were based on those in (Finkel et al., 2005)",o,0,740,o,0,0.96998537,True,0.96998537,0.026298001,0.0037166693
"(Macklovitch, 1994; Melamed, 1996b)), concordancing for bilingual lexicography (Catizone et al. , 1993; Gale & Church, 1991), computerassisted language learning, corpus linguistics (Melby",o,0,741,o,0,0.9686186,True,0.9686186,0.024739234,0.0066422387
"For example, smoothing methods have played a central role in probabilistic approaches (Collins, 1997; Wang et al. , 2005), and yet they are not being used in current large margin training algorithms",o,0,742,n,2,0.6841136,False,0.19688909,0.118997276,0.6841136
"Some other researchers also work on detecting negative cases, i.e. contradiction, instead of entailment (de Marneffe et al., 2008)",o,0,743,o,0,0.90995723,True,0.90995723,0.047979347,0.042063434
"The statistical methods are based on distributional analysis (we defined a measure called mutual conditioned plausibility, a derivation of the well known mutual information), and cluster analysis (a COBWEB-like algorithm for word classification is presented in \[Basili et al, 1993,a\])",o,0,744,o,0,0.8770029,True,0.8770029,0.116792284,0.0062048943
"Carletta suggests that content analysis researchers consider K >.8 as good reliability, with.67< /~"""" <.8 allowing tentative conclusions to be drawn (Carletta, 1996)",o,0,745,o,0,0.8448452,True,0.8448452,0.12767716,0.02747763
"a176 Base NP standard data set (baseNP-S) This data set was first introduced by (Ramshaw and Marcus, 1995), and taken as the standard data set for baseNP identification task2",o,0,746,o,0,0.9328962,True,0.9328962,0.06438973,0.0027140721
"3.1 A simple solution Wu (1997) suggests that in order to have an ITG take advantage of a known partial structure, one can simply stop the parser from using any spans that would violate the structure",o,0,747,o,0,0.9074119,True,0.9074119,0.08250768,0.010080435
"These categories were automatically generated using the labeled parses in Penn Treebank (Marcus et al., 1993) and the labeled semantic roles of PropBank (Kingsbury et al., 2002)",o,0,748,o,0,0.9730434,True,0.9730434,0.022606142,0.00435042
"Under the maximum entropy framework (Berger et al. , 1996), evidence from different features can be combined with no assumptions of feature independence",o,0,749,o,0,0.888572,True,0.888572,0.06882109,0.042606976
"Then, by using evaluations similar to those described in (Baroni et al., 2008) and by Rapp (2002), we show that the best distance-based measures correlate better overall with human association scores than do the best window based configurations (see Section 4), and that they also serve as better predictors of the strongest human associations (see Section 5)",o,0,750,o,0,0.44978225,True,0.44978225,0.29874307,0.25147477
"Therefore, (Och and Ney, 2002; Och, 2003) defined the translation candidate with the minimum word-error rate as pseudo reference translation",o,0,751,o,0,0.96389186,True,0.96389186,0.030574718,0.005533513
"Probability Based Commensurability Charniak and Goldman (1988) started out with a model very similar to Hobbs et al. , but became concerned with 227 the lack of theoretical grounding for Ihe number, in rules, much as we we.re",o,0,752,o,0,0.82512486,True,0.82512486,0.0968418,0.07803334
"1 Introduction In the first SMT systems (Brown et al. , 1993), word alignment was introduced as a hidden variable of the translation model",o,0,753,o,0,0.9374745,True,0.9374745,0.057634827,0.0048906743
"The parser implementation in (Bikel, 2002) was used in this experiment and it was run in a mode which emulated the Collins (1997) parser",o,0,754,o,0,0.9466877,True,0.9466877,0.048315357,0.0049969545
"Our approach differs from the corpus-based surface generation approaches of (Langkilde and Knight, 1998) and (Berger et al. , 1996)",o,0,755,o,0,0.9217235,True,0.9217235,0.039463114,0.03881337
"Modulo more minor differences, these notions are close to the ideas of interpretation as abduction (Hobbs et al \[1988\]) and generation as abduction (ltobbs et al \[1990:26-28\]), where we take abduction, in the former case for instance, to be a process returning a temporal-causal structure which can explain the utterance in context",o,0,756,o,0,0.93114716,True,0.93114716,0.06372217,0.005130717
"Wu (1997) proposes Inversion Transduction Grammars, treating translation as a process of parallel parsing of the source and target language via a synchronized grammar",o,0,757,o,0,0.9671833,True,0.9671833,0.03033836,0.0024783453
"4.1 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a)",p,1,758,o,0,0.634857,False,0.634857,0.32314682,0.041996215
"A tree sequence to string rule  174 A tree-sequence to string translation rule in a forest is a triple <L, R, A>, where L is the tree sequence in source language, R is the string containing words and variables in target language, and A is the alignment between the leaf nodes of L and R. This definition is similar to that of (Liu et al. 2007, Zhang et al. 2008a) except our treesequence is defined in forest",o,0,759,o,0,0.94675255,True,0.94675255,0.03739707,0.01585039
"glish (previously used for self-training of parsers (McClosky et al., 2006))",o,0,760,o,0,0.9082222,True,0.9082222,0.052376695,0.039401103
"2.1 Conditional Maximum Entropy Model The goal of CME is to find the most uniform conditional distribution of y given observation x, ( )xyp, subject to constraints specified by a set of features ()yxf i,, where features typically take the value of either 0 or 1 (Berger et al. , 1996)",o,0,761,o,0,0.9228185,True,0.9228185,0.07208688,0.005094766
"Verbs and possible senses in our corpus Both corpora were lemmatized and part-of-speech (POS) tagged using Minipar (Lin, 1993) and Mxpost (Ratnaparkhi, 1996), respectivelly",o,0,762,o,0,0.963589,True,0.963589,0.032942533,0.0034684637
"However, in (Quirk and Menezes, 2006), the authors investigate minimum translation units (MTU) which is a refinement over a similar approach by (Banchs et al. , 2005) to eliminate the overlap issue",p,1,763,o,0,0.78028816,False,0.78028816,0.105781145,0.11393078
"The most similar work to ours is (Daume III and Marcu, 2005), in which two most common synsets from WordNet for all words in an NP and their hypernyms are extracted as features",o,0,764,o,0,0.6499828,True,0.6499828,0.33918825,0.010828909
"These heuristics define a phrase pair to consist of a source and target ngrams of a word-aligned source-target sentence pair such that if one end of an alignment is in the one ngram, the other end is in the other ngram (and there is at least one such alignment) (Och and Ney, 2004; Koehn et al., 2003)",o,0,765,o,0,0.9656613,True,0.9656613,0.024917904,0.009420897
"3.1 The traditional IBM alignment model IBM Model 4 (Brown et al. , 1993) learns a set of 4 probability tables to compute p(f|e) given a foreign sentence f and its target translation e via the following (greatly simplified) generative story: 361 NP-C NPB NPB NNP taiwan POS s NN surplus PP IN in NP-C NPB NN trade PP IN between NP-C NPB DT the CD two NNS shores FTD0 GR G4E7 DYBG EL DIDV TAIWAN IN TWO-SHORES TRADE MIDDLE SURPLUS R1: NP-C NPB x0:NPB x1:NN x2:PP x0 x2EL x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R10: NP-C NPB x0:NPB x1:NN x2:PP x0 x2 x1 R2: NPB NNP taiwan POS s FTD0 R11: NPB x0:NNP POS s x0 R17: NPB NNP taiwan x0:POS x0 R12: NNP taiwan FTD0 R18: POS s FTD0 R3: PP x0:IN x1:NP-C x0 x1 R13: PP IN in x0:NP-C GR x0EL R19: PP IN in x0:NP-C x0 R4: IN in  GR R5: NP-C x0:NPB x1:PP  x1 x0 R5: NP-C x0:NPB x1:PP x1 x0 R20: NP-C x0:NPB PP x1:IN x2:NP-C x2 x0 x1 R6: PP IN between NP-C NPB DT the CD two NNS shores G4E7 R14: PP IN between x0:NP-C x0 R21: IN between EL R15: NP-C x0:NPB x0 R15: NP-C x0:NPB x0 R16: NPB DT the CD two NNS shores G4E7 R22: NPB x0:DT CD two x1:NNS x0 x1 R23: NNS shores G4E7 R24: DT the GR R7: NPB x0:NN x0 R7: NPB x0:NN x0 R7: NPB x0:NN x0 R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV R8: NN trade DYBG R9: NN surplus DIDV Figure 2: A (English tree, Chinese string) pair and three different sets of multilevel tree-to-string rules that can explain it; the first set is obtained from bootstrap alignments, the second from this papers re-alignment procedure, and the third is a viable, if poor quality, alternative that is not learned",o,0,766,o,0,0.888048,True,0.888048,0.08447247,0.027479488
"The details of the algorithm can be found in the literature for statistical translation models, such as (Brown et al., 1993)",o,0,767,o,0,0.89666194,True,0.89666194,0.09836824,0.0049697347
"Parse selection constitutes an important part of many parsing systems (Johnson et al., 1999; Hara et al., 2005; van Noord and Malouf, 2005; McClosky et al., 2006)",o,0,768,o,0,0.6195985,True,0.6195985,0.37507218,0.005329259
"Conditional Markov models (CMM) (Ratnaparkhi, 1996; Klein and Manning, 2002) have been successfully used in sequence labeling tasks incorporating rich feature sets",p,1,769,p,1,0.93957657,True,0.056247156,0.93957657,0.0041762497
"Standard MET (Och, 2003) iterative parameter estimation under IBM BLEU (Papineni et al., 2001) is performed on the corresponding development set",o,0,770,o,0,0.96806425,True,0.96806425,0.028333602,0.0036022132
"The score combination weights are trained by a minimum error rate training procedure similar to (Och and Ney, 2003)",o,0,771,o,0,0.9670624,True,0.9670624,0.028697412,0.004240052
"Second, we discuss the work done by (Barzilay & Lee, 2003) who use clustering of paraphrases to induce rewriting rules",o,0,772,o,0,0.9410593,True,0.9410593,0.05027392,0.008666856
"This evaluation shows that our WIDL-based approach to generation is capable of obtaining headlines that compare favorably, in both content and fluency, with extractive, state-of-the-art results (Zajic et al. , 2004), while it outperforms a previously-proposed abstractive system by a wide margin (Zhou and Hovy, 2003)",o,0,773,n,2,0.50621504,False,0.27599815,0.21778682,0.50621504
" Our evaluation metrics are BLEU (Papineni et al., 2002) and NIST, which are to perform caseinsensitive matching of n-grams up to n = 4",o,0,774,o,0,0.96938455,True,0.96938455,0.026944404,0.0036710934
"1 Introduction Summarizing spoken documents has been extensively studied over the past several years (Penn and Zhu, 2008; Maskey and Hirschberg, 2005; Murray et al., 2005; Christensen et al., 2004; Zechner, 2001)",o,0,775,p,1,0.5410367,False,0.45382237,0.5410367,0.0051409462
"More recently, the problem has been tackled using unsupervised (e.g. , Bean and Riloff (1999)) and supervised (e.g. , Evans (2001), Ng and Cardie (2002a)) approaches",o,0,776,o,0,0.7538416,True,0.7538416,0.23239173,0.0137666995
"Table 1 shows the impact of increasing reordering window length (Koehn et al. , 2003) on translation quality for the ?dev06??data.2 Increasing the reordering window past 2 has minimal impact on translation quality, implying that most of the reordering effects across Spanish and English are well modeled at the local or phrase level",o,0,777,o,0,0.7752265,True,0.7752265,0.16420116,0.060572367
"a11a29a9 thea13 thea15 a1a4a3a6a5 a11a29a9 thea13 thea15 a11a29a9 thea15 a11a29a9 thea15a1a0 a2 since a11a2a9 thea13 thea15a4a3 a11a29a9 thea15 a11a29a9 thea15 . Also note that in the case of phraseness of a bigram, the equation looks similar to pointwise mutual information (Church and Hanks, 1990), but they are different",o,0,778,o,0,0.8818179,True,0.8818179,0.063863076,0.054319113
"2.2.1 The evaluator The evaluator is a function p(t\[t', s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens t' which precede t in the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al. , 1993), but it diflhrs in one significant aspect: whereas the IBM model involves a """"noisy channel"""" decomposition, we use a linear combination of separate predictions from a language model p(t\[t') and a translation model p(t\[s)",o,0,779,o,0,0.8874178,True,0.8874178,0.070792384,0.04178978
"(Finkel et al., 2006), and in some cases, to factor the translation problem so that the baseline MT system can take advantage of the reduction in sparsity by being able to work on word stems",o,0,780,o,0,0.80208504,True,0.80208504,0.16239744,0.03551756
"The 74.6% final accuracy on apartments is higher than any result obtained by Haghighi and Klein (2006) (the highest is 74.1%), higher than the supervised HMM results reported by Grenager et al",n,2,781,n,2,0.8459369,True,0.12015525,0.033907894,0.8459369
"(Brown et al. , 1992))",o,0,782,o,0,0.96956015,True,0.96956015,0.022197666,0.008242177
"Some stem from work on graphical models,includingloopybeliefpropagation(Suttonand McCallum, 2004; Smith and Eisner, 2008), Gibbs sampling (Finkel et al., 2005), sequential Monte Carlo methods such as particle filtering (Levy et al., 2008), and variational inference (Jordan et al., 1999; MacKay, 1997; Kurihara and Sato, 2006)",o,0,783,o,0,0.9347849,True,0.9347849,0.0629025,0.0023125787
"We have also applied our more general unification grammar acquisition methodology to the TIGER Treebank (Brants et al. 2002) and Penn Chinese Treebank (Xue, Chiou, and Palmer 2002), extracting wide-coverage, probabilistic LFG grammar 361 Computational Linguistics Volume 31, Number 3 approximations and lexical resources for German (Cahill et al. 2003) and Chinese (Burke, Lam, et al. 2004)",o,0,784,o,0,0.94043195,True,0.94043195,0.054486375,0.005081651
"A common choice for the local probabilistic classifier is maximum entropy classifiers (Berger et al. , 1996)",o,0,785,o,0,0.51402605,True,0.51402605,0.48194057,0.0040334323
he fact that different authors use different versions of the same gold standard to evaluate similar experiments (e.g. Goldwater & Griffiths (2007) versus Johnson (2007)) supports this clai,o,0,786,o,0,0.939077,True,0.939077,0.04019628,0.020726662
"4 Corpus Annotation For our corpus, we selected 1,000 sentences containing at least one comma from the Penn Treebank (Marcus et al., 1993) WSJ section 00, and manually annotated them with comma information3",o,0,787,o,0,0.9706934,True,0.9706934,0.026606675,0.0026999817
"dependency lengths: Long-distance dependencies exhibit bad performance (McDonald and Nivre, 2007)",o,0,788,o,0,0.69016314,True,0.69016314,0.24626556,0.06357132
"The part of the 1Release 2 of this data set can be obtained t'rmn the Linguistic Data Consortium with Catalogue number LDC94T4B (http://www.ldc.upenn.edu/ldc/nofranm.html) 2There are 48 labels defined in (Marcus et al. , 1993), however, three of ttmm do not appear in the corpus",o,0,789,o,0,0.91374356,True,0.91374356,0.056754865,0.0295016
"In supervised domain adaptation (Gildea, 2001; Roark and Bacchiani, 2003; Hara et al., 2005; Daume III, 2007), besides the labeled source data, we have access to a comparably small, but labeled amount of target data",o,0,790,o,0,0.91573703,True,0.91573703,0.058462556,0.025800485
"Rulesize and lexicalization affect parsing complexity whether the grammar is binarized explicitly (Zhang et al., 2006) or implicitly binarized using Early-style intermediate symbols (Zollmann et al., 2006)",o,0,791,o,0,0.9590257,True,0.9590257,0.030121058,0.010853336
"We removed all but the first two characters of each POS tag, resulting in a set of 57 tags which more closely resembles that of the Penn TreeBank (Marcus et al., 1993)",o,0,792,o,0,0.82061774,True,0.82061774,0.06175305,0.1176292
"For tuning of decoder parameters, we conducted minimum error training (Och 2003) with respect to the BLEU score using 916 development sentence pairs",o,0,793,o,0,0.9640818,True,0.9640818,0.030569546,0.005348629
"(Turney (2002) makes a similar point, noting that for reviews, \the whole is not necessarily the sum of the parts"""")",o,0,794,o,0,0.8474221,True,0.8474221,0.08905634,0.06352151
"3 CLaC-NB System: Nave Bayes Supervised statistical methods have been very successful in sentiment tagging of texts and in subjectivity detection at sentence level: on movie review texts they reach an accuracy of 85-90% (Aue and Gamon, 2005; Pang and Lee, 2004) and up to 92% accuracy on classifying movie review snippets into subjective and objective using both Nave Bayes and SVM (Pang and Lee, 2004)",p,1,795,p,1,0.9278397,True,0.06451543,0.9278397,0.0076448396
"splitting tags (Matsuzaki et al. , 2005; Petrov et al. , 2006)",o,0,796,o,0,0.9714314,True,0.9714314,0.024617994,0.00395068
"One of the best efforts to quantify the performance of a term-recognition system (Smadja, 1993) does so only for one processing stage, leaving unassessed the text-to-output performance of the system",p,1,797,n,2,0.79280263,False,0.12408416,0.08311317,0.79280263
in (1998b) defined the similarity between two concepts as the information that is in common to both concepts and the information contained in each individual concep,o,0,798,o,0,0.962972,True,0.962972,0.031499777,0.005528232
"For non-local features, we adapt cube pruning from forest rescoring (Chiang, 2007; Huang and Chiang, 2007), since the situation here is analogous to machine translation decoding with integrated language models: we can view the scores of unit nonlocal features as the language model cost, computed on-the-fly when combining sub-constituents",o,0,799,o,0,0.9508456,True,0.9508456,0.043759465,0.005395022
"CRP-based samplers have served the communitywellinrelatedlanguagetasks,suchaswordsegmentation and coreference resolution (Goldwater et al., 2006; Haghighi and Klein, 2007)",o,0,800,o,0,0.95099217,True,0.95099217,0.044805463,0.004202295
"The measures2  Mutual Information (a0a2a1 ) (Church and Hanks, 1989), the log-likelihood ratio test (Dunning, 1993), two statistical tests: t-test and a3a5a4 -test, and co-occurrence frequency  are applied to two sets of data: adjective-noun (AdjN) pairs and preposition-noun-verb (PNV) triples, where the AMs are applied to (PN,V) pairs",o,0,801,o,0,0.96548223,True,0.96548223,0.028542306,0.005975494
"5.2 Experimental Results Following (Langkilde, 2002) and other work on general-purpose generators, BLEU score (Papineni et al., 2002), average NIST simple string accuracy (SSA) and percentage of exactly matched sentences are adopted as evaluation metrics",o,0,802,o,0,0.951192,True,0.951192,0.044368528,0.0044394406
"The recall problem is usually addressed by increasing the amount of text data for extraction (taking larger collections (Fleischman et al. , 2003)) or by developing more surface patterns (Soubbotin and Soubbotin, 2002)",o,0,803,o,0,0.9173729,True,0.9173729,0.06259589,0.020031285
"The Penn Treebank documentation (Marcus et al. , 1993) defines a commonly used set of tags",o,0,804,p,1,0.6765609,False,0.3170977,0.6765609,0.006341406
"Building heavily on the ideas of History-based parsing (Black et al. , 1993; Nivre, 2006), training the parser means essentially running the parsing algorithms in a learning mode on the data in order to gather training instances for the memory-based learner",o,0,805,o,0,0.91480446,True,0.91480446,0.08040447,0.0047910865
"Each item is associated with a stack whose signa12Specifically a B-hypergraph, equivalent to an and-or graph (Gallo et al., 1993) or context-free grammar (Nederhof, 2003)",o,0,806,o,0,0.97636193,True,0.97636193,0.020047233,0.0035907626
"Minimum error rate training (MERT) with respect to BLEU score was used to tune the decoders parameters, and performed using the technique proposed in (Och, 2003)",o,0,807,o,0,0.9638515,True,0.9638515,0.032582954,0.003565584
"Reliability metrics (Krippendorff 1980; Carletta 1996) are designed to give a robust measure of how well distinct sets of data agree with, or replicate, one another",o,0,808,o,0,0.77544594,True,0.77544594,0.2104481,0.014106029
"Dialogs Speakers Turns Words Fragments Distinct Words Distinct Words/POS Singleton Words Singleton Words/POS Intonational Phrases Speech Repairs 98 34 6163 58298 756 859 1101 252 350 10947 2396 Table 1: Size of the Trains Corpus 2.1 POS Annotations Our POS tagset is based on the Penn Treebank tagset (Marcus et al. , 1993), but modified to include tags for discourse markers and end-of-turns, and to provide richer syntactic information (Heeman, 1997)",o,0,809,o,0,0.95227873,True,0.95227873,0.036449157,0.011272142
"There are also approaches to anaphora resolution using unsupervised methods to extract useful information, such as gender and number (Ge et al. , 1998), or contextual role-knowledge (Bean and Riloff, 2004)",o,0,810,o,0,0.92503035,True,0.92503035,0.068681836,0.0062878276
"This criticism leads us to automatic approaches for building thesauri from large corpora \[Hirschman et al. , 1975; Hindle, 1990; Hatzivassiloglou and McKeown, 1993; Pereira et al. , 1993; Tokunaga et aL, 1995; Ushioda, 1996\]",o,0,811,o,0,0.9336183,True,0.9336183,0.05835148,0.008030191
"Clustering-based approaches usually represent word contexts as vectors and cluster words based on similarities of the vectors (Brown et al., 1992; Lin, 1998)",o,0,812,o,0,0.9710929,True,0.9710929,0.025265386,0.0036418238
"To speed our computations, we use the cube pruning method of Huang and Chiang (2007) with a fixed beam size",p,1,813,o,0,0.8842355,False,0.8842355,0.10524653,0.010517945
"As (Church and Hanks, 1990), we adopted an evaluation of mutual information as a cohesion measure of each cooccurrence",o,0,814,o,0,0.9644255,True,0.9644255,0.03137067,0.0042037866
"We compare TERp with BLEU (Papineni et al., 2002), METEOR (Banerjee and Lavie, 2005), and TER (Snover et al., 2006)",o,0,815,o,0,0.9702077,True,0.9702077,0.024467222,0.0053251027
"We evaluated annotation reliability by using the Kappa statistic (Carletta, 1996)",o,0,816,o,0,0.96979856,True,0.96979856,0.026318625,0.0038828936
"Although the BLEU (Papineni et al. , 2002) score from Finnish to English is 21.8, the score in the reverse direction is reported as 13.0 which is one of the lowest scores in 11 European languages scores (Koehn, 2005)",o,0,817,n,2,0.45176142,False,0.392114,0.15612458,0.45176142
"177 Proceedings of EACL '99 IOB1 IOB2 IOE1 IOE2 \[+\] \[+ IO IO +\] (Ramshaw and Marcus, 1995) (Veenstra, 1998) (Argamon et al. , 1998) (Cardie and Pierce, 1998) accuracy 97.58% 96.50% 97.58% 96.77% 97.37% 97.2% precision 92.50% 91.24% 92.41% 91.93% 93.66% 91.47% 91.25% 91.80% 89.0% 91.6 % 90.7% recall F~=I 92.25% 92.37 92.32% 91.78 92.04% 92.23 92.46% 92.20 90.81% 92.22 92.61% 92.04 92.54% 91.89 92.27% 92.03 94.3% 91.6 91.6% 91.6 91.1% 90.9 Table 6: The F~=I scores for the (Ramshaw and Marcus, 1995) test set after training with their training data set",o,0,818,o,0,0.9440153,True,0.9440153,0.037434895,0.018549724
"We consider three learning algorithms, namely, the C4.5 decision tree induction system (Quinlan, 1993), the RIPPER rule learning algorithm (Cohen, 1995), and maximum entropy classification (Berger et al. , 1996)",o,0,819,o,0,0.9641454,True,0.9641454,0.031193567,0.0046609105
"Joint parsing with a simplest synchronous context-free grammar (Wu, 1997) is O(n6) as opposed to the monolingual O(n3) time",o,0,820,o,0,0.87936974,True,0.87936974,0.07075236,0.049877826
"Previous approaches to processing lnetonymy have used hand-constructed ontologies or semantic networks (.\]?ass, 1988; Iverson and Hehnreich, 1992; B(maud et al. , 1996; Fass, 1997)",o,0,821,o,0,0.9594329,True,0.9594329,0.03775942,0.0028076787
"The statistical machine translation community relies on the Bleu metric for the purposes of evaluating incremental system changes and optimizing systems through minimum error rate training (Och, 2003)",p,1,822,o,0,0.94680864,False,0.94680864,0.048974756,0.0042166226
"Most current transliteration systems use a generative model for transliteration such as freely available GIZA++1 (Och and Ney , 2000),an implementation of the IBM alignment models (Brown et al., 1993)",o,0,823,o,0,0.7800146,True,0.7800146,0.21241276,0.00757268
 Introduction The Inversion Transduction Grammar (ITG) of Wu (1997) is a syntactically motivated algorithm for producing word-level alignments of pairs of translationally equivalent sentences in two language,o,0,824,o,0,0.9618752,True,0.9618752,0.034559496,0.0035652295
"The detailed algorithm can be found in (Collins, 2002)",o,0,825,o,0,0.9360841,True,0.9360841,0.059521295,0.004394603
"The translation quality is evaluated by BLEU metric (Papineni et al., 2002), as calculated by mteval-v11b.pl with case-insensitive matching of n-grams, where n =4",o,0,826,o,0,0.97019696,True,0.97019696,0.026213985,0.0035890578
"2.3 Perceptron Learning As learning algorithm, we use Perceptron tailored for structured scenarios, proposed by Collins (2002)",o,0,827,o,0,0.93529236,True,0.93529236,0.06137375,0.0033338922
"The agreement on identifying the boundaries of units, using the  statistic discussed in (Carletta, 1996), was  =.9 (for two annotators and 500 units); the agreement on features (2 annotators and at least 200 units) was as follows: UTYPE: =.76; VERBED: =.9; FINITE: =.81",o,0,828,o,0,0.96818113,True,0.96818113,0.024469825,0.0073489673
"We refer to a3a16a5a7 as the source language string and a10 a11a7 as the target language string in accordance with the noisy channel terminology used in the IBM models of (Brown et al. , 1993)",o,0,829,o,0,0.94924325,True,0.94924325,0.044215515,0.0065412354
"This characteristic of our corpus is similar to problems with noisy and comparable corpora (Veronis, 2000), and it prevents us from using methods developed in the MT community based on clean parallel corpora, such as (Brown et al. , 1993)",o,0,830,o,0,0.5941925,True,0.5941925,0.08853472,0.31727278
"Far from full syntactic complexity, we suggest to go back to the simpler alignment methods first described by (Brown et al. , 1993)",o,0,831,o,0,0.53371936,True,0.53371936,0.34493178,0.12134879
arletta (1996) says that 0.67 a10a14a11a15a10 0.8 allows just tentative conclusions to be draw,o,0,832,o,0,0.8784443,True,0.8784443,0.08675509,0.03480068
"2 Related Work There have been various efforts to integrate linguistic knowledge into SMT systems, either from the target side (Marcu et al., 2006; Hassan et al., 2007; Zollmann and Venugopal, 2006), the source side (Quirk et al., 2005; Liu et al., 2006; Huang et al., 2006) or both sides (Eisner, 2003; Ding et al., 2005; Koehn and Hoang, 2007), just to name a few",o,0,833,o,0,0.91160834,True,0.91160834,0.082788125,0.005603624
"Indeed, only few earlier works reported inter-judge agreement level, and those that did reported rather low Kappa values, such as 0.54 (Barzilay and Lee, 2003) and 0.55 0.63 (Szpektor et al. , 2004)",o,0,834,o,0,0.4399804,True,0.4399804,0.20889392,0.3511257
"As a side product, we find empirical evidence to suggest that the effectiveness of rule lexicalization techniques (Collins, 1997; Simaan, 2000) and parent annotation techniques (Klein and Manning, 2003) is due to the fact that both lead to a reduction in perplexity in the automata induced from training corpora",p,1,835,p,1,0.6378563,True,0.33810192,0.6378563,0.02404177
"As a result, they are being used in a variety of applications, such as question answering (Hermjakob, 2001), speech recognition (Chelba and Jelinek, 1998), language modeling (Roark, 2001), language generation (Soricut, 2006) and, most notably, machine translation (Charniak et al., 2003; Galley et al., 2004; Collins et al., 2005; Marcu et al., 2006; Huang et al., 2006; Avramidis and Koehn, 2008)",o,0,836,o,0,0.70772755,True,0.70772755,0.2898841,0.0023884699
 Perceptron Training We optimize feature weights using a modification of averaged perceptron learning as described by Collins (2002,o,0,837,o,0,0.96124387,True,0.96124387,0.036019064,0.0027371028
"Motivated by the fact that non-syntactic phrases make non-trivial contribution to phrase-based SMT, the tree sequencebased translation model is proposed (Liu et al., 2007; Zhang et al., 2008a) that uses tree sequence as the basic translation unit, rather than using single sub-tree as in the STSG",o,0,838,o,0,0.81693214,True,0.81693214,0.17258132,0.0104864845
"They developed a simple heuristic function for Model 2 from (Brown et al. , 1993) which was non admissible",o,0,839,o,0,0.6600872,True,0.6600872,0.13119036,0.20872232
"1 Introduction Recent trends in machine translation illustrate that highly accurate word and phrase translations can be learned automatically given enough parallel training data (Koehn et al., 2003; Chiang, 2007)",o,0,840,p,1,0.76560163,False,0.21849337,0.76560163,0.01590508
"We use the neural network approximation (Titov and Henderson, 2007a) to perform inference in our model",o,0,841,o,0,0.9683355,True,0.9683355,0.028239666,0.003424815
"The performance of PB-SMT system is measured with BLEU score (Papineni et al., 2002)",o,0,842,o,0,0.94732153,True,0.94732153,0.046728827,0.0059496122
"C, A, and B are computed for training dataset D as C = summationtext M m=1 y (m) y (m) , A = summationtext M m=1 y (m) , and B = summationtext M m=1 y (m) . In (Jansche, 2005), y (m) was approximated by using the discriminative and logistic functions shown in Eqs",o,0,843,o,0,0.94900906,True,0.94900906,0.04383652,0.0071543674
"A standard solution is to use a weighted linear mixture of N-gram models, 1  n  N, (Brown et al. , 1992)",o,0,844,o,0,0.95908344,True,0.95908344,0.038227916,0.0026886116
"These scores are higher than those of several other parsers (e.g. Collins 1997, 99; Charniak 1997), but remain behind tim scores of Charniak (2000) who obtains 90.1% LP and 90.1% LR for sentences _< 40 words",n,2,845,n,2,0.81052125,True,0.1582045,0.03127424,0.81052125
"(2004) 89.10 89.14 89.12 kitchen sink 89.26 89.55 89.40 parser (Bikel, 2004)8, the only one that we were able to train and test under exactly the same experimental conditions (including the use of POS tags from the tagger of Ratnaparkhi (1996))",o,0,846,o,0,0.58386534,True,0.58386534,0.19239739,0.22373724
aximum Entropy models implement the intuition that the best model is the one that is consistent with the set of constraints imposed by the evidence but otherwise is as uniform as possible (Berger et al. 1996,o,0,847,o,0,0.8709444,True,0.8709444,0.10405757,0.024998026
"The automatic assessment of the translation quality has been carried out using the BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002), and the Translation Error Rate (TER) (Snover et al., 2006)",o,0,848,o,0,0.9557819,True,0.9557819,0.039093737,0.005124403
"Many existing systems for statistical machine translation (Garca-Varea and Casacuberta 2001; Germann et al. 2001; Nieen et al. 1998; Och, Tillmann, and Ney 1999) implement models presented by Brown, Della Pietra, Della Pietra, and Mercer (1993): The correspondence between the words in the source and the target strings is described by alignments that assign target word positions to each source word position",o,0,849,o,0,0.9514808,True,0.9514808,0.04508091,0.0034382844
"Second, the significance of the K-S distance in case of the null hypothesis (data sets are drawn from same distribution) can be calculated (Press et al. , 1993)",o,0,850,o,0,0.94900936,True,0.94900936,0.039899003,0.0110917315
"Other methods that have been proposed are one based on using the gain (Berger et al. , 1996) and an approximate method for selecting informative features (Shirai et al. , 1998a), and several criteria for feature selection were proposed and compared with other criteria (Berger and Printz, 1998)",o,0,851,o,0,0.9435921,True,0.9435921,0.050388467,0.0060195136
he adaptive approach is somehow similar to their idea of incremental learning and to the bootstrap approach proposed by Yarowsky (1995,o,0,852,o,0,0.9398868,True,0.9398868,0.051780663,0.008332583
"Hence, either the best translation hypothesis is directly extracted from the word graph and output, or an N-best list of translations is computed (Tran et al. , 1996)",o,0,853,o,0,0.952746,True,0.952746,0.038573336,0.008680734
"Some regarded Wikipedia as the corpora and applied hand-crafted or machine-learned rules to acquire semantic relations (Herbelot and Copestake, 2006; Kazama and Torisawa, 2007; Ruiz-casado et al., 2005; Nastase and Strube, 2008; Sumida et al., 2008; Suchanek et al., 2007)",o,0,854,o,0,0.9632688,True,0.9632688,0.033928767,0.0028024353
arowsky (1995) studied a method for word sense disambiguation using unlabeled dat,o,0,855,o,0,0.9594784,True,0.9594784,0.037485648,0.0030359682
"However, most of them fail to utilize non-syntactic phrases well that are proven useful in the phrase-based methods (Koehn et al., 2003)",o,0,856,p,1,0.5901495,False,0.30068392,0.5901495,0.10916669
"Decision lists have already been successfully applied to lexical ambiguity resolution by (Yarowsky, 1995) where they perfromed well",p,1,857,p,1,0.9109257,True,0.0753368,0.9109257,0.013737446
"Example of such algorithms are (Pereira et al., 1993) and (Lin, 1998) that use syntactic features in the vector definition",o,0,858,o,0,0.9680705,True,0.9680705,0.028913788,0.0030156656
e solve SAT analogies with a simplified version of the method of Turney (2006,o,0,859,o,0,0.94341296,True,0.94341296,0.051479254,0.005107725
"Moses uses standard external tools for some of the tasks to avoid duplication, such as GIZA++ (Och and Ney 2003) for word alignments and SRILM for language modeling",o,0,860,o,0,0.92152613,True,0.92152613,0.07191566,0.006558216
"This is similar to results in the literature (Ramshaw and Marcus, 1995)",o,0,861,o,0,0.9478825,True,0.9478825,0.046375647,0.005741872
"The TRIPS structure generally has more levels of structure (roughly corresponding to levels in X-bar theory) than the Penn Treebank analyses (Marcus et al. , 1993), in particular for base noun phrases",o,0,862,n,2,0.81037104,False,0.16082306,0.028805839,0.81037104
"(Chanod and Tapanainen, 1995) compare two tagging frameworks for tagging French, one that is statistical, built upon the Xerox tagger (Cutting et al. , 1992), and another based on linguistic constraints only",o,0,863,o,0,0.9520992,True,0.9520992,0.032882694,0.015018085
"If e has length l and f has length m, there are possible 2lm alignments between e and f (Brown et al. , 1993)",o,0,864,o,0,0.9379406,True,0.9379406,0.040949475,0.021109885
"We have adopted the evaluation method of Snow et al (2006): compare the generated hypernyms with hypernyms present in a lexical resource, in our case the Dutch part of EuroWordNet (1998)",o,0,865,o,0,0.9587167,True,0.9587167,0.03552101,0.0057623065
"In the second pass, 5-gram and 6-gram zero-cutoff stupid-backoff (Brants et al., 2007) language models estimated using 4.7 billion words of English newswire text are used to generate lattices for phrasal segmentation model rescoring",o,0,866,o,0,0.9599375,True,0.9599375,0.034320828,0.005741541
"5.3 Analysis of BF-LM framework We refer to (Talbot and Osborne, 2007) for empirical results establishing the performance of the logfrequency BF-LM: overestimation errors occur with 474 0.01 0.025 0.05 0.1 0.25 0.5 0.03 0.02 0.01 0.005 0.0025 0.001 Mean squared error of log probabilites Memory in GB MSE between WB 3-gram SRILM and BF-LMs Base 3 Base 1.5 Base 1.1 Figure 5: MSE between SRILM and BF-LMs 22 23 24 25 26 27 28 29 30 0.01 0.1 1 BLEU Score Mean squared error WB-smoothed BF-LM 3-gram model BF-LM base 1.1 BF-LM base 1.5 BF-LM base 3 Figure 6: MSE vs. BLEU for WB 3-gram BF-LMs a probability that decays exponentially in the size of the overestimation error",o,0,867,o,0,0.95873696,True,0.95873696,0.032519102,0.008743855
"Sentence Compression takes an important place for Natural Language Processing (NLP) tasks where specific constraints must be satisfied, such as length in summarization (Barzilay & Lee, 2002; Knight & Marcu, 2002; Shinyama et al. , 2002; Barzilay & Lee, 2003; Le Nguyen & Ho, 2004; Unno et al. , 2006), style in text simplification (Marsi & Krahmer, 2005) or sentence simplification for subtitling (Daelemans et al. , 2004)",o,0,868,p,1,0.5931215,False,0.3781171,0.5931215,0.02876134
"Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007)",o,0,869,o,0,0.78879976,True,0.78879976,0.20357211,0.0076281144
"7 For a more detailed discussion, see Berger, Della Pietra, and Della Pietra (1996) and Ratnaparkhi (1996)",o,0,870,o,0,0.9480964,True,0.9480964,0.04374093,0.008162687
"Therefore, domain adaptation methods have recently been proposed in several NLP areas, e.g., word sense disambiguation (Chan and Ng, 2006), statistical parsing (Lease and Charniak, 2005; McClosky et al. , 2006), and lexicalized-grammar parsing (Johnson and Riezler, 2000; Hara et al. , 2005)",o,0,871,o,0,0.9053399,True,0.9053399,0.091721766,0.0029383309
"(2003), a trigram target language model, an order model, word count, phrase count, average phrase size functions, and whole-sentence IBM Model 1 logprobabilities in both directions (Och et al. 2004)",o,0,872,o,0,0.96236205,True,0.96236205,0.03219882,0.005439078
"Our learning algorithm stems from Perceptron training in (Collins, 2002)",o,0,873,o,0,0.9527715,True,0.9527715,0.043304197,0.0039242986
.1 Linear Models for NLP We follow the framework outlined in Collins (2002; 2004,o,0,874,o,0,0.95709693,True,0.95709693,0.039484825,0.0034182854
ur system assumes POS tags as input and uses the tagger of Ratnaparkhi (1996) to provide tags for the development and evaluation set,o,0,875,o,0,0.96091604,True,0.96091604,0.035247907,0.0038360746
"corpora and corpus query tools has been particularly significant in the area of compiling and developing lexicographic materials (Kilgarriff and Rundell, 2002) and in the area of creating various kinds of lexical resources, such as WordNet (Fellbaum, 1998) and FrameNet (Atkins et al., 2003; Fillmore et al., 2003)",o,0,876,p,1,0.85252136,False,0.14316797,0.85252136,0.0043106508
"The time complexity of the CKY-based binarization algorithm is  (n3), which is higher than that of the linear binarization such as the synchronous binarization (Zhang et al., 2006)",o,0,877,n,2,0.8679613,False,0.103726484,0.028312277,0.8679613
"In the probabilistic LR model, probabilities are assigned to tree 696 Precision Recall F-score Time (min) Best-First Classifier-Based (this paper) 88.1 87.8 87.9 17 Deterministic (MaxEnt) (this paper) 85.4 84.8 85.1 < 1 Charniak & Johnson (2005) 91.3 90.6 91.0 Unk Bod (2003) 90.8 90.7 90.7 145* Charniak (2000) 89.5 89.6 89.5 23 Collins (1999) 88.3 88.1 88.2 39 Ratnaparkhi (1997) 87.5 86.3 86.9 Unk Tsuruoka & Tsujii (2005): deterministic 86.5 81.2 83.8 < 1* Tsuruoka & Tsujii (2005): search 86.8 85.0 85.9 2* Sagae & Lavie (2005) 86.0 86.1 86.0 11* Table 1: Summary of results on labeled precision and recall of constituents, and time required to parse the test set",o,0,878,o,0,0.9651999,True,0.9651999,0.02945051,0.005349605
"It can be proven that the probability distribution p satisfying the above assumption is the one with the highest entropy, is unique and has the following expone ntial form (Berger et al. 1996): (1)  = = k j cajf jcZcap 1 ),( )( 1)|( a where Z(c) is a normalization factor, fj(a,c) are the values of k features of the pair (a,c) and correspond to the linguistic cues of c that are relevant to predict the outcome a. Features are extracted from the training data and define the constraints that the probabilistic model p must satisfy",o,0,879,o,0,0.8996305,True,0.8996305,0.083811566,0.016557958
"Other languagesfor which this is the case include English (with the Penn treebank (Marcus et al., 1993), the Susanne Corpus (Sampson, 1993), and the British section of the ICE Corpus (Wallis and Nelson, 2006)) and Italian (with ISST (Montegmagni et al., 2000) and TUT (Bosco et al., 2000))",o,0,880,o,0,0.96397567,True,0.96397567,0.029560734,0.0064635794
"However, they use the (Ramshaw and Marcus, 1995) data set in a different training-test division (10-fold cross validation) which makes it (tifficult to compare their results with others",o,0,881,n,2,0.81531507,False,0.14389409,0.040790837,0.81531507
"As in the work of (Ramshaw and Marcus, 1995), each word or punctuation mark within a sentence is labeled with IOB tag together with its function type",o,0,882,o,0,0.95476985,True,0.95476985,0.03315252,0.012077607
"(Johnson [1997] notes that this structure has a higher probability than the correct, flat structure, given counts taken from the treebank for a standard PCFG)",o,0,883,n,2,0.667143,False,0.28111014,0.05174686,0.667143
"Our evaluation metric is case-insensitive BLEU-4 (Papineni et al. 2002), as defined by NIST, that is, using the shortest (as opposed to closest) reference sentence length for the brevity penalty",o,0,884,o,0,0.9693564,True,0.9693564,0.025111152,0.0055323723
"Many statistical translation models (Brown et al. , 1993; Vogel et al. , 1996; Och and Ney, 2000b) try to model word-to-word correspondences between source and target words",o,0,885,o,0,0.9492928,True,0.9492928,0.0436134,0.007093883
"Following Wu (1997), the prevailing opinion in the research community has been that more complex patterns of word alignment in real bitexts are mostly attributable to alignment errors",o,0,886,o,0,0.57711536,True,0.57711536,0.31492338,0.10796129
"We use the same preprocessing steps as Turian and Melamed (2005): during both training and testing, the parser is given text POS-tagged by the tagger of Ratnaparkhi (1996), with capitalization stripped and outermost punctuation removed",o,0,887,o,0,0.96164495,True,0.96164495,0.034236338,0.004118629
"Instead of directly minimizing error as in earlier work (Och, 2003), we decompose the decoding process into a sequence of local decision steps based on Eq",o,0,888,o,0,0.9148412,True,0.9148412,0.03552424,0.04963459
"It has the advantage of naturally capturing local reorderings and is shown to outperform word-based machine translation (Koehn et al. , 2003)",n,2,889,p,1,0.38873237,False,0.23870303,0.38873237,0.37256467
"Our approach permits an alternative to minimum error-rate training (MERT; Och, 2003); it is discriminativebuthandleslatentstructureandregularization in more principled ways",o,0,890,o,0,0.6980373,True,0.6980373,0.22474621,0.07721644
"(2006) tried a different generative phrase translation model analogous to IBM word-translation Model 3 (Brown et al. , 1993), and again found that the standard model outperformed their generative model",n,2,891,n,2,0.61878335,True,0.29250672,0.08870998,0.61878335
"(2000) that draws on a stochastic tagger (see (Cutting et al. , 1992) for details) as well as the SPECIALIST Lexicon5, a large syntactic lexicon of both general and medical English that is distributed with the UMLS",o,0,892,o,0,0.9469097,True,0.9469097,0.05031933,0.0027710309
"4 Evaluation The evaluation is conducted with all four corpora from Bakeoff-3 (Levow, 2006), as summarized in Table 1 with corpus size in number of characters",o,0,893,o,0,0.95753586,True,0.95753586,0.035974417,0.0064897407
"The POS tag features were produced by rst predicting the tags with Ratnaparkhis Maximum Entropy Tagger (Ratnaparkhi, 1996) and then clustered by hand into a smaller number of groups based on their syntactic role",o,0,894,o,0,0.9624738,True,0.9624738,0.033958748,0.0035674484
"In one set of experiments, we generated lexicons for PEOPLE and ORGANIZATIONS using 2500 Wall Street Journal articles from the Penn Treebank (Marcus et al. , 1993)",o,0,895,o,0,0.96987355,True,0.96987355,0.026559496,0.0035669003
"In their seminal work, (Pang et al., 2002) demonstrated that supervised learning signi cantly outperformed a competing body of work where hand-crafted dictionaries are used to assign sentiment labels based on relative frequencies of positive and negative terms",p,1,896,n,2,0.37379378,False,0.2542332,0.37197307,0.37379378
"But without the global normalization, the maximumlikelihood criterion motivated by the maximum entropy principle (Berger et al. , 1996) is no longer a feasible option as an optimization criterion",n,2,897,n,2,0.7793627,True,0.180915,0.03972235,0.7793627
"For this experiment, we used sections 02 21 of the Penn Treebank (PTB) (Marcus et al. , 1993) as the training data and section 23 (2416 sentences) for evaluation, as is now standard",o,0,898,o,0,0.95694375,True,0.95694375,0.040109992,0.0029462744
"The OP data consists of 2,452 documents from the Penn Treebank (Marcus et al. , 1993)",o,0,899,o,0,0.9538861,True,0.9538861,0.03485575,0.0112581365
"For comparison, Haghighi and Klein (2006) report an unsupervised baseline of 41.3%, and a best result of 80.5% from using hand-labeled prototypes and distributional similarity",o,0,900,o,0,0.9174982,True,0.9174982,0.070456825,0.012044917
"We obtained word alignments of training data by first running GIZA++ (Och and Ney, 2003) and then applying the refinement rule grow-diag-final-and (Koehn et al., 2003)",o,0,901,o,0,0.9644425,True,0.9644425,0.031714875,0.0038426397
"Other work aims to do truly unsupervised learning of taggers, such as Goldwater and Griffiths (2007) and Johnson (2007)",o,0,902,o,0,0.6552507,True,0.6552507,0.30771026,0.037038986
1418 examples of structures of the kind 'VB N1 PREP N2' were extracted from the Penn-TreeBank Wall Street Journal (Marcus et al. 1993,o,0,903,o,0,0.9641017,True,0.9641017,0.03175305,0.0041453117
"During evaluation two performance metrics, BLEU (Papineni et al. , 2002) and NIST, were computed",o,0,904,o,0,0.94374937,True,0.94374937,0.048021566,0.008229071
"(2007) observe that their predominant sense method is not performing as well for 3We use the Lesk (overlap) similarity as implemented by the WordNet::similarity package (Pedersen et al., 2004)",o,0,905,o,0,0.5170302,True,0.5170302,0.13576739,0.3472024
"The transcription probabilities can then be easily learnt from the alignments induced by GIZA++, using a scoring function (Koehn et al., 2003)",o,0,906,o,0,0.9412785,True,0.9412785,0.054045007,0.004676508
"(Pedersen et al. , 1996) and (Zipf, 1935))",o,0,907,o,0,0.9670532,True,0.9670532,0.02592887,0.0070179575
"We consider three class models, models S, M, and L, defined as pS(cj|c1cj1,w1wj1)=png(cj|cj2cj1) pS(wj|c1cj,w1wj1)=png(wj|cj) pM(cj|c1cj1,w1wj1)=png(cj|cj2cj1,wj2wj1) pM(wj|c1cj,w1wj1)=png(wj|wj2wj1cj) pL(cj|c1cj1,w1wj1)=png(cj|wj2cj2wj1cj1) pL(wj|c1cj,w1wj1)=png(wj|wj2cj2wj1cj1cj) Model S is an exponential version of the class-based n-gram model from (Brown et al., 1992); model M is a novel model introduced in (Chen, 2009); and model L is an exponential version of the model indexpredict from (Goodman, 2001)",o,0,908,o,0,0.97327167,True,0.97327167,0.023113776,0.0036145237
"The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004)",o,0,909,o,0,0.9694244,True,0.9694244,0.027471934,0.0031035976
"Parsers Precision(a4 ) Recall(a4 ) a5a7a6 (a4 ) a8KM00 a9 93.45 93.51 93.48 a8Hal00 a9 93.13 93.51 93.32 a8CSCL a9 * 93.41 92.64 93.02 a8TKS00 a9 94.04 91.00 92.50 a8ZST00 a9 91.99 92.25 92.12 a8Dej00 a9 91.87 91.31 92.09 a8Koe00 a9 92.08 91.86 91.97 a8Osb00 a9 91.65 92.23 91.94 a8VB00 a9 91.05 92.03 91.54 a8PMP00 a9 90.63 89.65 90.14 a8Joh00 a9 86.24 88.25 87.23 a8VD00 a9 88.82 82.91 85.76 Baseline 72.58 82.14 77.07 2.2 Data Training was done on the Penn Treebank (Marcus et al. , 1993) Wall Street Journal data, sections 02-21",o,0,910,o,0,0.95195776,True,0.95195776,0.038872167,0.009170049
"Templates for local features are similar to the ones employed by Ratnaparkhi (1996) for POS-tagging (Table 3), though as our input already includes POStags, we can make use of part-of-speech information as well",o,0,911,o,0,0.92147297,True,0.92147297,0.06715175,0.011375275
"For example, Hindle (1990) used cooccurrences between verbs and their subjects and objects, and proposed a similarity metric based on mutual information, but no exploration concerning the effectiveness of other kinds of word relationship is provided, although it is extendable to any kinds of contextual information",p,1,912,o,0,0.9037504,False,0.9037504,0.05623018,0.040019456
"1 Introduction Word alignment is an important step of most modern approaches to statistical machine translation (Koehn et al. , 2003)",o,0,913,p,1,0.92308277,False,0.07256669,0.92308277,0.004350527
"Similarlyto(Collins and Singer, 1999; Yarowsky, 1995), we define the strength of a pattern p in a category y as the precision of p in the set of documents labeled with category y, estimated using Laplace smoothing: strength(p,y) = count(p,y) + epsilon1count(p) + kepsilon1 (3) where count(p,y) is the number of documents labeled y containing pattern p, count(p) is the overall number of labeled documents containing p, and k is the number of domains",o,0,914,o,0,0.96699375,True,0.96699375,0.026303442,0.0067027127
"In particular, this method has been used for word sense disambiguation (Lin, 1997) and thesaurus construction (Lin, 1998)",o,0,915,o,0,0.7833011,True,0.7833011,0.21268374,0.0040151696
"2 Hierarchical Clustering of Words Several algorithms have been proposed for automatically clustering words based on a large corpus (Jardino and Adda 91, Brown et al. 1992, Kneser and Ney 1993, Martin et al. 1995, Ueberla 1995)",o,0,916,o,0,0.9504014,True,0.9504014,0.046391167,0.0032074563
"Data-based Methods Data-based approaches extract their information directly from texts and are divided into supervised and unsupervised methods (Yarowsky, 1995; Stevenson, 2003)",o,0,917,o,0,0.9505941,True,0.9505941,0.04588239,0.003523416
"A few exceptions are the hierarchical (possibly syntax-based) transduction models (Wu, 1997; Alshawi et al. , 1998; Yamada and Knight, 2001; Chiang, 2005) and the string transduction models (Kanthak et al. , 2005)",o,0,918,o,0,0.92984015,True,0.92984015,0.0656206,0.004539183
"When conditioning on words, we treated each word feature individually, as this proved to be useful in (Titov and Henderson, 2007b)",p,1,919,p,1,0.7896679,True,0.20260553,0.7896679,0.0077265264
"For instance (Chiang, 2000), (Xia, 2001) (Chen, 2001) all automatically acquire large TAGs for English from the Penn Treebank (Marcus et al. , 1993)",o,0,920,o,0,0.9394689,True,0.9394689,0.05054325,0.009987851
"In the supervised condition, we used just 2 additional task instances, plant and tank, each with 4000 handannotated instances drawn from a large balanced corpus (Yarowsky, 1995)",o,0,921,o,0,0.9255548,True,0.9255548,0.062353674,0.012091501
"Inversion Transduction Grammar (ITG) is the model of Wu (1997), Tree-to-String is the model of Yamada and Knight (2001), and Tree-to-String, Clone allows the node cloning operation described above",o,0,922,o,0,0.95712924,True,0.95712924,0.038532633,0.0043381765
"With the exception of Fraser and Marcu (2006), these previous publications do not entirely discard the generative models in that they integrate IBM model predictions as features",o,0,923,o,0,0.62081355,True,0.62081355,0.098611414,0.2805751
"Unfortunately, as shown in (Okanohara and Tsujii, 2007), with the represetation of sentences that we use, linear classifiers cannot discriminate real sentences from sentences sampled from a trigram, which is the model we use as a baseline, so here we resort to a non-linear large-margin classifier (see section 3 for details)",o,0,924,o,0,0.7864469,True,0.7864469,0.07584244,0.13771063
"We also used the following resources: the Charniak parser (Charniak, 2000) to carry out the syntactic analysis; the wn::similaritypackage (Pedersen et al. , 2004) to compute the Jiang&Conrath (J&C) distance (Jiang and Conrath, 1997) needed to implement the lexical similarity siml(T,H) as defined in (Corley and Mihalcea, 2005); SVM-lightTK (Moschitti, 2004) to encode the basic tree kernel function, KT, in SVM-light (Joachims, 1999)",o,0,925,o,0,0.9671182,True,0.9671182,0.029857282,0.0030244903
"4 Optimizing Metric Parameters The original version of Meteor (Banerjee and Lavie, 2005) has instantiated values for three parameters in the metric: one for controlling the relative weight of precision and recall in computing the Fmean score (); one governing the shape of the penalty as a function of fragmentation () and one for the relative weight assigned to the fragmentation penalty ()",o,0,926,o,0,0.9571123,True,0.9571123,0.038151093,0.0047366354
"When evaluated against the state-of-the-art, phrase-based decoder Pharaoh (Koehn, 2004), using the same experimental conditions  translation table trained on the FBIS corpus (7.2M Chinese words and 9.2M English words of parallel text), trigram language model trained on 155M words of English newswire, interpolation weights a65 (Equation 2) trained using discriminative training (Och, 2003) (on the 2002 NIST MT evaluation set), probabilistic beam a90 set to 0.01, histogram beam a58 set to 10  and BLEU (Papineni et al. , 2002) as our metric, the WIDL-NGLM-Aa86 a129 algorithm produces translations that have a BLEU score of 0.2570, while Pharaoh translations have a BLEU score of 0.2635",o,0,927,o,0,0.8105194,True,0.8105194,0.17392302,0.015557616
"However, recent progress in machine translation and the continuous improvement on evaluation metrics such as BLEU (Papineni et al. , 2002) suggest that SMT systems are already very good at choosing correct word translations",o,0,928,p,1,0.65802366,False,0.29819182,0.65802366,0.043784503
"Mutual information MI(x,y) is defined as following (Church and Hanks, 1990): )()( ),( log )()( ),( log),( 22 yfxf yxfN ypxp yxp yxMI  == (4) where f(x) and f(y) are frequency of term x and term y, respectively",o,0,929,o,0,0.9691749,True,0.9691749,0.026093833,0.004731203
"A number of systems for automatically learning semantic parsers have been proposed (Ge and Mooney, 2005; Zettlemoyer and Collins, 2005; Wong and Mooney, 2007; Lu et al., 2008)",o,0,930,o,0,0.9410229,True,0.9410229,0.05604566,0.0029314086
"We ran the decoder with its default settings and then used Moses implementation of minimum error rate training (Och, 2003) to tune the feature weights on the development set",o,0,931,o,0,0.9632894,True,0.9632894,0.03176311,0.0049474365
"This scoring function has been successfully applied to resolve ambiguity problems in an English-to-Chinese machine translation system (BehaviorTran) (Chen et al. 1991) and a spoken language processing system (Su, Chiang, and Lin 1991; 1992)",o,0,932,p,1,0.9119798,False,0.08031291,0.9119798,0.007707396
"For classi cation, we use a maximum entropy model (Berger et al., 1996), from the logistic regression package in Weka (Witten and Frank, 2005), with all default parameter settings",o,0,933,o,0,0.9617137,True,0.9617137,0.03460857,0.0036777845
"This iterative optimiser, derived from a word disambiguation technique (Yarowsky, 1995), finds the nearest local maximum in the lexical cooccurrence network from each concept seed",o,0,934,o,0,0.94988936,True,0.94988936,0.044835526,0.0052750395
"3.1 Regeneration with Re-decoding One way of regeneration is by running the decoding again to obtain new hypotheses through a re-decoding process (Rosti et al., 2007a)",o,0,935,o,0,0.95288557,True,0.95288557,0.03814815,0.008966355
"However, the only known work which automates part of a customer service center using natural language dialogue is the one by Chu-Carroll and Carpenter (1999)",p,1,936,p,1,0.67920214,True,0.2897064,0.67920214,0.031091498
"Finally, recent efforts have also looked at transfer learning mechanisms for sentiment analysis, e.g., see (Blitzer et al., 2007)",o,0,937,o,0,0.9109911,True,0.9109911,0.083727725,0.0052811424
"3.2 Evaluation Metrics AER (Alignment Error Rate) (Och and Ney, 2003) is the most widely used metric of alignment quality, but requires gold-standard alignments labelled with sure/possible annotations to compute; lacking such annotations, we can compute alignment fmeasure instead",n,2,938,n,2,0.64153165,True,0.16184859,0.1966198,0.64153165
"One popular approach is to use a log-linear parsing model and maximise the conditional likelihood function (Johnson et al. , 1999; Riezler et al. , 2002; Clark and Curran, 2004b; Malouf and van Noord, 2004; Miyao and Tsujii, 2005)",o,0,939,p,1,0.50492907,False,0.48891634,0.50492907,0.0061545484
"For instance, the to-PP frame is poorly' represented in the syntactically annotated version of the Penn Treebank (Marcus et al. , 1993)",o,0,940,n,2,0.48109427,False,0.46492845,0.05397728,0.48109427
"The following treebanks were used for training the parser: (Aduriz et al. , 2003; Bhmov et al. , 2003; Chen et al. , 2003; Haji et al. , 2004; Marcus et al. , 1993; Mart et al. , 2002; Montemagni et al. 2003; Oflazer et al. , 2003; Prokopidis et al. , 2005; Csendes et al. , 2005)",o,0,941,o,0,0.9732956,True,0.9732956,0.02187354,0.004830857
"As is common (Collins, 1997; Johnson, 1998; Klein and Manning, 2003; Schmid, 2006), the treebank is first transformed in various ways, in order to give an accurate PCFG",o,0,942,o,0,0.89455163,True,0.89455163,0.09775413,0.007694172
"Successful discriminative parsers have used generative models to reduce training time and raise accuracy above generative baselines (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004)",o,0,943,p,1,0.61019945,False,0.3715532,0.61019945,0.018247357
"3 Evaluation of Algorithms All four algorithms were run on a 3900 utterance subset of the Penn Treebank annotated corpus (Marcus et al. , 1993) provided by Charniak and Ge (1998)",o,0,944,o,0,0.9703561,True,0.9703561,0.025241593,0.004402424
"While the former is piecewise constant and thus cannot be optimized using gradient techniques, Och (2003) provides an approach that performs such training efficiently",p,1,945,o,0,0.6542493,False,0.6542493,0.2562077,0.089543
"Although this study falls under the general topic of discourse modeling, our work differs from previous attempts to characterize text in terms of domainindependent rhetorical elements (McKeown, 1985; Marcu and Echihabi, 2002)",o,0,946,n,2,0.48467872,False,0.44498342,0.07033788,0.48467872
"Following Church & Hanks (1990), Rapp (2004), and Wettler et al",o,0,947,o,0,0.96066254,True,0.96066254,0.03384936,0.005488111
"The X 2 statistic is performing at least as well as G 2, and the results show that the average level of generalization is slightly higher for G 2 than X 2 . This suggests a possible explanation for the results presented here and those in Dunning (1993): that the X 2 statistic provides a less conservative test when counts in the contingency table are low",o,0,948,o,0,0.60942674,True,0.60942674,0.1484558,0.24211748
"Methods 4.1 Experiment 1: Held out data To examine the generalizability of classifiers trained on the automatically generated data, a C4.5 decision tree classifier (Quinlan, 1993) was trained and tested on the held out test set described above",o,0,949,o,0,0.9382994,True,0.9382994,0.054359503,0.00734106
he corresponding weight is trained through minimum error rate method (Och 2003,o,0,950,o,0,0.95712686,True,0.95712686,0.036360722,0.006512358
he above observations can be stated formally from the perspective of Brown et al.'s (1993) Model ,o,0,951,o,0,0.8834516,True,0.8834516,0.10849114,0.0080572385
"eBonsai first performs syntactic analysis of a sentence using a parser based on GLR algorithm (MSLR parser) (Tanaka et al. , 1993), and provides candidates of its syntactic structure",o,0,952,o,0,0.9610082,True,0.9610082,0.03536658,0.0036251831
"2 Statistical Machine Translation We use a log-linear approach (Och, 2003) in which a foreign language sentence f is translated into another language, for example English, e, by seeking a maximum solution: e = argmax e wT h( f, e) (1) where h( f, e) is a large-dimension feature vector",o,0,953,o,0,0.96206033,True,0.96206033,0.03476185,0.0031777916
"(Brown et al., 1992) is one of the first works to use statistical methods of distributional analysis to induce clusters of words",o,0,954,p,1,0.7989488,False,0.18783107,0.7989488,0.013220047
"Johnson (2007) compared two Bayesian inference algorithms, Variational Bayes and what we call here a point-wise collapsed Gibbs sampler, and found that Variational Bayes produced the best solution, and that the Gibbs sampler was extremely slow to converge and produced a worse solution than EM",o,0,955,o,0,0.6470173,True,0.6470173,0.16440237,0.1885803
"Our work builds upon Turneys work on semantic orientation (Turney, 2002) and synonym learning (Turney, 2001), in which he used a PMI-IR algorithm to measure the similarity of words and phrases based on Web queries",o,0,956,o,0,0.9401547,True,0.9401547,0.05484394,0.005001392
"In the first, a separate language model is trained on each column of the database and these models are then used to segment and label a given text sequence (Agichtein and Ganti, 2004; Canisius and Sporleder, 2007)",o,0,957,o,0,0.963295,True,0.963295,0.03296315,0.0037418436
"In (Matsuzaki et al. , 2005) non-terminals in a standard PCFG model are augmented with latent variables",o,0,958,o,0,0.97017515,True,0.97017515,0.0252924,0.004532464
"Each element of the resulting vector was replaced with its log-likelihood value (see Definition 10 in Section 2.3) which can be considered as an estimate of how surprising or distinctive a co-occurrence pair is (Dunning, 1993)",o,0,959,o,0,0.8607128,True,0.8607128,0.1184637,0.02082348
"They mention that the resulting shallow parse tags are somewhat different than those used by Ramshaw and Marcus (1995), but that they found no significant accuracy differences in training on either set",o,0,960,o,0,0.67812747,True,0.67812747,0.05902311,0.26284945
"Formal complexity analysis has not been carried out, but my algorithm is simpler, at least conceptually, than the variable-word-order parsers of Johnson (1985), Kashket (1986), and Abramson and Dahl (1989)",n,2,961,n,2,0.776638,True,0.1680828,0.05527917,0.776638
"3 Algorithm As in previous work (Rapp, 2002), our computations are based on a partially lemmatized version of the British National Corpus (BNC) which has the function words removed",o,0,962,o,0,0.9553947,True,0.9553947,0.036010273,0.008595055
": there is : want to : need not : in front of : as soon as : look at Figure 2: Examples of entries from the manually developed dictionary 4 Experimental Setting 4.1 Evaluation The intrinsic quality of word alignment can be assessed using the Alignment Error Rate (AER) metric (Och and Ney, 2003), that compares a systems alignment output to a set of gold-standard alignment",o,0,963,o,0,0.9294182,True,0.9294182,0.0617072,0.008874586
"Wordalignment, however, isalmost exclusively done using statistics (Brown et al. , 1993; Hiemstra, 1996; Vogel et al. , 1999; Toutanova et al. , 2002)",o,0,964,o,0,0.84933877,True,0.84933877,0.063386016,0.087275304
"757 hbps strong tendency to overestimate the probability of rare bi-phrases; it is computed as in equation (2), except that bi-phrase probabilities are computed based on individual word translation probabilities, somewhat as in IBM model 1 (Brown et al. , 1993): Pr(t|s) = 1|s||t| productdisplay tt summationdisplay ss Pr(t|s)  The target language feature function htl: this is based on a N-gram language model of the target language",o,0,965,o,0,0.9396445,True,0.9396445,0.038257122,0.022098321
"The original Ramshaw and Marcus (1995) publication evaluated their NP chunker on two data sets, the second holding a larger amount of training data (Penn Treebank sections 02-21) while using 00 as test data",o,0,966,o,0,0.93217266,True,0.93217266,0.046139006,0.021688364
"It has been shown that phrasal machine translation systems are not affected by the quality of the input word alignments (Koehn et al. , 2003)",o,0,967,o,0,0.5994979,True,0.5994979,0.13127491,0.26922712
"(Yarowsky, 1995), whose training corpus for the noun drug was 9 times bigger than that of Karov and Edelman, reports 91.4% correct performance improved to impressive 93.9% when using the """"one sense per discourse"""" constraint",p,1,968,n,2,0.39283824,False,0.37732798,0.22983384,0.39283824
"Second, benefits for sentiment analysis can be realized by decomposing the problem into S/O (or neutral versus polar) and polarity classification (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al., 2005a; Kim and Hovy, 2006)",p,1,969,o,0,0.77881473,False,0.77881473,0.21136236,0.009822997
"That is obtained using the Viterbi alignment provided by a translation model as described in (Brown et al. , 1993)",o,0,970,o,0,0.9660609,True,0.9660609,0.029602988,0.0043361066
"Moses uses standard external tools for some of these tasks, such as GIZA++ (Och and Ney, 2003) for word alignments and SRILM (Stolcke, 2002) for language modeling",o,0,971,o,0,0.93994164,True,0.93994164,0.055912968,0.00414536
"For the current work, the Log-likelihood coefficient has been employed (Dunning, 1993), as it is reported to perform well among other scoring methods (Daille, 1995)",p,1,972,p,1,0.78438187,True,0.18639801,0.78438187,0.0292201
"We also have an additional held-out translation set, the development set, which is employed by the MT system to train the weights of its log-linear model to maximize BLEU (Och 2003)",o,0,973,o,0,0.93513626,True,0.93513626,0.05880417,0.006059515
"The other intriguing issue is how our anchor-based method for shared argument identification can benefit from recent advances in coreference and zero-anaphora resolution (Iida et al., 2006; Komachi et al., 2007, etc.)",o,0,974,p,1,0.61791354,False,0.29302406,0.61791354,0.08906236
"Following extraction, O-CRF applies the RESOLVER algorithm (Yates and Etzioni, 2007) to find relation synonyms, the various ways in which a relation is expressed in text",o,0,975,o,0,0.97193456,True,0.97193456,0.024077803,0.0039876206
"They have used the (Ramshaw and Marcus, 1995) representation as well (IOB1)",o,0,976,o,0,0.94890076,True,0.94890076,0.045688972,0.0054103406
"1510 5 Related Work In recent years, many research has been done on extracting relations from free text (e.g., (Pantel and Pennacchiotti, 2006; Agichtein and Gravano, 2000; Snow et al., 2006)); however, almost all of them require some language-dependent parsers or taggers for English, which restrict the language of their extractions to English only (or languages that have these parsers)",o,0,977,o,0,0.8740443,True,0.8740443,0.06728397,0.0586718
"To this purpose, different authors (Papineni et al., 1998; Och and Ney, 2002) propose the use of the so-called log-linear models, where the decision rule is given by the expression y = argmax y Msummationdisplay m=1 mhm(x,y) (3) where hm(x,y) is a score function representing an important feature for the translation of x into y, M is the number of models (or features) and m are the weights of the log-linear combination",o,0,978,o,0,0.9388043,True,0.9388043,0.05802742,0.003168318
"This method of co-training has been previously applied to a variety of natural language tasks, such as word sense disambiguation (Yarowsky, 1995), lexicon construction for information extraction (Riloff and Jones, 1999), and named entity classification (Collins and Singer, 1999)",o,0,979,o,0,0.6790576,True,0.6790576,0.3176469,0.003295576
"3.3 CRFs and Perceptron Learning Perceptron training for conditional models (Collins, 2002) is an approximation to the SGD algorithm, using feature counts from the Viterbi label sequence in lieu of expected feature counts",o,0,980,o,0,0.9645054,True,0.9645054,0.029189605,0.0063049938
"org/pubs/citations/ j ournals/toms/1986-12-2/p154-meht a/ Mutual Information Given the definition of Mutual Information (Church and Hanks 1990), I(x,y) = log 2 P(x,y) P(x)P(y)"""" we consider the distribution of a window word according to the contingency table (a) in Table 4",o,0,981,o,0,0.9709317,True,0.9709317,0.025207287,0.0038609467
"Recentworkconsidersadamagedtagdictionary by assuming that tags are known only for words that occur more than once or twice (Toutanova and Johnson, 2007)",o,0,982,o,0,0.94358325,True,0.94358325,0.03950174,0.01691499
"Hyperparameter  is automatically selected from 2Although Kanayama and Nasukawa (2006) that  for their dataset similar to ours was 0.83, this value cannot be directly compared with our value because their dataset includes both individual words and pairs of words",o,0,983,n,2,0.66206807,False,0.3207811,0.017150855,0.66206807
"During training, the early update strategy of Collins and Roark (2004) is used: when the correct state item falls out of the beam at any stage, parsing is stopped immediately, and the model is updated using the current best partial item",o,0,984,o,0,0.90811825,True,0.90811825,0.08004121,0.01184056
"For instance, the HALOGEN statistical realizer [LangkildeGeary, 2002] underwent the most comprehensive evaluation of any surface realizer, which was conducted by measuring sentences extracted from the Penn TreeBank [Marcus et al. , 1993], converting them into its input formalism, and then producing output strings",o,0,985,p,1,0.5868614,False,0.40255654,0.5868614,0.010582097
"Of course, many applications require smoothing of the estimated distributionsthis problem also has known solutions in MapReduce (Brants et al., 2007)",o,0,986,p,1,0.5723367,False,0.4090306,0.5723367,0.018632786
"The intuition is that the produced clusters will be less sense-conflating than those produced by other graph-based approaches, since collocations provide strong and consistent clues to the senses of a target word (Yarowsky, 1995)",o,0,987,o,0,0.5934437,True,0.5934437,0.3156376,0.090918705
"In order to extract the linguistic features necessary for the model, all sentences were first automatically part-of-speech-tagged using a maximum entropy tagger (Ratnaparkhi, 1998) and parsed using the Collins parser (Collins, 1997)",o,0,988,o,0,0.95585746,True,0.95585746,0.039869003,0.0042735827
"Banko and Etzioni (2008) studied open domain relation extraction, for which they manually identified several common relation patterns",o,0,989,o,0,0.9619714,True,0.9619714,0.03377776,0.004250811
"In this paper, we make a direct comparison of a syntactically unsupervised alignment model, based on Wu (1997), with a syntactically supervised model, based on Yamada and Knight (2001)",o,0,990,o,0,0.9512331,True,0.9512331,0.03763832,0.011128584
"The dependency trees induced when each rewrite rule in an i-th order LCFRS distinguish a unique head can similarly be characterized by being of gap-degree i, so that i is the maximum number of gaps that may appear between contiguous substrings of any subtree in the dependency tree (Kuhlmann and Mohl, 2007)",o,0,991,o,0,0.952028,True,0.952028,0.03838931,0.009582722
"More recently, Ramshaw & Marcus (In press) apply transformation-based learning (Brill, 1995) to the problem",o,0,992,o,0,0.7060956,True,0.7060956,0.286405,0.0074994434
A natural fit to the existing statistical machine translation framework  A metric that ranks a good translation high in an nbest list could be easily integrated in a minimal error rate statistical machine translation training framework (Och 2003,o,0,993,p,1,0.6472809,False,0.33910027,0.6472809,0.013618814
"to estimale a model (clustering words), and measured the I(L distancd ~ between 'l'he K\], distance (relative Clt|,l:Opy), which is widely used in information theory and sta, tist, ics, is a, nleasur,2 of 'dista, n<:c' l>~\[,wcen two distributions 5.2 Experiment 2: Qualitative Evaluation We extracted roughly 180,000 case fl:anles from the bracketed WSJ (Wall Street Journal) corpus of the Penn Tree Bank (Marcus et al. , 1993) as co-occurrence data",o,0,994,o,0,0.9122919,True,0.9122919,0.08510533,0.0026027926
"Past work has synchronously binarized such rules for efficiency (Zhang et al., 2006; Huang et al., 2008)",o,0,995,o,0,0.9369588,True,0.9369588,0.05348024,0.009560866
"For the IBM models defined by a pioneering paper (Brown et al. , 1993), a decoding algorithm based on a left-to-right search was described in (Berger et al. , 1996)",p,1,996,o,0,0.85766464,False,0.85766464,0.13649972,0.00583561
"However, these unsupervised methodologies show a major drawback by extracting quasi-exact or even exact match pairs of sentences as they rely on classical string similarity measures such as the Edit Distance in the case of (Dolan et al., 2004) and Word N-gram Overlap for (Barzilay & Lee, 2003)",o,0,997,n,2,0.6402802,False,0.25580755,0.10391222,0.6402802
"To compare different clustering algorithms, results with the standard method of (Brown et al. , 1992) (SRILMs ngram-class) are also reported",o,0,998,o,0,0.92316294,True,0.92316294,0.06819267,0.008644362
"We evaluated the translation quality using the BLEU metric (Papineni et al. , 2002), as calculated by mteval-v11b.pl with its default setting except that we used case-sensitive matching of n-grams",o,0,999,o,0,0.96787906,True,0.96787906,0.0255674,0.006553439
"6 Related Work A large body of previous work exists on extending WORDNET with additional concepts and instances (Snow et al., 2006; Suchanek et al., 2007); these methods do not address attributes directly",o,0,1000,o,0,0.8031666,True,0.8031666,0.042607863,0.1542255
"We will briefly review the perceptron algorithm, and its convergence properties  see Collins (2002) for a full description",o,0,1001,o,0,0.9462465,True,0.9462465,0.044467732,0.009285738
"Unfortunately, a counterexample illustrated in (Boughorbel et al. , 2004) shows that the max function does not produce valid kernels in general",o,0,1002,n,2,0.48108512,False,0.434412,0.08450294,0.48108512
"918 English For English we used the Wall Street Journal section of the Penn Treebank (Marcus et al. , 1993)",o,0,1003,o,0,0.9653327,True,0.9653327,0.025431745,0.009235537
"The IBM translation models (Brown et al. , 1993) describe word reordering via a distortion model defined over word positions within sentence pairs",o,0,1004,o,0,0.9675941,True,0.9675941,0.028357895,0.00404811
"4.1 Data We used Penn-Treebank (Marcus et al. , 1993) data, presented in Table 1",o,0,1005,o,0,0.95059735,True,0.95059735,0.04273592,0.006666731
"Second, the word alignment is refined by a grow-diag-final heuristic (Koehn et al. , 2003)",o,0,1006,o,0,0.9606687,True,0.9606687,0.0345678,0.00476353
"Roget's has been used as the sense division in two recent WSD works (Yarowsky 1992; Luk 1995) more or less as is, except for a small number of senses added to fill gaps",o,0,1007,o,0,0.8411256,True,0.8411256,0.15124798,0.0076264003
"Besides the the case-sensitive BLEU-4 (Papineni et al., 2002) used in the two experiments, we design another evaluation metrics Reordering Accuracy (RAcc) for forced decoding evaluation",o,0,1008,o,0,0.94594777,True,0.94594777,0.044742234,0.009310042
"In the work of Smadja (1993) on extracting collocations, preference was given to constructions whose constituents appear in a fixed order, a similar (and more generally implemented) version of our assumption here that asymmetric constructions are more idiomatic than symmetric ones",o,0,1009,o,0,0.73470515,True,0.73470515,0.18449701,0.0807978
"To help our model learn that it is desirable to copy answer words into the question, we add to each corpus a list of identical dictionary word pairs w iw i . For each corpus, we use GIZA (Al-Onaizan et al. , 1999), a publicly available SMT package that implements the IBM models (Brown et al. , 1993), to train a QA noisy-channel model that maps flattened answer parse trees, obtained using the cut procedure described in Section 3.1, into questions",o,0,1010,o,0,0.918787,True,0.918787,0.071435444,0.009777517
"Using these patterns, we introduced verb form errors into AQUAINT, then re-parsed the corpus (Collins, 1997), and compiled the changes in the disturbed trees into a catalog",o,0,1011,o,0,0.9596808,True,0.9596808,0.036495592,0.0038236678
"translation systems (Och and Ney, 2004; Koehn et al., 2003) and use Moses (Koehn et al., 2007) to search for the best target sentence",o,0,1012,o,0,0.9676021,True,0.9676021,0.028130574,0.004267349
"Its success stories range from parsing (McClosky et al., 2006) to machine translation (Ueffing, 2006)",p,1,1013,p,1,0.5335425,True,0.45904493,0.5335425,0.0074125286
"It is therefore desirable to have dedicated servers to load parts of the LM3  an idea that has been exploited by (Zhang et al., 2006; Emami et al., 2007; Brants et al., 2007)",o,0,1014,o,0,0.7413818,True,0.7413818,0.24930374,0.009314409
"1 Introduction Conditional Maximum Entropy (maxent) models have been widely used for a variety of tasks, including language modeling (Rosenfeld, 1994), part-of-speech tagging, prepositional phrase attachment, and parsing (Ratnaparkhi, 1998), word selection for machine translation (Berger et al. , 1996), and finding sentence boundaries (Reynar and Ratnaparkhi, 1997)",o,0,1015,p,1,0.85039556,False,0.14777659,0.85039556,0.001827819
"For symmetrization, we found that Och and Neys refined technique described in (Och and Ney, 2003) produced the best AER for this data set under all experimental conditions",p,1,1016,p,1,0.64509374,True,0.30353272,0.64509374,0.05137349
"The annotation consists of four parts: 1) a context-free structure augmented with traces to mark movement and discontinuous constituents, 2) phrasal categories that are annotated as node labels, 3) a small set of grammatical functions that are annotated as extensions to the node labels, and 4) part-of-speech tags (Marcus et al. , 1993)",o,0,1017,o,0,0.9724701,True,0.9724701,0.023752341,0.0037774837
"But it makes obvious that (Ratnaparkhi et al. , 1994) were tackling a problem different from (Hindle and Rooth, 1993) given the fact that their baseline was at 59% guessing noun attachment (rather than 67% in the Hindle and Rooth experiments).3 Of course, the baseline is not a direct indicator of the difficulty of the disambiguation task",o,0,1018,n,2,0.6282124,False,0.32750753,0.044280063,0.6282124
"The models in the comparative study by Klein and Manning (2002) did not include such features, and so, again for consistency of comparison, we experimentally verified that our maximum entropy model (a) consistently yielded higher scores than when the features were not used, and (b) consistently yielded higher scores than nave Bayes using the same features, in agreement with Klein and Manning (2002)",o,0,1019,o,0,0.6117572,True,0.6117572,0.066655576,0.3215873
"Themodeling approachhere describedis discriminative, and is based on maximum entropy (ME) models, firstly applied to natural language problems in (Berger et al., 1996)",o,0,1020,o,0,0.9110179,True,0.9110179,0.08482066,0.004161563
"Table 3 compares precision, recall, and F scores for our system with CoNLL-2001 results training on sections 15-18 of the Penn Treebank and testing on section 21 (Marcus et al. , 1993)",o,0,1021,o,0,0.9509811,True,0.9509811,0.038076553,0.010942458
"It worked well for word segmentation alone (Zhang and Clark, 2007), even with an agenda size as small as 8, and a simple beam search algorithm also works well for POS tagging (Ratnaparkhi, 1996)",p,1,1022,p,1,0.73973054,True,0.23585558,0.73973054,0.024413913
"4.2 Experiments To build all alignment systems, we start with 5 iterations of Model 1 followed by 4 iterations of HMM (Vogel et al. , 1996), as implemented in GIZA++ (Och and Ney, 2003)",o,0,1023,o,0,0.95480454,True,0.95480454,0.04236287,0.0028325974
"3.3 System evaluation Since both the system translations and the reference translations are available for the tuning 43 set, we first compare each output to the reference translation using BLEU (Papineni et al., 2001) and METEOR (Banerjee and Lavie, 2005) and a combined scoring scheme provided by the ULC toolkit (Gimenez and Marquez, 2008)",o,0,1024,o,0,0.9561889,True,0.9561889,0.039152328,0.0046587014
"In this paper we report case-insensitive Bleu scores (Papineni et al., 2002), unless otherwise stated, calculated with the NIST tool, and caseinsensitive Meteor-ranking scores, without WordNet (Agarwal and Lavie, 2008)",o,0,1025,o,0,0.9564751,True,0.9564751,0.02529084,0.018234106
"Several authors have used mutual information and similar statistics as an objective function for word clustering (Dagan et al. , 1993; Brown et al. , 1992; Pereira et al. , 1993; Wang et al. , 1996), for automatic determination of phonemic baseforms (Lucassen & Mercer, 1984), and for language modeling for speech recognition (Ries ct al. , 1996)",o,0,1026,o,0,0.96437,True,0.96437,0.03193489,0.003695153
"One is how to learn a statistical model to estimate the conditional probability    , and the other is how to generate confusion set C of a given query q 4.1 Maximum Entropy Model for Query Spelling Correction We take a feature-based approach to model the posterior probability     . Specifically we use the maximum entropy model (Berger et al. , 1996) for this task:     = exp     ,   =1 exp(     (,  ) =1 ) (2) where exp(     (, ) =1 ) is the normalization factor;   , is a feature function defined over query q and correction candidate c, while   is the corresponding feature weight",o,0,1027,o,0,0.92311317,True,0.92311317,0.06589568,0.010991122
"We trained IBM Translation Model 4 (Brown et al. , 1993) both on our corpus alone and on the augmented corpus, using the EGYPT toolkit (Knight et al. , 1999; Al-Onaizan et al. , 1999), and then translated a number of texts using different translation models and different transfer methods, namely glossing (replacing each Tamil word by the most likely candidate from the translation tables created with the EGYPT toolkit) and Model 4 decoding (Brown et al. , 1995; Germann et al. , 2001)",o,0,1028,o,0,0.9656272,True,0.9656272,0.03070885,0.0036640135
"The success of recent high-quality parsers (Charniak, 1997; Collins, 1997) relies on the availability of such treebank corpora",p,1,1029,p,1,0.9254597,True,0.06333682,0.9254597,0.011203521
"Chiang (2005) distinguishes statistical MT approaches that are  syntactic in a formal sense, going beyond the  nite-state underpinnings of phrasebased models, from approaches that are syntactic in a linguistic sense, i.e. taking advantage of a priori language knowledge in the form of annotations derived from human linguistic analysis or treebanking.1 The two forms of syntactic modeling are doubly dissociable: current research frameworks include systems that are  nite state but informed by linguistic annotation prior to training (e.g., (Koehn and Hoang, 2007; Birch et al., 2007; Hassan et al., 2007)), and also include systems employing contextfree models trained on parallel text without bene t of any prior linguistic analysis (e.g",o,0,1030,o,0,0.9093851,True,0.9093851,0.07727068,0.013344295
P chunks (Abney 1991; Ramshaw and Marcus 1995; Evans and Zhai 1996; Frantzi and Ananiadou 1996) and technical terms (Dagan and Church 1994; Justeson and Katz 1995; Daille 1996; Jacquemin 2001; Bourigault et al. 2002) fall into this difficult-toassess categor,o,0,1031,o,0,0.9264902,True,0.9264902,0.06264951,0.010860305
albot and Brants (2008) used a Bloomier filter to encode a L,o,0,1032,o,0,0.9447056,True,0.9447056,0.052868977,0.0024254802
"2 Motivation Automatic subjectivity analysis methods have been used in a wide variety of text processing applications, such as tracking sentiment timelines in online forums and news (Lloyd et al. , 2005; Balog et al. , 2006), review classification (Turney, 2002; Pang et al. , 2002), mining opinions from product reviews (Hu and Liu, 2004), automatic expressive text-to-speech synthesis (Alm et al. , 2005), text semantic analysis (Wiebe and Mihalcea, 2006; Esuli and Sebastiani, 2006), and question answering (Yu and Hatzivassiloglou, 2003)",o,0,1033,o,0,0.6725851,True,0.6725851,0.3255587,0.0018562356
"Features that consider only target-side syntax and words without considering s can be seen as syntactic language model features (Shen et al., 2008)",o,0,1034,o,0,0.9651518,True,0.9651518,0.028345076,0.0065031415
"The reliability of the annotations was checked using the kappa statistic (Carletta, 1996)",o,0,1035,o,0,0.9655165,True,0.9655165,0.028366175,0.0061174156
"4 Experiments and evaluation We carried out an evaluation on the local rephrasing of French sentences, using English as the pivot language.2 We extracted phrase alignments of up to 7 word forms using the Giza++ alignment tool (Och and Ney, 2003) and the grow-diag-final-and heuristics described in (Koehn et al., 2003) on 948,507 sentences of the French-English part of the Europarl corpus (Koehn, 2005) and obtained some 42 million phrase pairs for which probabilities were estimated using maximum likelihood estimation",o,0,1036,o,0,0.9267823,True,0.9267823,0.06476524,0.008452423
"In order to build models that perform well in new (target) domains we usually find two settings (Daume III, 2007): In the semi-supervised setting the goal is to improve the system trained on the source domain using unlabeled data from the target domain, and the baseline is that of the system c2008",o,0,1037,o,0,0.91157645,True,0.91157645,0.08055224,0.007871293
"Some work has been done on adding new terms and relations to WordNet (Snow et al., 2006) and FACTOTUM (OHara and Wiebe, 2003)",o,0,1038,o,0,0.94414115,True,0.94414115,0.049818236,0.0060406877
"Please note that our approach is very different from other approaches to context dependent rule selection such as (Ittycheriah and Roukos, 2007) and (He et al., 2008)",o,0,1039,n,2,0.59935266,False,0.35028282,0.050364558,0.59935266
"The  statistic (Carletta, 1996) is recast as: (fs,w)(sys,sys) = agr(fs,w)(sys,sys) P agr(fs,)(sys,sys) N  P agr(fs,)(sys,sys) N In this modified form, (fs,w) represents the divergence in relative agreement wrt f s for target noun w, relative to the mean relative agreement wrt f s over all words",o,0,1040,o,0,0.95640844,True,0.95640844,0.03503762,0.008553908
"Their experiments were performed using a decoder based on IBM Model 4 using the translation techniques developed at IBM (Brown et al., 1993)",o,0,1041,o,0,0.9639226,True,0.9639226,0.032621242,0.0034561376
"We use the distributed training and application infrastructure described in (Brants et al., 2007) with modifications to allow the training of predictive class-based models and their application in the decoder of the machine translation system",o,0,1042,o,0,0.94991595,True,0.94991595,0.04640144,0.0036826741
esults This algorithm was applied to a fragment of the Canadian Hansards that has been used in a number of other studies: Church (1993) and Simard et al (1992,o,0,1043,o,0,0.86685324,True,0.86685324,0.1306199,0.0025268642
"1 Introduction Motivation: Sharing basic intuitions and longterm goals with other tasks within the area of Webbased information extraction (Banko and Etzioni, 2008; Davidov and Rappoport, 2008), the task of acquiring class attributes relies on unstructured text available on the Web, as a data source for extracting generally-useful knowledge",o,0,1044,o,0,0.8274764,True,0.8274764,0.16631581,0.0062077744
"In fact, many studies that try to exploit Wikipedia as a knowledge source have recently emerged (Bunescu and Pasca, 2006; Toral and Munoz, 2006; Ruiz-Casado et al. , 2006; Ponzetto and Strube, 2006; Strube and Ponzetto, 2006; Zesch et al. , 2007)",o,0,1045,o,0,0.7689397,True,0.7689397,0.22465003,0.0064102816
"Recently, an elegant approach to inference in discourse interpretation has been developed at a number of sites (e.g. , ltobbs et al. , 1988; Charniak and Goldman, 1988; Norvig, 1987), all based on tim notion of abduction, and we have begun to explore its potential application to machine translation",p,1,1046,p,1,0.7061757,True,0.28924844,0.7061757,0.0045758914
"The translation quality is evaluated by BLEU metric (Papineni et al., 2002), as calculated by mtevalv11b.pl with case-insensitive matching of n-grams, where n =4",o,0,1047,o,0,0.9699364,True,0.9699364,0.02649645,0.0035671312
"We viewed the seed word as a classified sentence, following a similar proposal in Yarowsky (1995)",o,0,1048,o,0,0.9603678,True,0.9603678,0.033843104,0.005789166
"We use three different kinds of metrics: DR-STM Semantic Tree Matching, a la Liu and Gildea (2005), but over DRS instead of over constituency trees",o,0,1049,o,0,0.93953234,True,0.93953234,0.036483023,0.023984635
"Automatic text summarization approaches have offered reasonably well-performing approximations for identifiying important sentences (Lin and Hovy, 2002; Schiffman et al., 2002; Erkan and Radev, 2004; Mihalcea and Tarau, 2004; Daume III and Marcu, 2006) but, not surprisingly, text (re)generation has been a major challange despite some work on sub-sentential modification (Jing and McKeown, 2000; Knight and Marcu, 2000; Barzilay and McKeown, 2005)",o,0,1050,p,1,0.81539947,False,0.13209055,0.81539947,0.052509934
"This was done for supervised parsing in different ways by Collins (1997), Klein and Manning (2003), and McDonald et al",o,0,1051,o,0,0.9464432,True,0.9464432,0.045635793,0.007920924
"Examples of such techniques are Markov Random Fields (Ratnaparkhi et al. , 1994; Abney, 1997; Della Pietra et al. , 1997; Johnson et al. , 1999), and boosting or perceptron approaches to reranking (Freund et al. , 1998; Collins, 2000; Collins and Duffy, 2002)",o,0,1052,o,0,0.9673236,True,0.9673236,0.029167216,0.0035092153
"Recently, many phrase reordering methods have been proposed, ranging from simple distancebased distortion model (Koehn  et al., 2003; Och and Ney, 2004), flat reordering model (Wu, 1997; Zens et al., 2004), lexicalized reordering model (Tillmann, 2004; Kumar and Byrne, 2005), to hierarchical phrase-based model (Chiang, 2005; Setiawan et al., 2007) and classifier-based reordering model with linear features (Zens and Ney, 2006; Xiong et al., 2006; Zhang et al., 2007a; Xiong et al., 2008)",o,0,1053,o,0,0.92695737,True,0.92695737,0.07057756,0.0024650698
"2.1 Training the model As with (Minnen et al. , 2000), we train the language model on the Penn Treebank (Marcus et al. , 1993)",o,0,1054,o,0,0.9717049,True,0.9717049,0.0219554,0.0063396627
"Kappa is defined as K = P(A)P(E)1P(E) (Carletta, 1996), where P(A) is the proportion of times that the labels agree, and P(E) is the proportion of times that they may agree by chance",o,0,1055,o,0,0.9619722,True,0.9619722,0.030132568,0.00789517
"Decoding used beam search with the cube pruning algorithm (Huang and Chiang, 2007)",o,0,1056,o,0,0.97056556,True,0.97056556,0.02422064,0.0052138395
"For automatic evaluation, we employed BLEU (Papineni et al., 2002) by following (Unno et al., 2006)",o,0,1057,o,0,0.96138155,True,0.96138155,0.03368074,0.0049376376
"11 This low agreement ratio is also re ected in a measure called the  statistic (Carletta, 1996;; Bruce and Wiebe, 1998;; Ng et al. , 1999)",o,0,1058,o,0,0.93945533,True,0.93945533,0.049755894,0.010788744
"1 Introduction Over the past decade, there has been tremendous progress on learning parsing models from treebank data (Collins, 1997; Charniak, 2000; Wang et al. , 2005; McDonald et al. , 2005)",p,1,1059,p,1,0.827923,True,0.16446689,0.827923,0.007610029
"3.4 Learning algorithm Maximum entropy (ME) models (Berger et al., 1996; Manning and Klein, 2003), also known as log-linear and exponential learning models, has been adopted in the SC classification task",o,0,1060,o,0,0.7858211,True,0.7858211,0.21129444,0.0028843721
"c2006 Association for Computational Linguistics Robust PCFG-Based Generation using Automatically Acquired LFG Approximations Aoife Cahill1 and Josef van Genabith1,2 1 National Centre for Language Technology (NCLT) School of Computing, Dublin City University, Dublin 9, Ireland 2 Center for Advanced Studies, IBM Dublin, Ireland {acahill,josef}@computing.dcu.ie Abstract We present a novel PCFG-based architecture for robust probabilistic generation based on wide-coverage LFG approximations (Cahill et al. , 2004) automatically extracted from treebanks, maximising the probability of a tree given an f-structure",o,0,1061,p,1,0.5305851,False,0.46233281,0.5305851,0.0070821256
"More specifically, two recent works have suggested using statistical data on lexical relations for resolving ambiguity of prepositional phrase attachment (Hindle and Rooth 1991) and pronoun references (Dagan and Itai 1990, 1991)",o,0,1062,o,0,0.9195879,True,0.9195879,0.07555812,0.004853912
"The reported results for the full parse tree (on section 23) are recall/precision of 88.1/87.5 (Collins, 1997)",o,0,1063,o,0,0.92940235,True,0.92940235,0.055808134,0.01478949
"Two metrics have become quite popular in multi-document summarization, namely the Pyramid method (Nenkova and Passonneau, 2004b) and ROUGE (Lin, 2004)",p,1,1064,p,1,0.93169075,True,0.06363496,0.93169075,0.004674298
"Bilingual lexicographers can work with bilingual concordancing software that can point them to instances of any link type induced from a bitext and display these instances sorted by their contexts (e.g. Simard, Foster, and Perrault 1993)",o,0,1065,o,0,0.93883973,True,0.93883973,0.05834213,0.0028180664
"The algorithm is essentially the same as the one introduced in (Collins, 2002)",o,0,1066,o,0,0.9485973,True,0.9485973,0.04590353,0.005499151
"1 Introduction In phrase-based statistical machine translation (Koehn et al., 2003) phrases extracted from word-aligned parallel data are the fundamental unit of translation",o,0,1067,o,0,0.93004924,True,0.93004924,0.06697893,0.0029717286
"Ramshaw and Marcus used transformationbased learning (TBL) for developing two chunkers (Ramshaw and Marcus, 1995)",o,0,1068,o,0,0.9620366,True,0.9620366,0.034507327,0.003456119
"As in other work, we collapsed AI)VP and Pl?Jl"""" to the same label when calculating these scores (see Collins 1997; I~,atnaparkhi 1999; Charniak 1997)",o,0,1069,o,0,0.9540776,True,0.9540776,0.038107384,0.007815098
"We estimate loss gradients (Equation 13) using a sample of the inference set, which gives a 100-fold increase in training speed (Turian & Melamed, 2006)",o,0,1070,o,0,0.868485,True,0.868485,0.09849144,0.033023488
"In natural language processing, recent years have seen ME techniques used for sentence boundary detection, part of speech tagging, parse selection and ambiguity resolution, and stochastic attribute-value grammars, to name just a few applications (Abney, 1997; Berger et al. , 1996; Ratnaparkhi, 1998; Johnson et al. , 1999)",o,0,1071,o,0,0.7389138,True,0.7389138,0.2573646,0.0037216444
"3.2 Conversion to Dependencies 3.2.1 Syntactic Dependencies There exists no large-scale dependency treebank for English, and we thus had to construct a dependency-annotated corpus automatically from the Penn Treebank (Marcus et al., 1993)",o,0,1072,o,0,0.85907394,True,0.85907394,0.06113183,0.07979423
"For example, the sentence My father is *work in the laboratory is parsed (Collins, 1997) as: (S (NP My father) (VP is (NP work)) (PP in the laboratory)) 2The abbreviations s (is or has) and d (would or had) compound the ambiguities",o,0,1073,o,0,0.9587523,True,0.9587523,0.03564613,0.0056016133
"Given the training pairs, any sequence predictor can be used, for example a Conditional Random Field (CRF) (Lafferty et al., 2001) or a structured perceptron (Collins, 2002)",o,0,1074,o,0,0.96495885,True,0.96495885,0.031614896,0.0034262296
"Preparing tagged corpora either by hand is labour-intensive and potentially error-prone, and although a semi-automatic approach can be used (Marcus et al. , 1993), it is a good thing to reduce the human involvement as much as possible",p,1,1075,n,2,0.70135415,False,0.16824155,0.13040434,0.70135415
"The heuristic estimator employs word-alignment (Giza++) (Och and Ney, 2003) and a few thumb rules for defining phrase pairs, and then extracts a multi-set of phrase pairs and estimates their conditional probabilities based on the counts in the multi-set",o,0,1076,o,0,0.9654338,True,0.9654338,0.03059747,0.0039686933
"The kappa statistic (Krippendorff, 1980; Carletta, 1996) has become the de facto standard to assess inter-annotator agreement",o,0,1077,p,1,0.6701494,False,0.32692385,0.6701494,0.002926792
"So far, research in automatic opinion recognition has primarily addressed learning subjective language (Wiebe et al. , 2004; Riloff et al. , 2003), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Yu and Hatzivassiloglou, 2003; Riloff et al. , 2003), and discriminating between positive and negative language (Pang et al. , 2002; Morinaga et al. , 2002; Yu and Hatzivassiloglou, 2003; Turney and Littman, 2003; Dave et al. , 2003; Nasukawa and Yi, 2003; Popescu and Etzioni, 2005; Wilson et al. , 2005)",o,0,1078,o,0,0.96211,True,0.96211,0.03377747,0.0041125803
"In most recent parsing work the history consists of a small number of manually selected features (Charniak, 1997; Collins, 1997)",o,0,1079,o,0,0.8945258,True,0.8945258,0.09914533,0.006328871
"1.2 Evaluation In this paper we report results using the BLEU metric (Papineni et al., 2002), however as the evaluation criterion in GALE is HTER (Snover et al., 2006), we also report in TER (Snover et al., 2005)",o,0,1080,o,0,0.94328403,True,0.94328403,0.041092373,0.015623583
"EMD training (Fraser and Marcu, 2006) combines generative and discriminative elements",o,0,1081,o,0,0.9498884,True,0.9498884,0.044722058,0.005389591
"RECALL F-SCORE Brackets 89.17 87.50 88.33 Dependencies 96.40 96.40 96.40 Brackets, revised 97.56 98.03 97.79 Dependencies, revised 99.27 99.27 99.27 Table 1: Agreement between annotators few weeks, and increased to about 1000 words per hour after gaining more experience (Marcus et al. , 1993)",o,0,1082,o,0,0.8655024,True,0.8655024,0.11559892,0.018898668
"There is also work on grouping senses of other inventories using information in the inventory (Dolan, 1994) along with information retrieval techniques (Chen and Chang, 1998)",o,0,1083,o,0,0.9669545,True,0.9669545,0.028545734,0.004499806
"We have also used ROUGE evaluation approach (Lin, 2004) which is based on n-gram co-occurrences between machine summaries and ideal human summaries",o,0,1084,o,0,0.9479361,True,0.9479361,0.047891382,0.00417246
"On the other hand, Kazama and Torisawa (2007) extracted hyponymy relations, which are independent of the NE categories, from Wikipedia and utilized it as a gazetteer",o,0,1085,o,0,0.96032953,True,0.96032953,0.03536858,0.0043019713
"To estimate combination weights, we extend the F 1 -score maximization training algorithm for LRM described in (Jansche, 2005)",o,0,1086,o,0,0.95182586,True,0.95182586,0.043661773,0.004512357
"Following initial work by (Sparck Jones, 1964) and (Grefenstette, 1994), an early, online distributional thesaurus presented in (Lin, 1998) has been widely used and cited, and numerous authors since have explored thesaurus properties and parameters: see survey component of (Weeds and Weir, 2005)",o,0,1087,p,1,0.81035244,False,0.18564503,0.81035244,0.004002513
"Recently, severalmethods(Collins and Roark, 2004; Daume III and Marcu, 2005; McDonald and Pereira, 2006) have been proposed with similar motivation to ours",o,0,1088,o,0,0.8286285,True,0.8286285,0.16372527,0.007646324
"However, at the short term, the incorporation of these type of features will force us to either build a new decoder or extend an existing one, or to move to a new MT architecture, for instance, in the fashion of the architectures suggested by Tillmann and Zhang (2006) or Liang et al",o,0,1089,o,0,0.90661556,True,0.90661556,0.06823704,0.025147477
"(DeRose, 1988; Cutting et al. , 1992; Church, 1988)",o,0,1090,o,0,0.9687902,True,0.9687902,0.023784088,0.0074257543
"Studies on self-training have focused mainly on generative, constituent based parsing (Steedman et al., 2003; McClosky et al., 2006; Reichart and Rappoport, 2007)",o,0,1091,o,0,0.94501233,True,0.94501233,0.051572822,0.0034149098
"Clark (2000) reports results on a corpus containing 12 million terms, Schcurrency1utze (1993) on one containing 25 million terms, and Brown, et al, (1992) on one containing 365 million terms",o,0,1092,o,0,0.96707,True,0.96707,0.025891365,0.0070386706
"Evaluation We evaluate translation output using three automatic evaluation measures: BLEU (Papineni et al., 2002), NIST (Doddington, 2002), and METEOR (Banerjee and Lavie, 2005, version 0.6).5 All measures used were the case-sensitive, corpuslevel versions",o,0,1093,o,0,0.96540445,True,0.96540445,0.030845454,0.0037500376
he model of Haghighi and Klein (2007) incorporated a latent variable for named entity clas,o,0,1094,o,0,0.9749107,True,0.9749107,0.020472134,0.004617285
itation texts have also been used to create summaries of single scientific articles in Qazvinian and Radev (2008) and Mei and Zhai (2008,o,0,1095,o,0,0.96254736,True,0.96254736,0.034932625,0.00252003
"7 Related Work There has been a recent interest in training methods that enable the use of first-order features (Paskin, 2002; Daume III and Marcu, 2005b; Richardson and Domingos, 2006)",o,0,1096,o,0,0.7571176,True,0.7571176,0.2380051,0.004877324
ustejovsky confronted with the problem of automatic acquisition more extensively in \[Pustejovsky et al. 1993\,o,0,1097,o,0,0.7566761,True,0.7566761,0.16484563,0.07847829
"It is potentially useful in other natural language processing tasks, such as the problem of estimating n-gram models (Brown et al. 1992) or the problem of semantic tagging (Cucchiarelli and Velardi 1997)",o,0,1098,p,1,0.50050944,False,0.48939282,0.50050944,0.010097684
2002) and Turney (2002) classified sentiment polarity of reviews at the document leve,o,0,1099,o,0,0.96026325,True,0.96026325,0.026145885,0.013590826
"Note that, since the FrameNet data does not include deep syntactic tree annotation, we processed the FrameNet data with Collins parser (Collins, 1997), consequently, the experiments on FrameNet relate to automatic syntactic parse trees",o,0,1100,o,0,0.93535817,True,0.93535817,0.0325261,0.03211578
"(Veenstra, 1998) used the Base-NP tag set as presented in (Ramshaw and Marcus, 1995): I for inside a Base-NP, O for outside a Base-NP, and B for the first word in a Base-NP following another Base-NP",o,0,1101,o,0,0.96724343,True,0.96724343,0.027198482,0.0055581788
"440 respondence learning (SCL) domain adaptation algorithm (Blitzer et al. , 2006) for use in sentiment classification",o,0,1102,o,0,0.97171164,True,0.97171164,0.02456505,0.0037232838
"Most of the previous work on statistical machine translation, as exemplified in (Brown et al. , 1993), employs word-alignment algorithm (such as GIZA++ (Och and Ney, 2003)) that provides local associations between source and target words",o,0,1103,o,0,0.90008086,True,0.90008086,0.09655017,0.0033689258
"For this reason, to our knowledge, all discriminative models proposed to date either side-step the problem by choosing simple model and feature structures, such that spurious ambiguity is lessened or removed entirely (Ittycheriah and Roukos, 2007; Watanabe et al., 2007), or else ignore the problem and treat derivations as translations (Liang et al., 2006; Tillmann and Zhang, 2007)",o,0,1104,o,0,0.75909775,True,0.75909775,0.114369035,0.12653318
"This set of words (rooted primarily in the verbs of the set) corresponds to the (Levin, 1993) Characterize (class 29.2), Declare (29.4), Admire (31.2), and Judgment verbs (33) and hence may have particular syntactic and semantic patterning",o,0,1105,o,0,0.9616719,True,0.9616719,0.031848457,0.006479694
here are two necessary ingredients to implement Ochs (2003) training procedur,o,0,1106,o,0,0.8365982,True,0.8365982,0.15612125,0.007280527
"In these experiments we used the MXPOST tagger (Ratnaparkhi, 1996) combined withCollinsparser(Collins,1996)toassignparse trees to the corpus",o,0,1107,o,0,0.95768553,True,0.95768553,0.039331064,0.0029833151
"Och (2003) claimed that this approximation achieved essentially equivalent performance to that obtained when directly using the loss as the objective, O = lscript",o,0,1108,o,0,0.8119069,True,0.8119069,0.15548567,0.03260749
"For instance, we may find metrics which compute similarities over shallow syntactic structures/sequences (Gimenez and M`arquez, 2007; Popovic and Ney, 2007), constituency trees (Liu and Gildea, 2005) and dependency trees (Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Owczarzak et al., 2007)",o,0,1109,o,0,0.96524584,True,0.96524584,0.028745087,0.0060091377
"For instance, we may find metrics based on full constituent parsing (Liu and Gildea, 2005), and on dependency parsing (Liu and Gildea, 2005; Amigo et al., 2006; Mehay and Brew, 2007; Owczarzak et al., 2007)",o,0,1110,o,0,0.9642308,True,0.9642308,0.030471807,0.0052974685
"4.1 The base line For our base line parse accuracy, we used the now standard division of the WSJ (see Collins 1997, 1999; Charniak 1997, 2000; Ratnaparkhi 1999) with sections 2 through 21 for training (approx",o,0,1111,o,0,0.8270475,True,0.8270475,0.15471624,0.018236207
"Because our system uses a synchronous CFG, it could be thought of as an example of syntax-based statistical machine translation (MT), joining a line of research (Wu 1997; Alshawi, Bangalore, and Douglas 2000; Yamada and Knight 2001) that has been fruitful but has not previously produced systems that can compete with phrase-based systems in large-scale translation tasks such as the evaluations held by NIST",o,0,1112,n,2,0.39496642,False,0.3236239,0.28140965,0.39496642
"In (Knight and A1-Onaizan, 1998), finite-state machine translation is based on (Brown et al. , 1993) and is used for decoding the target language string",o,0,1113,o,0,0.95783985,True,0.95783985,0.038772468,0.0033876938
"Model performance is evaluated using the standard BLEU metric (Papineni et al., 2002) which measures average n-gram precision, n 4, and we use the NIST definition of the brevity penalty for multiple reference test sets",o,0,1114,o,0,0.9650315,True,0.9650315,0.028647635,0.006320766
"Top-Down Parsing and Language Modeling Statistically based heuristic best-first or beam-search strategies (Caraballo and Charniak 1998; Charniak, Goldwater, and Johnson 1998; Goodman 1997) have yielded an enormous improvement in the quality and speed of parsers, even without any guarantee that the parse returned is, in fact, that with the maximum likelihood for the probability model",o,0,1115,p,1,0.90775114,False,0.08049377,0.90775114,0.0117551405
he use of such relations (mainly relations between verbs or nouns and their arguments and modifiers) for various purposes has received growing attention in recent research (Church and Hanks 1990; Zernik and Jacobs 1990; Hindle 1990; Smadja 1993,o,0,1116,p,1,0.53136575,False,0.46346545,0.53136575,0.005168787
"Fox (2002), Galley et al (2004) and Wellington et al",o,0,1117,o,0,0.97008073,True,0.97008073,0.0223074,0.007611978
"String alignment with synchronous grammars is quite expensive even for simple synchronous formalisms like ITG (Wu, 1997)but Duchi et al",n,2,1118,n,2,0.7285278,True,0.20793833,0.063533835,0.7285278
"It is possible to recognize a common structure of these works, based on a typical bootstrap schema (Yarowsky, 1995; Collins and Singer, 1999): Step 1: Initial unsupervised categorization",o,0,1119,o,0,0.9244119,True,0.9244119,0.067993805,0.007594315
"Unsupervised systems (Och and Ney, 2003; Liang et al. , 2006) are based on generative models trained with the EM algorithm",o,0,1120,o,0,0.9642268,True,0.9642268,0.032199245,0.0035739457
"(2002), various classification models and linguistic features have been proposed to improve the classification performance (Pang and Lee, 2004; Mullen and Collier, 2004; Wilson et al., 2005a; Read, 2005)",o,0,1121,o,0,0.74264395,True,0.74264395,0.2003685,0.056987613
"And again, we see this insight informing statistical machine translation systems, for instance, in the phrase-based approaches of Och (2003) and Koehn et al",p,1,1122,o,0,0.6628034,False,0.6628034,0.3297175,0.0074790325
"is a WordNet based relatedness measure (Pedersen et al., 2004)",o,0,1123,o,0,0.9728263,True,0.9728263,0.019974638,0.007199097
"In this work, we study a method for obtaining word phrases that is based on Stochastic Inversion Transduction Grammars that was proposed in (Wu, 1997)",o,0,1124,o,0,0.9304921,True,0.9304921,0.06438078,0.0051271077
"For example, if we make a mean-field assumption, with respect to hidden structure and weights, the variationalalgorithmforapproximatelyinferringthe distribution over  and trees y resembles the traditional EM algorithm very closely (Johnson, 2007)",o,0,1125,o,0,0.90484196,True,0.90484196,0.07837355,0.016784497
"(Cutting et al. , 1992) reported very high results (96% on the Brown corpus) for unsupervised POS tagging using Hidden Markov Models (HMMs) by exploiting hand-built tag dictionaries and equivalence classes",p,1,1126,p,1,0.7750299,True,0.20697317,0.7750299,0.017997023
"We only describe these models briefly since full details are presented elsewhere(Kudo and Matsumoto, 2001; Sha and Pereira, 2003; Ramshaw and Marcus, 1995; Sang, 2002)",o,0,1127,o,0,0.91730464,True,0.91730464,0.052004095,0.030691283
"In addition to tf.idf scores, Hulth (2004) uses part-of-speech tags and NP chunks and complements this with machine learning; the latter has been used to good results in similar cases (Turney, 2000; Neto et al., 2002)",o,0,1128,p,1,0.8071198,False,0.18391399,0.8071198,0.00896629
"Statistics on co-occurrence of words in a local context were used recently for monolingual word sense disambiguation (Gale, Church, and Yarowsky 1992b, 1993; Sch6tze 1992, 1993) (see Section 7 for more details and Church and Hanks 1990; Smadja 1993, for other applications of these statistics)",o,0,1129,o,0,0.96536934,True,0.96536934,0.030528275,0.0041024047
"Before parsing, POS tags are assigned to the input sentence using our reimplementation of the POStagger from Collins (2002)",o,0,1130,o,0,0.95658594,True,0.95658594,0.03966175,0.0037522477
"Following our previous work (Jiang and Zhai, 2007b), we extract features from a sequence representation and a parse tree representation of each relation instance",o,0,1131,o,0,0.9593127,True,0.9593127,0.035874374,0.0048128776
"6 Related works After the work of Ramshaw and Marcus (1995), many machine learning techniques have been applied to the basic chunking task, such as Support Vector Machines (Kudo and Matsumoto, 2001), Hidden Markov Model(Molina and Pla 2002), Memory Based Learning (Sang, 2002), Conditional Random Fields (Sha and Pereira, 2003), and so on",o,0,1132,o,0,0.7855635,True,0.7855635,0.211019,0.0034174728
"(2001) compare taggers trained and tested on the Wall Street Journal (WSJ, Marcus et al. , 1993) and the Lancaster-Oslo-Bergen (LOB, Johansson, 1986) corpora and find that the results for the WSJ perform significantly worse",o,0,1133,o,0,0.74159247,True,0.74159247,0.108943686,0.1494638
"There exist many different string similarity measures: word overlap (Tomuro and Lytinen, 2004), longest common subsequence (Islamand Inkpen,2007), Levenshteinedit distance (Dolan et al., 2004), word n-gramoverlap (Barzilay and Lee, 2003) etc. Semantic similarity measures are obtained by first computing the semantic similarity of the words containedin the sentencesbeing compared",o,0,1134,o,0,0.9194505,True,0.9194505,0.07198177,0.008567663
"Minor variants support voted perceptron (Collins, 2002) and MEMMs (McCallum et al. , 2000) with the same ef cient feature encoding",o,0,1135,o,0,0.878534,True,0.878534,0.10961298,0.011853114
"Thus, our generative model is a quasi-synchronous grammar, exactly as in (Smith and Eisner, 2006a).3 When training on target sentences w, therefore, we tune the model parameters to maximize notsummationtextt p(t,w) as in ordinary EM, but rather 3Our task here is new; they used it for alignment",o,0,1136,o,0,0.8915962,True,0.8915962,0.075768396,0.03263535
"Dunning (1993) argues for the use of G 2 rather than X 2, based on an analysis of the sampling distributions of G 2 and X 2, and results obtained when using the statistics to acquire highly associated bigrams",o,0,1137,o,0,0.9168507,True,0.9168507,0.07222209,0.010927222
"The data contains words, their part-of-speech 1This Ramshaw and Marcus (1995) bascNP data set is availal)le via ffp://fti).cis.upe,m.edu/pub/chunker/ 857 (POS) tags as computed by the Brill tagger and their baseNP segmentation as derived from the %'eebank (with some modifications)",o,0,1138,o,0,0.9655316,True,0.9655316,0.029215312,0.0052530644
"For a sequential learning algorithm, we make use of the Collins Perceptron Learner (Collins, 2002)",o,0,1139,o,0,0.94688344,True,0.94688344,0.04879959,0.004316958
"In showing how DLTAG and an interpretative process on its derivations operate, we must, of necessity, gloss over how inference triggered by adjacency or associated with a structural connective provides the intended relation between adjacent discourse 578 Computational Linguistics Volume 29, Number 4 units: It may be a matter simply of statistical inference, as in Marcu and Echihabi (2002), or of more complex inference, as in Hobbs et al",o,0,1140,o,0,0.91363716,True,0.91363716,0.06787629,0.01848654
his further supports the claim by Dunning (1993) that loglikelihood ratio is much less sensitive than pmi to low count,p,1,1141,o,0,0.46705362,False,0.46705362,0.118957736,0.41398868
"It is important to realize that the output of all mentioned processing steps is noisy and contains plenty of mistakes, since the data has huge variability in terms of quality, style, genres, domains etc., and domain adaptation for the NLP tasks involved is still an open problem (Dredze et al., 2007)",o,0,1142,n,2,0.68173265,False,0.27223587,0.046031464,0.68173265
"As expected, as we double the size of the data, the BLEU score (Papineni et al., 2002) increases",o,0,1143,o,0,0.78474265,True,0.78474265,0.12035888,0.09489842
"These instances can be retagged with their countability by using the proposed method and some kind of bootstrapping (Yarowsky, 1995)",o,0,1144,o,0,0.9312805,True,0.9312805,0.06517895,0.0035405953
"Appendix A: Derivation of the Probability of RWE We take a noisy channel approach, which is a common technique in NLP (for example (Brown et al. , 1993)), including spellchecking (Kernighan et al. , 1990)",o,0,1145,o,0,0.62534785,True,0.62534785,0.3697834,0.0048687602
"4.5.2 BLEU on NIST MT Test Sets We use MT02 as the development set4 for minimum error rate training (MERT) (Och, 2003)",o,0,1146,o,0,0.97227335,True,0.97227335,0.02534478,0.0023819471
DeRose 1988; Cutting et al 1992; Merialdo 1994,o,0,1147,o,0,0.96469027,True,0.96469027,0.025935072,0.009374732
"They can be roughly divided into three categories: string-to-tree models (e.g., (Galley et al., 2006; Marcu et al., 2006; Shen et al., 2008)), tree-to-string models (e.g., (Liu et al., 2006; Huang et al., 2006)), and tree-totree models (e.g., (Eisner, 2003; Ding and Palmer, 2005; Cowan et al., 2006; Zhang et al., 2008))",o,0,1148,o,0,0.97160274,True,0.97160274,0.025434963,0.0029623364
"Previous studies called the class of algorithms illustrated in Figure 2 cautious or sequential because in each iteration they acquire 1 or a small set of rules (Abney, 2004; Collins and Singer, 1999)",o,0,1149,o,0,0.9383458,True,0.9383458,0.051331438,0.0103227785
"Then we compute the same ratio of machine translation sentence to source sentence, and take the output of p-norm function as a feature: ) __/__ ()( s csrcoflengthtoflenght Ptf norm  =      (7)   Features based on parse score The usual practice to model the wellformedness of a sentence is to employ the n-gram language model or compute the syntactic structure similarity (Liu and Gildea 2005)",o,0,1150,o,0,0.92575216,True,0.92575216,0.069511704,0.004736109
"Recently, many syntax-based models have been proposed to address the above deficiencies (Wu, 1997; Chiang, 2005; Eisner, 2003; Ding and Palmer, 2005; Quirk et al, 2005; Cowan et al., 2006; Zhang et al., 2007; Bod, 2007; Yamada and Knight, 2001; Liu et al., 2006; Liu et al., 2007; Gildea, 2003; Poutsma, 2000; Hearne and Way, 2003)",p,1,1151,o,0,0.87846327,False,0.87846327,0.10698679,0.014549959
"In order to create the necessary SMT language and translation models, they used:  Giza++ (Och & Ney, 2003);2  the CMU-Cambridge statistical toolkit;3  the ISI ReWrite Decoder.4 Translation was performed from EnglishFrench and FrenchEnglish, and the resulting translations were evaluated using a range of automatic metrics: BLEU (Papineni et al. , 2002), Precision and Recall 2http://www.isi.edu/och/Giza++.html 3http://mi.eng.cam.ac.uk/prc14/toolkit.html 4http://www.isi.edu/licensed-sw/rewrite-decoder/ 185 (Turian et al. , 2003), and Wordand Sentence Error Rates",o,0,1152,o,0,0.9311974,True,0.9311974,0.06251594,0.0062866253
"1 Introduction Word compositions have long been a concern in lexicography(Benson et al. 1986; Miller et al. 1995), and now as a specific kind of lexical knowledge, it has been shown that they have an important role in many areas in natural language processing, e.g., parsing, generation, lexicon building, word sense disambiguation, and information retrieving, etc.(e.g. , Abney 1989, 1990; Benson et al. 1986; Yarowsky 1995; Church and Hanks 1989; Church, Gale, Hans, and Hindle 1989)",o,0,1153,p,1,0.6531759,False,0.3435279,0.6531759,0.0032962451
"Many of the current approaches of domain modeling collapse together different instances and make the decision on what information is important for a domain based on this generalized corpus (Collier, 1998; Barzilay and Lee, 2003; Sudo et al. , 2003)",o,0,1154,o,0,0.91884106,True,0.91884106,0.075129025,0.0060299938
"The more recent set of techniques includes mult iplicative weightupdate algorithms (Golding and Roth, 1998), latent semantic analysis (Jones and Martin, 1997), transformation-based learning (Mangu and Brill, 1997), differential grammars (Powers, 1997), decision lists (Yarowsky, 1994), and a variety of Bayesian classifiers (Gale et al. , 1993, Golding, 1995, Golding and Schabes, 1996)",o,0,1155,p,1,0.6491607,False,0.34308732,0.6491607,0.0077519612
"Concrete similarity measures compare a pair of weighted context feature vectors that characterize two words (Church and Hanks, 1990; Ruge, 1992; Pereira et al. , 1993; Grefenstette, 1994; Lee, 1997; Lin, 1998; Pantel and Lin, 2002; Weeds and Weir, 2003)",o,0,1156,o,0,0.97256976,True,0.97256976,0.023949856,0.0034803376
"Also relevant is previous work that applied machine learning approaches to MT evaluation, both with human references (Corston-Oliver et al. , 2001; Kulesza and Shieber, 2004; Albrecht and Hwa, 2007; Liu and Gildea, 2007) and without (Gamon et al. , 2005)",o,0,1157,o,0,0.87963367,True,0.87963367,0.11254501,0.007821289
"Recently, there have been several discriminative approaches at training large parameter sets including (Tillmann and Zhang, 2006) and (Liang et al. , 2006)",o,0,1158,o,0,0.7772557,True,0.7772557,0.21668088,0.0060632974
"1 Introduction Over the past five years progress in machine translation, and to a lesser extent progress in natural language generation tasks such as summarization, has been driven by optimizing against n-grambased evaluation metrics such as Bleu (Papineni et al. , 2002)",o,0,1159,o,0,0.6275186,True,0.6275186,0.36388993,0.008591366
"We adopt their idea of an utterance as a description, generated from a communicative goal, and also use an ontologically promiscuous formalism for representing meaning [Hobbs, 1985]",o,0,1160,o,0,0.95292217,True,0.95292217,0.043440774,0.0036370533
"CFGs extracted from such structures were then annotated with hidden variables encoding the constraints described in the previous section and trained until convergence by means of the Inside-Outside algorithm defined in (Pereira and Schabes, 1992) and applied in (Matsuzaki et al., 2005)",o,0,1161,o,0,0.96207094,True,0.96207094,0.03484295,0.003086077
"Atthefinestlevel, thisinvolvesthealignment of words and phrases within two sentences that are known to be translations (Brown et al. , 1993; Och and Ney, 2003; Vogel et al. , 1996; Deng and Byrne, 2005)",o,0,1162,o,0,0.9511839,True,0.9511839,0.045171496,0.0036446282
"For instance, both Pang and Lee (2002) and Turney (2002) consider the thumbs up/thumbs down decision: is a film review positive or negative",o,0,1163,o,0,0.90221554,True,0.90221554,0.06317558,0.034608915
"On a separate note, previous research has explicitly studied sentiment analysis as an application of transfer learning (Blitzer et al., 2007)",o,0,1164,o,0,0.8699094,True,0.8699094,0.12117039,0.008920134
"For instance, the resulting word graph can be used in the prediction engine of a CAT system (Och et al. , 2003)",o,0,1165,o,0,0.9554752,True,0.9554752,0.04115862,0.0033661558
"The study is conducted on both a simple Air Travel Information System (ATIS) corpus (Hemphill et al. , 1990) and the more complex Wall Street Journal (WSJ) corpus (Marcus et al. , 1993)",o,0,1166,o,0,0.83553797,True,0.83553797,0.14210857,0.022353482
"The interest reader is referred to \[Basili et al, 1993 b and c\], for a summary of ARIOSTO, an integrated tool for extensive acquisition of lexieal knowledge from corpora that we used to demonstrate and validate our approach",o,0,1167,o,0,0.8613139,True,0.8613139,0.13292786,0.005758324
"However, reordering models in traditional phrase-based systems are not sufficient to treat such complex cases when we translate long sentences (Koehn et al, 2003)",n,2,1168,n,2,0.79491186,True,0.15293881,0.05214927,0.79491186
"Treebank (Marcus et al., 1993), six of which are errors",o,0,1169,o,0,0.8430553,True,0.8430553,0.06736847,0.08957616
"Given the parallel corpus, we tagged the English words with a publicly available maximum entropy tagger (Ratnaparkhi, 1996), and we used an implementation of the IBM translation model (AlOnaizan et al. , 1999) to align the words",o,0,1170,o,0,0.9671874,True,0.9671874,0.028394459,0.0044181473
"In information retrieval, word similarity can be used to identify terms for pseudo-relevance feedback (Harman, 1992; Buckley et al. , 1995; Xu and Croft, 2000; Vechtomova and Robertson, 2000)",o,0,1171,o,0,0.9665767,True,0.9665767,0.030376753,0.0030465052
"This can also be interpreted as a generalization of standard class-based models (Brown et al. , 1992)",o,0,1172,o,0,0.9155854,True,0.9155854,0.07914815,0.0052664713
"Unlike Yarowsky (1995), we use automatic collection of seeds",o,0,1173,o,0,0.93362683,True,0.93362683,0.026614591,0.039758623
"Following Collins and Roark (2004) we also use the early-update strategy, where an update happens whenever the goldstandard action-sequence falls off the beam, with the rest of the sequence neglected",o,0,1174,o,0,0.93051213,True,0.93051213,0.059974156,0.009513647
he effectiveness of these features for recognition of discourse relations has been previously shown by Marcu and Echihabi (2002,o,0,1175,o,0,0.7986212,True,0.7986212,0.19015282,0.0112260645
"For the statistics-based approaches, Bean and Riloff (1999) developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric",o,0,1176,o,0,0.9542926,True,0.9542926,0.041407336,0.00430005
"Our appoach is based on Maximum Entropy (MaxEnt henceforth) technique (Berger et al. , 1996)",o,0,1177,o,0,0.95098895,True,0.95098895,0.043952107,0.005059028
"In Hirschberg and Nakatani (1996), average reliability (measured using the kappa coefficient discussed in Carletta \[1996\]) of segmentinitial labels among 3 coders on 9 monologues produced by the same speaker, labeled using text and speech, is.8 or above for both read and spontaneous speech; values of at least .8 are typically viewed as representing high reliability (see Section 3.2)",o,0,1178,o,0,0.8791426,True,0.8791426,0.08778586,0.03307156
"Others have introduced alternative discriminative training methods (Tillmann and Zhang, 2006; Liang et al., 2006; Turian et al., 2007; Blunsom et al., 2008; Macherey et al., 2008), in which a recurring challenge is scalability: to train many features, we need many train218 ing examples, and to train discriminatively, we need to search through all possible translations of each training example",o,0,1179,o,0,0.7199105,True,0.7199105,0.25345382,0.026635686
"The majority of this research was done on extending the tree structure (finding new synsets (Snow et al., 2006) or enriching WN with new relationships (Cuadros and Rigau, 2008)) rather than improving the quality of existing concept/synset nodes",o,0,1180,o,0,0.548615,True,0.548615,0.06632745,0.38505763
"c2005 Association for Computational Linguistics Recognizing Paraphrases and Textual Entailment using Inversion Transduction Grammars Dekai Wu1 Human Language Technology Center HKUST Department of Computer Science University of Science and Technology, Clear Water Bay, Hong Kong dekai@cs.ust.hk Abstract We present first results using paraphrase as well as textual entailment data to test the language universal constraint posited by Wus (1995, 1997) Inversion Transduction Grammar (ITG) hypothesis",o,0,1181,o,0,0.9531295,True,0.9531295,0.04243075,0.004439804
"The value of Dist(D(T)) can be defined in various ways, and they found that using log-likelihood ratio (see Dunning 1993) worked best which is represented as follows: 0 # log )(# log D K k TD k k i M ii i i M ii i  == , where k i and K i are the frequency of a word w i in D(W) and D 0 respectively, and {w 1,,w M } is the set of all words in D 0 . As stated in introduction, Dist(D(T)) is normalized by the baseline function, which is referred as B Dist () here",o,0,1182,o,0,0.8028789,True,0.8028789,0.18357402,0.013547102
"Work at the University of Dundee (e.g. , Aim et al, 1992; Todman and Alm, this volume) has shown that the extensive use of fixed text for sequences such as greetings and prestored narratives is beneficial in AAC",o,0,1183,p,1,0.87096465,False,0.11294226,0.87096465,0.016093098
"4 Features Features used in our experiments are inspired by previous work on corpus-based approaches for discourse analysis (Marcu and Echihabi, 2002; Lapata, 2003; Elsner et al. , 2007)",o,0,1184,o,0,0.9267887,True,0.9267887,0.06764639,0.005564968
"After line 17, we can employ the one-sense-per-discourse heuristic to further classify unclassified data, as proposed in Yarowsky (1995)",o,0,1185,o,0,0.9413754,True,0.9413754,0.053616855,0.005007886
"We carried out automatic evaluation of our summaries using ROUGE (Lin, 2004) toolkit, which has been widely adopted by DUC for automatic summarization evaluation",p,1,1186,p,1,0.8854749,True,0.10964599,0.8854749,0.0048790583
"Unlike our technique, in most cases researchers have focused on the scenario where labeled training data is available in both the source and the target domain (e.g., (Daume III, 2007; Chelba and Acero, 2004; Daume III and Marcu, 2006))",o,0,1187,o,0,0.9097607,True,0.9097607,0.07146813,0.018771172
"291 3.1 Level of Analysis Research on sentiment annotation is usually conducted at the text (Aue and Gamon, 2005; Pang et al., 2002; Pang and Lee, 2004; Riloff et al., 2006; Turney, 2002; Turney and Littman, 2003) or at the sentence levels (Gamon and Aue, 2005; Hu and Liu, 2004; Kim and Hovy, 2005; Riloff et al., 2006)",o,0,1188,o,0,0.9717291,True,0.9717291,0.021774448,0.0064965067
"The POS tagger uses the same contextual predicates as Ratnaparkhi (1996); the supertagger adds contextual predicates corresponding to POS tags and bigram combinations of POS tags (Curran and Clark, 2003)",o,0,1189,o,0,0.96796787,True,0.96796787,0.026458818,0.0055732164
"4.2 Word alignment We have used IBM models proposed by Brown (Brown et al. , 1993) for word aligning the parallel corpus",o,0,1190,o,0,0.9455263,True,0.9455263,0.050800875,0.0036728226
"6 Related Work Several works attempt to extend WordNet with additional lexical semantic information (Moldovan and Rus, 2001; Snow et al., 2006; Suchanek et al., 2007; Clark et al., 2008)",o,0,1191,o,0,0.94801044,True,0.94801044,0.03566223,0.016327359
"The difference in accuracy between a SVM model applied to RRR dataset (RRR-basic experiment) and the same experiment applied to TB2 dataset (TB2278 Description Accuracy Data Extra Supervision Always noun 55.0 RRR Most likely for each P 72.19 RRR Most likely for each P 72.30 TB2 Most likely for each P 81.73 FN Average human, headwords (Ratnaparkhi et al. , 1994) 88.2 RRR Average human, whole sentence (Ratnaparkhi et al. , 1994) 93.2 RRR Maximum Likelihood-based (Hindle and Rooth, 1993) 79.7 AP Maximum entropy, words (Ratnaparkhi et al. , 1994) 77.7 RRR Maximum entropy, words & classes (Ratnaparkhi et al. , 1994) 81.6 RRR Decision trees (Ratnaparkhi et al. , 1994) 77.7 RRR Transformation-Based Learning (Brill and Resnik, 1994) 81.8 WordNet Maximum-Likelihood based (Collins and Brooks, 1995) 84.5 RRR Maximum-Likelihood based (Collins and Brooks, 1995) 86.1 TB2 Decision trees & WSD (Stetina and Nagao, 1997) 88.1 RRR WordNet Memory-based Learning (Zavrel et al. , 1997) 84.4 RRR LexSpace Maximum entropy, unsupervised (Ratnaparkhi, 1998) 81.9 Maximum entropy, supervised (Ratnaparkhi, 1998) 83.7 RRR Neural Nets (Alegre et al. , 1999) 86.0 RRR WordNet Boosting (Abney et al. , 1999) 84.4 RRR Semi-probabilistic (Pantel and Lin, 2000) 84.31 RRR Maximum entropy, ensemble (McLauchlan, 2001) 85.5 RRR LSA SVM (Vanschoenwinkel and Manderick, 2003) 84.8 RRR Nearest-neighbor (Zhao and Lin, 2004) 86.5 RRR DWS FN dataset, w/o semantic features (FN-best-no-sem) 91.79 FN PR-WWW FN dataset, w/ semantic features (FN-best-sem) 92.85 FN PR-WWW TB2 dataset, best feature set (TB2-best) 93.62 TB2 PR-WWW Table 5: Accuracy of PP-attachment ambiguity resolution (our results in bold) basic experiment) is 2.9%",o,0,1192,o,0,0.92497385,True,0.92497385,0.04683408,0.028192129
"Examples are Andersen (2006; 2007), Okanohara and Tsujii (2007), Sun et al",o,0,1193,o,0,0.97157335,True,0.97157335,0.023609085,0.0048176013
"In cases where the number of gold tags is different than the number of induced tags, some must necessarily remain unassigned (Johnson, 2007)",o,0,1194,o,0,0.7294906,True,0.7294906,0.052330572,0.21817885
"1 Introduction There has been a great deal of progress in statistical parsing in the past decade (Collins, 1996; Collins, 1997; Chaniak, 2000)",p,1,1195,p,1,0.8986785,True,0.0901951,0.8986785,0.011126435
"5 Related Work Although there have been many studies on collocation extraction and mining using only statistical approaches (Church and Hanks, 1990; Ikehara et al. , 1996), there has been much less work on collocation acquisition which takes into account the linguistic properties typically associated with collocations",o,0,1196,n,2,0.691166,False,0.23105986,0.0777742,0.691166
"The second approximation proposed in (Titov and Henderson, 2007) takes into consideration the fact that, after each decision is made, all the preceding latent variables should have their means i updated",o,0,1197,o,0,0.92449164,True,0.92449164,0.053956576,0.021551706
"For the maximum entropy classifier, we estimate the weights by maximizing the likelihood of a heldout set, using the standard IIS algorithm (Berger et al. , 1996)",o,0,1198,o,0,0.94772184,True,0.94772184,0.042663895,0.009614196
"This is due to the reason that Telugu (Entropy=15.625 bits per character) (Bharati et al., 1998) is comparitively a high entropy language than English (Brown and Pietra, 1992)",o,0,1199,n,2,0.69663787,False,0.23448662,0.06887552,0.69663787
"1 Introduction Automatic Metrics for machine translation (MT) evaluation have been receiving significant attention in the past two years, since IBM's BLEU metric was proposed and made available (Papineni et al 2002)",p,1,1200,p,1,0.7407092,True,0.25324717,0.7407092,0.0060436875
"'\['here are three main approaches in tagging problem: rule-based approach (Klein and Simmons 1%3; Brodda 1982; Paulussen and Martin 1992; Brill et al. 1990), statistical approach (Church :1988; Merialdo 1994; Foster 1991; Weischedel et al. 1993; Kupiec 1992) and connectionist approach (Benello et al. 1989; Nakanmra et al. 1989)",o,0,1201,o,0,0.94024295,True,0.94024295,0.052174702,0.0075823697
"(Ruge, 1992; Rapp, 2002))",o,0,1202,o,0,0.9741115,True,0.9741115,0.021891875,0.003996552
"(1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g. , Dang and Palmer (2002), Klein and Manning (2002)) in particular have shown a large degree of success for WSD, and have established challenging state-of-the-art benchmarks",p,1,1203,p,1,0.93442947,True,0.056931023,0.93442947,0.00863948
"This research has focused mostly on the development of statistical parsers trained on large annotated corpora, in particular the Penn Treebank WSJ corpus (Marcus et al. , 1993)",o,0,1204,o,0,0.86251676,True,0.86251676,0.1331135,0.004369717
"Until now, we have defined BestLossk, a to be the minimum of the loss given that the kth feature is updated an optimal amount: BestLossk, amin d LogLossUpda,k,d In this section we sketch a different approach, based on results from Collins, Schapire, and Singer (2002), which leads to an algorithm very similar to that for ExpLoss in Figures 3 and 4",o,0,1205,o,0,0.9288568,True,0.9288568,0.064558566,0.006584615
"Combining statistical and parsing methods has been done by (Hindle, 1990; Hindle and Rooths,1991) and (Smadja and McKewon, 1990; Smadja,1991)",o,0,1206,o,0,0.92724824,True,0.92724824,0.06991361,0.002838168
"Coming from the other direction, such observations about phrase reordering between different languages are precisely thekindsoffactsthatparsingapproachestomachine translation are designed to handle and do successfully handle (Wu, 1997; Melamed, 2003; Chiang, 2005)",p,1,1207,o,0,0.4955805,False,0.4955805,0.46373978,0.040679723
ll of the convergence and generalization results in Collins (2002) depend on notions of separability rather than the size of GEN. Two questions come to min,o,0,1208,o,0,0.76729536,True,0.76729536,0.1188233,0.11388133
"This was expected, as it has been observed before that very simple smoothing techniques can perform well on large data sets, such as web data (Brants et al., 2007)",o,0,1209,p,1,0.8276471,False,0.15209344,0.8276471,0.020259542
"Clustering algorithms have been previously shown to work fairly well for the classification of words into syntactic and semantic classes (Brown et al. 1992), but determining the optimum number of classes for a hierarchical cluster tree is an ongoing difficult problem, particularly without prior knowledge of the item classification",n,2,1210,p,1,0.48109296,False,0.19631061,0.48109296,0.32259652
"4.1 NER features We used the features generated by the CRF package (Finkel et al., 2005)",o,0,1211,o,0,0.97231156,True,0.97231156,0.02487072,0.002817715
"Distance from a target word is used for this purpose and it is calculated by the assumption that the target words in the context window have the same sense (Yarowsky, 1995)",o,0,1212,o,0,0.9617574,True,0.9617574,0.032237567,0.0060049878
"2 Our statistical engine 2.1 The statistical models In this study, we built an SMT engine designed to translate from French to English, following the noisy-channel paradigm flrst described by (Brown et al. , 1993b)",o,0,1213,o,0,0.95099443,True,0.95099443,0.044860296,0.0041452423
"Although generating training examples in advance without a working parser (Turian & Melamed, 2005) is much faster than using inference (Collins & Roark, 2004; Henderson, 2004; Taskar et al. , 2004), our training time can probably be decreased further by choosing a parsing strategy with a lower branching factor",n,2,1214,n,2,0.85220736,True,0.10990789,0.03788475,0.85220736
amshaw and Marcus (1995) approached chunking by using a machine learning metho,o,0,1215,o,0,0.94807965,True,0.94807965,0.04785188,0.004068468
"1 Introduction In recent years, statistical machine translation have experienced a quantum leap in quality thanks to automatic evaluation (Papineni et al. , 2002) and errorbased optimization (Och, 2003)",p,1,1216,p,1,0.89184237,True,0.10243484,0.89184237,0.0057228175
"Dependency models (Rosenfeld, 2000) use the parsed dependency structure of sentences to build the language model as in grammatical trigrams (Lafferty et al., 1992), structured language models (Chelba and Jelinek, 2000), and dependency language models (Chelba et al., 1997)",o,0,1217,o,0,0.97633857,True,0.97633857,0.020174408,0.0034870072
"The model scaling factors are optimized on the development corpus with respect to mWER similar to (Och, 2003)",o,0,1218,o,0,0.973927,True,0.973927,0.0217015,0.004371413
"1 Introduction In recent years, Bracketing Transduction Grammar (BTG) proposed by (Wu, 1997) has been widely used in statistical machine translation (SMT)",p,1,1219,p,1,0.9274543,True,0.06965652,0.9274543,0.0028891407
"2 Data Sets for the Experiments 2.1 Coordination Annotation in the PENN TREEBANK For our experiments, we used the WSJ part of the PENN TREEBANK (Marcus et al., 1993)",o,0,1220,o,0,0.9729354,True,0.9729354,0.02182278,0.005241904
"For this present work, we use Dunnings log-likelihood ratio statistics (Dunning, 1993) defined as follows: sim = aloga+blogb+clogc+dlogd (a+b)log(a+b)(a+c)log(a+c) (b+d)log(b+d)(c+d)log(c+d) +(a+b+c+d)log(a+b+c+d) For each bilingual pattern EiJj, we compute its similarity score and qualify it as a bilingual sequence-to-sequence correspondence if no equally strong or stronger association for monolingual constituent is found",o,0,1221,o,0,0.94402796,True,0.94402796,0.043889467,0.01208249
"We utilise the automatic annotation algorithm of (Cahill et al. , 2004b) to derive a version of Penn-II where each node in each tree is annotated with an LFG functional annotation (i.e. an attribute value structure equation)",o,0,1222,o,0,0.9700254,True,0.9700254,0.027318362,0.0026562933
ohnson (2007) and Zhang et a,o,0,1223,o,0,0.96787214,True,0.96787214,0.026494984,0.0056328503
arcu and Echihabi (2002) demonstrated that word pairs extracted from the respective text spans are a good signal of the discourse relation between argument,o,0,1224,o,0,0.58771235,True,0.58771235,0.3957291,0.016558535
urney (2002) and Wiebe (2000) focused on learning adjectives and adjectival phrases and Wiebe et a,o,0,1225,o,0,0.9646722,True,0.9646722,0.031565987,0.0037618594
"We use a program to label syntactic arguments with the roles they are playing (Blaheta and Charniak, 2000), and the rules for complement/adjunct distinction given by (Collins, 1997) to never allow deletion of the complement",o,0,1226,o,0,0.9565686,True,0.9565686,0.03809322,0.005338133
"The results have demonstrated the existence of priming effects in corpus data: they occur for specific syntactic constructions (Gries, 2005; Szmrecsanyi, 2005), consistent with the experimental literature, but also generalize to syntactic rules across the board, which repeated more often than expected by chance (Reitter et al. , 2006b; Dubey et al. , 2006)",o,0,1227,o,0,0.7824229,True,0.7824229,0.15079345,0.06678362
"To 848 make feature ranking computationally tractable in (Della Pietra et al. , 1995) and (Berger et al. , 1996) a simplified process proposed: at the feature ranking stage when adding a new feature to the model, all previously computed parameters are kept fixed and, thus, we have to fit only one new constraint imposed by the candidate feature",o,0,1228,o,0,0.8695298,True,0.8695298,0.11988193,0.010588298
"It is difficult to compare these with previous work, but Haghighi and Klein (2006) report that in a completely unsupervised setting, their MRF model, which uses a large set of additional features and a more complex estimation procedure, achieves an average 1-to-1 accuracy of 41.3%",o,0,1229,o,0,0.5891924,True,0.5891924,0.2603379,0.15046981
"1087 Model 3 of (Brown et al. , 1993) is a zero-order alignment model like Model 2 including in addition fertility paranmters",o,0,1230,o,0,0.9710051,True,0.9710051,0.024924623,0.004070323
"(2001)) and unsupervised approaches (e.g. , Cardie and Wagstaff (1999), Bean and Riloff (2004))",o,0,1231,o,0,0.92078507,True,0.92078507,0.05058299,0.028631957
"Syntactic context information is used (Hindle, 1990; Ruge, 1992; Lin, 1998) to compute term similarities, based on which similar words to a particular word can directly be returned",o,0,1232,o,0,0.96207017,True,0.96207017,0.03348767,0.0044422355
"This curve plots the average labeled attachment score over Basque, Chinese, English, and Turkish as a function of parsing time per token.4 Accuracy of only 1% below the maximum can be achieved with average processing time of 17 ms per token, or 60 tokens per second.5 We also refer the reader to (Titov and Henderson, 2007b) for more detailed analysis of the ISBN dependency parser results, where, among other things, it was shown that the ISBN model is especially accurate at modeling long dependencies",o,0,1233,p,1,0.5504652,False,0.38036636,0.5504652,0.06916847
"3.1 Binarizable segmentations (a) Following (Zhang et al., 2006; Huang et al., 2008), every sequence of phrase alignments can be viewed 1For example, if the cut-off on phrase pairs is ten words, all sentence pairs smaller than ten words in the training data will be included as phrase pairs as well",o,0,1234,o,0,0.96215254,True,0.96215254,0.03188675,0.0059607043
"Finally, Section 4 reports the results of parsing experiments using our exhaustive k-best CYK parser with the concise PCFGs induced from the Penn WSJ treebank (Marcus et al. , 1993)",o,0,1235,o,0,0.7558843,True,0.7558843,0.22907297,0.015042749
"Among them, the unsupervised algorithm using decisiontrees (Yarowsky, 1995) has achieved promising performance",p,1,1236,p,1,0.94233924,True,0.05145834,0.94233924,0.006202347
"Note that all systems were optimized using a non-deterministic implementation of the Minimum Error Rate Training described in (Och, 2003)",o,0,1237,o,0,0.95502377,True,0.95502377,0.03616365,0.00881266
"Current work has been spurred by two papers, (Yarowsky, 1995) and (Blum and Mitchell, 1998)",o,0,1238,o,0,0.6921489,True,0.6921489,0.30090463,0.006946505
his model is related to the averaged perceptron algorithm of Collins (2002,o,0,1239,o,0,0.97157186,True,0.97157186,0.021856135,0.0065720216
"OHara and Wiebe (2003) also make use of high level features, in their case the Penn Treebank (Marcus et al., 1993) and FrameNet (Baker et al., 1998) to classify prepositions",o,0,1240,o,0,0.5059992,True,0.5059992,0.4772027,0.01679803
"Three approaches are dominating, i.e. knowledge-based approach (Kim and Hovy, 2004), information retrieval-based approach (Turney and Littman, 2003) and machine learning approach (Pang et al., 2002), in which the last approach is found very popular",p,1,1241,p,1,0.8503117,True,0.13355705,0.8503117,0.016131263
"More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods",o,0,1242,o,0,0.68034655,True,0.68034655,0.31239924,0.0072542443
"Its previous applications (e.g. , Grefenstette 1993, Hearst and Schuetze 1993, Takunaga et al 1997, Lin 1998, Caraballo 1999) demonstrated that cooccurrence statistics on a target word is often sufficient for its automatical classification into one of numerous classes such as synsets of WordNet",o,0,1243,o,0,0.65137166,True,0.65137166,0.3146753,0.033953052
"In (Koo and Collins, 2005), an undirected graphical model for constituent parse reranking uses dependency relations to define the edges",o,0,1244,o,0,0.96726114,True,0.96726114,0.027059887,0.005678989
"The approaches proposed to the ACE RDC task such as kernel methods (Zelenko et al. , 2002) and Maximum Entropy methods (Kambhatla, 2004) required the availability of large set of human annotated corpora which are tagged with relation instances",o,0,1245,o,0,0.9428058,True,0.9428058,0.048400376,0.0087938765
"First, we can let the number of nonterminals grow unboundedly, as in the Infinite PCFG, where the nonterminals of the grammar can be indefinitely refined versions of a base PCFG (Liang et al., 2007)",o,0,1246,o,0,0.94040215,True,0.94040215,0.053060334,0.006537518
"The maximum entropy models used here are similar in form to those in (Ratnaparkhi, 1996; Berger, Della Pietra, and Della Pietra, 1996; Lau, Rosenfeld, and Roukos, 1993)",o,0,1247,o,0,0.93774915,True,0.93774915,0.052550185,0.009700655
"The reader is referred to (Ushioda 1996) and (Brown et al. 1992) for details of MI clustering, but we will first briefly summarize the MI clustering and then describe our hierarchical clustering algorithm",o,0,1248,o,0,0.9553616,True,0.9553616,0.038009904,0.006628555
"Accordingly, in this section we describe a set of experiments which extends the work of (Way and Gough, 2005) by evaluating the Marker-based EBMT system of (Gough & Way, 2004b) against a phrase-based SMT system built using the following components:  Giza++, to extract the word-level correspondences;  The Giza++ word alignments are then refined and used to extract phrasal alignments ((Och & Ney, 2003); or (Koehn et al. , 2003) for a more recent implementation);  Probabilities of the extracted phrases are calculated from relative frequencies;  The resulting phrase translation table is passed to the Pharaoh phrase-based SMT decoder which along with SRI language modelling toolkit5 performs translation",o,0,1249,o,0,0.95971173,True,0.95971173,0.036030862,0.004257424
"We have also implemented a Bloom Filter LM in Joshua, following Talbot and Osborne (2007)",o,0,1250,o,0,0.9313176,True,0.9313176,0.063469864,0.0052124686
"Based on the observations in (Koehn et al. , 2003), we also limited the phrase length to 3 for computational reasons",o,0,1251,o,0,0.93706024,True,0.93706024,0.048316915,0.014622937
"272 Similarity-based estimation was first used for language modeling in the cooccurrence smoothing method of Essen and Steinbiss (1992), derived from work on acoustic model smoothing by Sugawara et al",o,0,1252,o,0,0.9045227,True,0.9045227,0.09317303,0.0023042406
"These include scripts for creating alignments from a parallel corpus, creating phrase tables and language models, binarizing phrase tables, scripts for weight optimization using MERT (Och 2003), and testing scripts",o,0,1253,o,0,0.973551,True,0.973551,0.022180464,0.0042685005
"We are encoding the knowledge as axioms in what is for the most part  first-order logic, described in Hobbs (1985a), although quantification over predicates is sometimes convenient",o,0,1254,o,0,0.7536114,True,0.7536114,0.11361175,0.13277696
"unlabeled R 100% 20/08/199605/08/1997 (351 days) 50% 20/08/199617/02/1997 (182 days) 10% 20/08/199624/09/1996 (36 days) labeled WSJ 50% sections 0012 (23412 sentences) 25% lines 1  292960 (11637 sentences) 5% lines 1  58284 (2304 sentences) 1% lines 1  11720 (500 sentences) 0.05% lines 1  611 (23 sentences) Table 1: Corpora used for the experiments: unlabeled Reuters (R) corpus for attachment statistics, labeled Penn treebank (WSJ) for training the Collins parser",o,0,1255,o,0,0.95495856,True,0.95495856,0.036391452,0.008650062
"1 To train their system, R&M used a 200k-word chunk of the Penn Treebank Parsed Wall Street Journal (Marcus et al. , 1993) tagged using a transformation-based tagger (Brill, 1995) and extracted base noun phrases from its parses by selecting noun phrases that contained no nested noun phrases and further processing the data with some heuristics (like treating the possessive marker as the first word of a new base noun phrase) to flatten the recursive structure of the parse",o,0,1256,o,0,0.9616161,True,0.9616161,0.035244532,0.0031393191
"The trends are the same as in (McClosky et al. , 2006): Adding NANC data improves parsing performance on BROWN development considerably, improving the f-score from 83.9% to 86.4%",o,0,1257,o,0,0.56885076,True,0.56885076,0.2954403,0.13570896
"Most SMT models (Brown et al. , 1993; Vogel et al. , 1996) try to model word-to-word corresl)ondences between source and target words using an alignment nmpl)ing from source l)osition j to target position i = aj",o,0,1258,o,0,0.91431403,True,0.91431403,0.07936697,0.0063190237
"Dependency models have recently gained considerable interest in many NLP applications, including machine translation (Ding and Palmer, 2005; Quirk et al., 2005; Shen et al., 2008)",o,0,1259,p,1,0.65214133,False,0.34499934,0.65214133,0.0028592912
"It reconfirms that only allowing sibling nodes reordering as done in SCFG may be inadequate for translational equivalence modeling (Galley et al., 2004) 4 . 3) All the three models on the FBIS corpus show much lower performance than that on the other two corpora",o,0,1260,n,2,0.6423481,False,0.29974237,0.057909444,0.6423481
"In the iNeast system (Leuski et al. , 2003), the identification of relevant terms is oriented towards multi-document summarization, and they use a likelihood ratio (Dunning, 1993) which favours terms which are representative of the set of documents as opposed to the full collection",o,0,1261,o,0,0.96007234,True,0.96007234,0.03445369,0.0054740375
"We use the IBM Model 1 (Brown et al. , 1993) (uniform distribution) and the Hidden Markov Model (HMM, first-order dependency, (Vogel et al. , 1996)) to estimate the alignment model",o,0,1262,o,0,0.9757294,True,0.9757294,0.020132309,0.00413834
"We used treebank grammars induced directly from the local trees of the entire WSJ section of the Penn Treebank (Marcus et al. , 1993) (release 3)",o,0,1263,o,0,0.9642505,True,0.9642505,0.031643793,0.004105661
"We base our work partly on previous work done by Bagga and Baldwin (Bagga and Baldwin, 1998), which has also been used in later work (Chen and Martin, 2007)",o,0,1264,o,0,0.9129829,True,0.9129829,0.08194699,0.005070086
"In the thriving area of research on automatic analysis and processing of product reviews (Hu and Liu 2004; Turney 2002; Pang and Lee 2005), little attention has been paid to the important task studied here  assessing review helpfulness",n,2,1265,p,1,0.5662478,False,0.18128218,0.5662478,0.25247005
"10Our experiments have shown that using averaging helps tremendously, confirming both the theoretical and practical results of (Collins, 2002)",o,0,1266,p,1,0.8365711,False,0.14069532,0.8365711,0.022733571
"Parse Parse score from Model 2 of the statistical parser (Collins, 1997), normalized by the number of words",o,0,1267,o,0,0.95843923,True,0.95843923,0.03377102,0.0077897296
"(Brown et al. , 1993) defined two local search operations for their 1-to-N alignment models 3, 4 and 5",o,0,1268,o,0,0.96064645,True,0.96064645,0.03110693,0.008246542
"However, as also pointed out by Yarowsky (1995), this observation does not hold uniformly over all possible co-occurrences of two words",p,1,1269,n,2,0.7281717,False,0.24462259,0.027205728,0.7281717
"1 Introduction The dominance of traditional phrase-based statistical machine translation (PBSMT) models (Koehn et al., 2003) has recently been challenged by the development and improvement of a number of new models that explicity take into account the syntax of the sentences being translated",n,2,1270,p,1,0.7692865,False,0.174823,0.7692865,0.05589043
"Our model improves the baseline provided by (Cahill and van Genabith, 2006): (i) accuracy is increased by creating a lexicalised PCFG grammar and enriching conditioning context with parent f-structure features; and (ii) coverage is increased by providing lexical smoothing and fuzzy matching techniques for rule smoothing",n,2,1271,o,0,0.7892411,False,0.7892411,0.13434915,0.076409794
"Following previous work (Ratnaparkhi, 1996), we assume that the tag of a word is independent of the tags of all preceding words given the tags of the previous two words (i.e. ,  =2 in the equation above)",o,0,1272,o,0,0.95662105,True,0.95662105,0.030023534,0.013355428
"5 Related Work We already discussed the relation of our work to (Daume III, 2007) in Section 2.4",o,0,1273,o,0,0.922208,True,0.922208,0.061877962,0.015914021
"4 Experiment Our baseline system is a popular phrase-based SMT system, Moses (Koehn et al., 2007), with 5-gram SRILM language model (Stolcke, 2002), tuned with Minimum Error Training (Och, 2003)",o,0,1274,p,1,0.87340546,False,0.12047507,0.87340546,0.00611939
"2.2 Statistical Translation Lexicon We use a statistical translation lexicon known as IBM Model-1 in (Brown et al. , 1993) for both efficiency and simplicity",p,1,1275,o,0,0.7587474,False,0.7587474,0.23735562,0.0038969126
"2 Related Work Question Answering has attracted much attention from the areas of Natural Language Processing, Information Retrieval and Data Mining (Fleischman et al. , 2003; Echihabi et al. , 2003; Yang et al. , 2003; Hermjakob et al. , 2002; Dumais et al. , 2002; Hermjakob et al. , 2000)",o,0,1276,o,0,0.5302527,True,0.5302527,0.46566704,0.004080282
"METRIC FORMULA Frequency (Guiliano, 1964) x yf Pointwise Mutual Information [PMI] (Church & Hanks, 1990) ( )xy x y2log /P P P True Mutual Information [TMI] (Manning, 1999) ( )xy 2 xy x ylog /P P P P Chi-Squared ( 2 ) (Church and Gale, 1991) { }{ },, 2( ) i X X Y Y i j i j i j j f     T-Score (Church & Hanks, 1990) 1 2 2 2 1 2 1 2 x x s s n n  + C-Values4 (Frantzi, Anadiou & Mima 2000) 2 is not nested 2 log ( ) log ( ) 1 ( ) ( ) a a b T a f f f b P T         where is the candidate string f( ) is its frequency in the corpus T is the set of candidate terms that contain P(T ) is the number of these candidate terms 609 1,700 of the three-word phrases are attested in the Lexile corpus",o,0,1277,o,0,0.9679617,True,0.9679617,0.026035732,0.0060025523
"40,000 sentences) and section 23 for testing (see Collins 1997, 1999; Charniak 1997, 2000; l~,atnalmrkhi 1999); we only tested on sentences _< 40 words (2245 sentences)",o,0,1278,o,0,0.9435843,True,0.9435843,0.026481425,0.029934214
"This is in sharp contrast to the smoothed fixed-word statistics in most lexicalized parsing models derived from sparse data (Magerman (1995), Collins (1996), Charniak (1997), etc.)",o,0,1279,o,0,0.72797257,True,0.72797257,0.16238803,0.10963941
", Yarowsky 1995) after using an ensemble of NBCs",o,0,1280,o,0,0.96954423,True,0.96954423,0.02615481,0.004301042
"The state of the art technology for relation extraction primarily relies on pattern-based approaches (Snow et al. , 2006)",p,1,1281,p,1,0.8990615,True,0.08919318,0.8990615,0.0117453905
"2 Experimental System and Data HMIHY is a spoken dialogue system based on the notion of call routing (Gorin et al. , 1997; Chu-Carroll and Carpenter, 1999)",o,0,1282,o,0,0.9673333,True,0.9673333,0.028350253,0.004316452
he extraction procedure utilizes a head percolation table as introduced by Magerman (1995) in combination with a variation of Collinss (1997) approach to the differentiation between complement and adjunc,o,0,1283,o,0,0.96036446,True,0.96036446,0.035679925,0.0039555724
"Post-editing of automatic annotation has been pursued in various projects (e.g. , Brants 2000, and Marcus et al. 1993)",o,0,1284,o,0,0.91295594,True,0.91295594,0.08258727,0.0044567594
"The sentences in the training and testing sets were already (perfectly) POS-tagged and noun chunked, and that in a real-life situation additional preprocessing by a POS-tagger (such as the LT-POS-tagger4) and noun chunker (such as described in (Ramshaw and Marcus, 1995)) which will introduce additional errors",o,0,1285,o,0,0.772187,True,0.772187,0.16724196,0.060571022
"It is also related to (log-)linear models described in Berger, Della Pietra, and Della Pietra (1996), Xue (2003); Och (2003), and Peng, Feng, and McCallum (2004)",o,0,1286,o,0,0.9571336,True,0.9571336,0.03621259,0.0066538323
"model reranking has also been established, both for synchronous binarization (Zhang et al., 2006) and for target-only binarization (Huang, 2007)",o,0,1287,o,0,0.9351466,True,0.9351466,0.05715583,0.007697523
he linear kernel derived from the L1 distance is the same as the difference-weighted token-based similarity measure of Weeds and Weir (2005,o,0,1288,o,0,0.9614685,True,0.9614685,0.03195757,0.0065739197
"To model p(fJle~;8,.T) we assume the existence of an alignment a J. We assume that every word fj is produced by the word e~j at position aj in the training corpus with the probability P(f~le,~i): J p(f lc ') = 1\] p(L Icon) j=l (7) The word alignment a J is trained automatically using statistical translation models as described in (Brown et al. , 1993; Vogel et al. , 1996)",o,0,1289,o,0,0.95627064,True,0.95627064,0.038377248,0.0053521274
"1 Specifically, MIMIC uses an n-dimensional call router front-end (Chu-Carroll, 2000), which is a generalization of the vector-based call-routing paradigm of semantic interpretation (Chu-CarroU and Carpenter, 1999); that is, instead of detecting one concept per utterance, MIMIC's semantic interpretation engine detects multiple (n) concepts or classes conveyed by a single utterance, by using n call touters in parallel",o,0,1290,o,0,0.9670407,True,0.9670407,0.027641242,0.0053180973
"However, most parsers still tend to show low performance on the long sentences (Li et al. , 1990; Doi et al. , 1993; Kim et al. , 2000)",o,0,1291,o,0,0.4665642,True,0.4665642,0.26255077,0.27088502
"andw2 iscomputedusinganassociationscorebased on pointwise mutual information, asdefinedbyFano (1961) and used for a similar purpose in Church and Hanks (1990), as well as in many other studies in corpus linguistics",o,0,1292,o,0,0.9363822,True,0.9363822,0.060536966,0.0030809157
ike the work of Jing and McKeown (2000) and Mani et a,o,0,1293,o,0,0.93758523,True,0.93758523,0.058492213,0.0039225626
"We extracted all examples of each word from the 14-million-word English portion of the Hansards.8 Note that this is considerably smaller than Yarowskys (1995) corpus of 460 million words, so bootstrapping will not perform as well, and may be more sensitive to the choice of seed",o,0,1294,n,2,0.6993726,False,0.25678277,0.043844637,0.6993726
"In addition to individual seed words, Kanayama and Nasukawa (2006) used more complicated syntactic patterns that were manually created",o,0,1295,o,0,0.60513973,True,0.60513973,0.085785165,0.30907512
"One possible approach is to employ state-of-the-art techniques for coreference and zeroanaphora resolution (Iida et al., 2006; Komachi et al., 2007, etc.) in preprocessing cooccurrence samples",p,1,1296,p,1,0.7624393,True,0.2268118,0.7624393,0.010748908
"Every sentence was part-of-speech tagged using a maximum entropy tagger (Ratnaparkhi, 1996) and parsed using a state-of-the-art wide coverage phrase structure parser (Collins, 1999)",o,0,1297,p,1,0.61076283,False,0.36541614,0.61076283,0.023821013
"We then parse both sides of the corpus with syntactic parsers [Collins, 1997; Schmidt and Schulte im Walde, 2000]",o,0,1298,o,0,0.95830184,True,0.95830184,0.03830883,0.0033893278
"Labeled data for one domain might be used to train a initial classifier for another (possibly related) domain, and then bootstrapping can be employed to learn new knowledge from the new domain (Blitzer et al., 2007)",o,0,1299,o,0,0.9583095,True,0.9583095,0.037355524,0.0043350505
"In our SMT system implementation, this optimization procedure is performed by using a tool developed in-house, which is based on a simplex method (Press et al. 2002), and the BLEU score (Papineni et al. 2002) is used as a translation quality measurement",o,0,1300,o,0,0.94849676,True,0.94849676,0.04724594,0.004257271
"In order to prove this induction step, we use the concept of order annotations (Kuhlmann, 2007; Kuhlmann and Mohl, 2007), which are strings that lexicalise the precedence relation between the nodes of a dependency tree",o,0,1301,o,0,0.9548039,True,0.9548039,0.04064309,0.004553075
"303 Wiebe, Wilson, Bruce, Bell, and Martin Learning Subjective Language While it is common in studies of collocations to omit low-frequency words and expressions from analysis, because they give rise to invalid or unrealistic statistical measures (Church and Hanks, 1990), we are able to identify higher-precision collocations by including placeholders for unique words (i.e. , the ugen-n-grams)",o,0,1302,o,0,0.74196297,True,0.74196297,0.22683905,0.031198
"The novel algorithm differs computationally from earlier work in discriminative training algorithms for SMT (Och, 2003) as follows: a90 No computationally expensive a57 -best lists are generated during training: for each input sentence a single block sequence is generated on each iteration over the training data",o,0,1303,o,0,0.7259047,True,0.7259047,0.17947981,0.094615474
"Interestingly, similar conclusions were also reached in the area of Machine Translation evaluation; in their experiments, Zhang and Vogel (2004) show that adding an additional reference translation compensates the effects of removing 1015% of the testing data, and state that, therefore, it seems more cost effective to have more test sentences but fewer reference translations",o,0,1304,o,0,0.7410837,True,0.7410837,0.19550657,0.06340974
"Our predicate-argument structure-based thesatmis is based on the method proposed by Hindie (Hindle, 1990), although Hindle did not apply it to information retrieval",n,2,1305,o,0,0.4904584,False,0.4904584,0.029976645,0.47956502
"Liu and Gildea (2005) also pointed out that due to the limited references for every MT output, using the overlapping ratio of n-grams longer than 2 did not improve sentence level evaluation performance of BLEU",o,0,1306,n,2,0.7516705,False,0.1831286,0.06520093,0.7516705
"4.5 Hindles Measure Hindle (1990) proposed an MI-based measure, which he used to show that nouns could be reliably clustered based on their verb co-occurrences",o,0,1307,o,0,0.8379561,True,0.8379561,0.15223102,0.009812922
"While previous researchers have used agglomerative nesting clustering (e.g. Brown et al (1992), Futrelle and Gauch (1993)), comparisons with our work are difficult to draw, due to their use of the 1,000 commonest words from their respective corpora",o,0,1308,n,2,0.6328317,False,0.3108365,0.056331802,0.6328317
"Finally, Zhang and Clark (2008) achieve an SF of 95.90% and a TF of 91.34% by 10-fold cross validation using CTB data",o,0,1309,o,0,0.85658187,True,0.85658187,0.12954572,0.013872424
"To support distributed computation (Brants et al., 2007), we further split the N-gram data into shards by hash values of the first bigram",o,0,1310,o,0,0.95337605,True,0.95337605,0.042361498,0.004262489
"It has a lower bound of 0, no upper bound, better scores indicate better translations, and it tends to be highly correlated with the adequacy of outputs ;  mWER (Och 2003) or Multiple Word Error Rate is the edit distance in words between the system output and the closest reference translation in a set",o,0,1311,o,0,0.8790619,True,0.8790619,0.09079939,0.03013865
 Related work Turney (2008) recently advocated the need for a uniform approach to corpus-based semantic task,o,0,1312,o,0,0.81398994,True,0.81398994,0.17095514,0.015055052
"lscript1-regularized log-linear models (lscript1-LLMs), on the other hand, provide sparse solutions, in which weights of irrelevant features are exactly zero, by assumingaLaplacianpriorontheweights(Tibshirani, 1996; Kazama and Tsujii, 2003; Goodman, 2004; Gao et al., 2007)",o,0,1313,o,0,0.95853984,True,0.95853984,0.035492793,0.00596739
"We then used Cohens Kappa () to determine the level of agreement (Carletta, 1996)",o,0,1314,o,0,0.96487236,True,0.96487236,0.030196218,0.004931428
mith and Eisner (2006) used a quasisynchronous grammar to discover the correspondence between words implied by the correspondence between the tree,o,0,1315,o,0,0.9600753,True,0.9600753,0.03617344,0.0037512528
"2.1 Model 2 of (Collins, 1997) Both parsing models discussed in this paper inherit a great deal from this model, so we briefly describe its """"progenitive"""" features here, describing only how each of the two models of this paper differ in the subsequent two sections",o,0,1316,o,0,0.8350449,True,0.8350449,0.1417476,0.02320755
"Parsers that attempt to disambiguate the input completely  full parsing  typically first employ some kind of dynamic programming algorithm to derive a packed parse forest and then applies a probabilistic top-down model in order to select the most probable analysis (Collins, 1997; Charniak, 2000)",o,0,1317,o,0,0.94636714,True,0.94636714,0.0495955,0.0040373937
"The association relationship between two words can be indicated by their mutual information, which can be further used to discover phrases \[Church :& Hanks (1990)\]",o,0,1318,o,0,0.9392703,True,0.9392703,0.05481911,0.00591058
"First, even when sentiment is the desired focus, researchers in sentiment analysis have shown that a two-stage approach is often beneficial, in which subjective instances are distinguished from objective ones, and then the subjective instances are further classified according to polarity (Yu and Hatzivassiloglou, 2003; Pang and Lee, 2004; Wilson et al. , 2005; Kim and Hovy, 2006)",p,1,1319,p,1,0.5013805,True,0.48076236,0.5013805,0.017857157
"For each cell in the contingency table, the expected counts are: mi j = ni+n+ jn++ . The measures are calculated as (Pedersen, 1996): 2 = i;j (ni j mi j) 2 mi j LL = 2 i;j log2 n 2i j mi j Log-likelihood ratios (Dunning, 1993) are more appropriate for sparse data than chi-square",o,0,1320,n,2,0.79717106,False,0.14807512,0.05475379,0.79717106
"In addition, the performance of the adapted model for Joint S&T obviously surpass that of (Jiang et al., 2008), which achieves an F1 of 93.41% for Joint S&T, although with more complicated models and features",n,2,1321,n,2,0.6213382,True,0.25316676,0.12549503,0.6213382
"In Turney (2002), features are selected according to part-of-speech labels",o,0,1322,o,0,0.96514845,True,0.96514845,0.029212633,0.0056389836
"Similarly, the sense disambiguation problem is typically attacked by comparing the distribution of the neighbors of a word's occurrence to prototypical distributions associated with each of the word's senses \[Gale et al. , 1992, Schtltze, 1992\]",o,0,1323,o,0,0.952947,True,0.952947,0.040955868,0.0060970285
"in at with use teacher school 11894.47020.1 28.9 0.0 teacher handbook 2.5 0.0 3.2 10.1 soldier gun 2.8 10.3 105.9 41.0 Table 5: A fragment of the CCxL space We use this space to measure relational similarity (Turney, 2006) of concept pairs, e.g., finding that the relation between teachers and handbooks is more similar to the one between soldiers and guns, than to the one between teachers and schools",o,0,1324,o,0,0.89038944,True,0.89038944,0.042965993,0.06664458
"For process (3), machine-learning methods are usually used to classify subjective descriptions into bipolar categories (Dave et al. , 2003; Beineke et al. , 2004; Hu and Liu, 2004; Pang and Lee, 2004) or multipoint scale categories (Kim and Hovy, 2004; Pang and Lee, 2005)",o,0,1325,o,0,0.9548403,True,0.9548403,0.0417892,0.0033704955
"The results so far mainly come from studies where a parser originally developed for English,such as the Collins parser (Collins 1997,1999), is applied to a new language,which often leads to a signicant decrease in the measured accuracy (Collins et al. 1999; Bikel and Chiang 2000; Dubey and Keller 2003; Levy and Manning 2003; Corazza et al. 2004)",o,0,1326,o,0,0.7779058,True,0.7779058,0.19534543,0.026748763
"However, much recent work in machine learning and statistics has turned away from maximum-likelihood in favor of Bayesian methods, and there is increasing interest in Bayesian methods in computational linguistics as well (Finkel et al. , 2006)",o,0,1327,o,0,0.6430473,True,0.6430473,0.3428565,0.014096207
or colnparison~ we refer here to Smadja's method (1993) because this method and the proposed method have much in connno,o,0,1328,o,0,0.90385044,True,0.90385044,0.08364127,0.012508276
"We compare semisupervised LEAF with a previous state of the art semi-supervised system (Fraser and Marcu, 2006b)",p,1,1329,p,1,0.55290514,True,0.42227435,0.55290514,0.024820521
"Note that the results of MB-D here cannot be directly compared with those in (Yarowsky, 1995), mainly because the data used are different",o,0,1330,n,2,0.7173896,False,0.25121337,0.031397015,0.7173896
arzilay and Lee (2003) applied multi-sequence alignment (MSA) to parallel news sentences and induced paraphrase patterns for generating new sentences (Figure 1 (1),o,0,1331,o,0,0.9690898,True,0.9690898,0.027677843,0.003232424
"This information can be annotated reliably (a1a3a2a5a4a7a6a9a8 a10a12a11a14a13a16a15 and a1a17a2a5a4a19a18a20a8 a10a12a11a14a13a16a21 ).4 4Following (Carletta, 1996), we use the a22 statistic to estimate reliability of annotation",o,0,1332,o,0,0.9153515,True,0.9153515,0.078877196,0.005771326
"Presently, many systems (Tan et al, 1999), (Liu, 2000), (Song, 1993), (Luo et al, 2001) focus on online recognition of proper nouns, and have achieved inspiring results in newscorpus but will be deteriorated in special text, such as spoken corpus, novels",o,0,1333,p,1,0.7845388,False,0.19001961,0.7845388,0.025441585
"1 Introduction Word alignments were first introduced as an intermediate result of statistical machine translation systems (Brown et al. , 1993)",o,0,1334,o,0,0.9283373,True,0.9283373,0.06780906,0.0038536475
"Our goal is to come up with a mechanism that, given an input string, identifies the phrases in this string, this is a fundamental task with applications in natural language (Church, 1988; Ramshaw and Marcus, 1995; Mufioz et al. , 1999; Cardie and Pierce, 1998)",o,0,1335,o,0,0.87091005,True,0.87091005,0.122440435,0.00664948
"2 Incremental Parsing This section gives a description of Collins and Roarks incremental parser (Collins and Roark, 2004) and discusses its problem",o,0,1336,o,0,0.9091304,True,0.9091304,0.0818606,0.0090090595
"(Hughes and Ramage, 2007) described the use of a biased PageRank over the WordNet graph to compute word pair semantic relatedness using the divergence of the probability values over the graph created by each word",o,0,1337,o,0,0.9648639,True,0.9648639,0.029569918,0.005566206
"Previous attempts have used, for instance, the similarities between case frames (Lin and Pan57 tel, 2001), anchor words (Barzilay and Lee, 2003; Shinyama et al. , 2002; Szepektor et al. , 2004), and a web-based method(Szepektor et al. , 2004;Geffet and Dagan, 2005)",o,0,1338,o,0,0.96471137,True,0.96471137,0.03223608,0.0030525264
"4 Experiments Our experiments were conducted on CoNLL-2007 shared task domain adaptation track (Nivre et al. , 2007) using treebanks (Marcus et al. , 1993; Johansson and Nugues, 2007; Kulick et al. , 2004)",o,0,1339,o,0,0.9740786,True,0.9740786,0.022025159,0.003896223
"For the log-linear model training, we take minimum-error-rate training method as described in (Och, 2003)",o,0,1340,o,0,0.9443408,True,0.9443408,0.049646627,0.006012535
"INTRODUCTION Class-based language models (Brown et al. , 1992)have been proposed for dealing with two problems confronted by the well-known word n-gram language models (1) data sparseness: the amount of training data is insufficient for estimating the huge number of parameters; and (2) domain robustness: the model is not adaptable to new application domains",o,0,1341,p,1,0.600808,False,0.20099998,0.600808,0.19819197
"Averaging has been shown to help reduce overfitting (Collins, 2002)",p,1,1342,p,1,0.9417186,True,0.05309247,0.9417186,0.0051889666
"There is usually not a considerable difference between the two methods in terms of the accuracy of the resulting model (Gao et al., 2007), but L1 regularization has a significant advantage in practice",p,1,1343,n,2,0.42227492,False,0.33848006,0.23924495,0.42227492
"The model consists of a set of word-pair parameters p(t\[s) and position parameters p(j\[i,/); in model 1 (IBM1) the latter are fixed at 1/(1 + 1), as each position, including the empty position 0, is considered equally likely to contain a translation for w. Maximum likelihood estimates for these parameters can be obtained with the EM algorithm over a bilingual training corpus, as described in (Brown et al. , 1993)",o,0,1344,o,0,0.9129938,True,0.9129938,0.07137384,0.01563241
"Bergsma et al (2008) proposed a distributional method in detecting non-anaphoric pronouns by first extracting the surrounding textual context of the pronoun, then gathering the distribution of words that occurred within that context from a large corpus and finally learning to classify these distributions as representing either anaphoric and non-anaphoric pronoun instances",o,0,1345,o,0,0.96024376,True,0.96024376,0.036018945,0.0037372836
"These linguistically-motivated trimming rules (Dorr et al. , 2003; Zajic et al. , 2004) iteratively remove constituents until a desired sentence compression rate is reached",o,0,1346,o,0,0.94536644,True,0.94536644,0.04732339,0.00731018
"However, as (Barzilay & Lee, 2003) do not propose any evaluation of which clustering algorithm should be used, we experiment a set of clustering algorithms and present the comparative results",o,0,1347,o,0,0.9025679,True,0.9025679,0.04571076,0.051721264
"While simple statistical alignment models like IBM-1 (Brown et al. , 1993) and the symmetric alignment approach by Hiemstra (1996) treat sentences as unstructured bags of words, the more sophisticated IBM-models by Brown et al",o,0,1348,p,1,0.3772072,False,0.37308577,0.3772072,0.24970707
"A recent trend is to store the LM in a distributed cluster of machines, which are queried via network requests (Brants et al., 2007; Emami et al., 2007)",o,0,1349,o,0,0.7900783,True,0.7900783,0.20630561,0.0036161623
"There are accurate parsers available such as Chaniak parser (Charniak and Johnson, 2005), Stanford parser (Klein and Manning, 2003) and Berkeley parser (Petrov and Klein, 2007), among which we use the Berkeley parser 2 to help identify the head word",o,0,1350,p,1,0.53213316,False,0.46187404,0.53213316,0.0059928414
"The relationship between the translation model and the alignment model is given by: Pr(fJ1 jeI1) = X aJ1 Pr(fJ1 ;aJ1jeI1) (3) In this paper, we use the models IBM-1, IBM4 from (Brown et al. , 1993) and the HiddenMarkovalignmentmodel(HMM)from(Vogelet al. , 1996)",o,0,1351,o,0,0.9712976,True,0.9712976,0.025293859,0.0034085575
"For each candidate triple, the log-likelihood (Dunning, 1993) and salience (Kilgarriff and Tugwell, 2001) scores were calculated",o,0,1352,o,0,0.96072096,True,0.96072096,0.0329987,0.006280255
"Note that the need to consider segmentation and alignment at the same time is also mentioned in (Tiedemann, 2003), and related issues are reported in (Wu, 1997)",o,0,1353,o,0,0.81530446,True,0.81530446,0.09789865,0.08679694
"This paper continues a line of research on online discriminative training (Tillmann and Zhang, 2006; Liang et al., 2006; Arun and Koehn, 2007), extending that of Watanabe et al",o,0,1354,o,0,0.91032517,True,0.91032517,0.06843266,0.021242192
"However, they do not elaborate on how the comparisons are done, or on how effective the program is. Dolan (1994) describes a heuristic approach to forming unlabeled clusters of closely related senses in an MRD",o,0,1355,o,0,0.7995733,True,0.7995733,0.13622014,0.06420657
"234 ADV Non-specific adverbial BNF Benefemtive CLF It-cleft CLR 'Closely related' DIR Direction DTV Dative EXT Extent HLN Headline LGS Logical subject L0C Location MNI~ Manner N0M Nominal PRD Predicate PRP Purpose PUT Locative complement of 'put' SBJ Subject TMP Temporal TPC Topic TTL Title V0C Vocative Grammatical DTV 0.48% LGS 3.0% PRD 18.% PUT 0.26% SBJ 78.% v0c 0.025% Figure 1: Penn treebank function tags 53.% Form/Function 37.% Topicalisation 2.2% 0.25% NOM 6.8% 2.5% TPC 100% 2.2% 1.5% ADV 11.% 4.2% 9.3% BN'F 0.072% 0.026% 0.13% DIR 8.3% 3.0% 41.% EXT 3.2% 1.2% 0.013% LOC 25.% 9.2% MNR 6.2% 2.3% PI~ 5.2% 1.9% 33.% 12.% Miscellaneous 9.5% CLR 94.% 8.8% CLF 0.34% 0.03% HLN 2.6% 0.25% TTL 3.1% 0.29% Figure 2: Categories of function tags and their relative frequencies one project that used them at all: (Collins, 1997) defines certain constituents as complements based on a combination of label and function tag information",o,0,1356,o,0,0.9627577,True,0.9627577,0.029286481,0.007955817
"The most widely used are Word Error Rate (WER), Position Independent Word Error Rate (PER), the BLEU score (Papineni et al. , 2002) and the NIST score (Doddington, 2002)",p,1,1357,p,1,0.93004566,True,0.061619908,0.93004566,0.008334386
"1 Introduction Possibly the most remarkable evolution of recent years in statistical machine translation is the step from word-based models to phrase-based models (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002; Tillmann and Xia, 2003)",o,0,1358,p,1,0.9397573,False,0.053137343,0.9397573,0.007105407
"The f-structure annotation algorithm used for inducing LFG resources from the Penn-II treebank for English (Cahill et al. , 2004) uses configurational, categorial, function tag and trace information",o,0,1359,o,0,0.970809,True,0.970809,0.024686456,0.004504527
"Examples of formalisms using this approach include the work of Magerman (1995), Charniak (1997), Collins (1997), and Goodman (1997)",o,0,1360,o,0,0.95025307,True,0.95025307,0.04611294,0.003633957
"Following Collins (2002), we used the averaged parameters from the training algorithm in decoding heldout and test examples in our experiments",o,0,1361,o,0,0.95917225,True,0.95917225,0.037804496,0.0030231674
"In order to calculate a global score or probability for a transition sequence, two systems used a Markov chain approach (Duan et al. , 2007; Sagae and Tsujii, 2007)",o,0,1362,o,0,0.96416295,True,0.96416295,0.031098133,0.004739021
"ROUGE has been used in meeting summarization evaluation (Murray et al., 2005; Galley, 2006), yet the question remained whether ROUGE is a good metric for the meeting domain",o,0,1363,n,2,0.81165564,False,0.14543305,0.042911284,0.81165564
"Some of the best results were reported in (Yarowsky, 1995) who uses a large training corpus",p,1,1364,p,1,0.9133051,True,0.07574595,0.9133051,0.010948932
"Detail of the Bakeoff data sets is in (Levow, 2006)",o,0,1365,o,0,0.95956486,True,0.95956486,0.03539006,0.0050451783
"NJ 08903 U.S.A. suzanne~ruccs, rutgers, edu Empirically-induced models that learn a linguistically meaningflll grammar (Collins, 1997) seem to give tile best practical results in statistical natural language processing",p,1,1366,p,1,0.8963389,True,0.09823682,0.8963389,0.0054243426
"2 Treebanking The Penn Treebank (Marcus et al. , 1993) is annotated with information to make predicate-argument structure easy to decode, including function tags and markers of empty categories that represent displaced constituents",p,1,1367,o,0,0.9247505,False,0.9247505,0.07056441,0.004685008
"The original training set (before the addition of the feedback sets) consisted of a few dozen examples, in comparison to thousands of examples needed in other corpus-based methods (Schutze, 1992; Yarowsky, 1995)",o,0,1368,o,0,0.8639602,True,0.8639602,0.07490452,0.06113529
"We presented some theoretical arguments for not limiting extraction to minimal rules, validated them on concrete examples, and presented experiments showing that contextually richer rules provide a 3.63 BLEU point increase over the minimal rules of (Galley et al. , 2004)",n,2,1369,n,2,0.667275,True,0.27065867,0.062066246,0.667275
"Recent lexicalized stochastic parsers such as Collins (1999), Charniak (1997), and others add additional features to each constituent, the most important being the head word of the parse constituent",o,0,1370,p,1,0.52263147,False,0.4603207,0.52263147,0.017047865
"Here, we extract part-of-speech tags from the Collins parsers output (Collins, 1997) for section 23 instead of reinventing a tagger",o,0,1371,o,0,0.9496137,True,0.9496137,0.038362134,0.01202412
"Since the use of cluster of machines is not always practical, (Talbot and Osborne, 2007b; Talbot and Osborne, 2007a) showed a randomized data structure called Bloom filter, that can be used to construct space efficient language models 513 for SMT",p,1,1372,o,0,0.89367527,False,0.89367527,0.085894376,0.020430364
"Several models were introduced for these problems, for example, the Hidden Markov Model (HMM) (Rabiner, 1989), Maximum Entropy Model (ME) (Ratnaparkhi and Adwait, 1996), and Conditional Random Fields (CRFs) (Lafferty et al., 2001)",o,0,1373,o,0,0.9506108,True,0.9506108,0.042676575,0.0067125554
"The corpus consists of sections 15-18 and section 20 of the Penn Treebank (Marcus et al. , 1993), and is pre-divided into a 8936-sentence (211727 tokens) training set and a 2012-sentence (47377 tokens) test set",o,0,1374,o,0,0.9612735,True,0.9612735,0.034858853,0.0038675992
"Firstly, they classify all the GHKM2 rules (Galley et al., 2004; Galley et al., 2006) into two categories: lexical rules and non-lexical rules",o,0,1375,o,0,0.9566709,True,0.9566709,0.038881462,0.0044476045
"To reduce it we exploit the one sense per collocation property (Yarowsky, 1995)",o,0,1376,o,0,0.93265295,True,0.93265295,0.063297614,0.004049446
"Substantial improvements have been made to parse western language such as English, and many powerful models have been proposed (Brill 1993, Collins 1997)",p,1,1377,p,1,0.8526696,True,0.14242584,0.8526696,0.004904578
"The evaluation shows that our algorithm considerably outperforms (Cahill et al. , 2004)s with respect to Chinese data",n,2,1378,n,2,0.7049606,True,0.2086787,0.086360686,0.7049606
"Substring-based transliteration with a generative hybrid model is very similar to existing solutions for phrasal SMT (Koehn et al., 2003), operating on characters rather than words",o,0,1379,o,0,0.92472017,True,0.92472017,0.060023416,0.015256398
"For the evaluation of translation quality, we applied standard automatic evaluation metrics, i.e., BLEU (Papineni et al., 2002) and METEOR (Banerjee and Lavie, 2005)",o,0,1380,o,0,0.96095407,True,0.96095407,0.03413457,0.004911402
"Surprisingly, though, rather little work has been devoted to learning local syntactic patterns, mostly noun phrases (Ramshaw and Marcus, 1995; Vilain and Day, 1996)",o,0,1381,o,0,0.7212954,True,0.7212954,0.18420671,0.09449794
"The decoder is capable of producing nbest derivations and nbest lists (Knight and Graehl, 2005), which are used for Maximum Bleu training (Och, 2003)",o,0,1382,o,0,0.90991724,True,0.90991724,0.08299849,0.0070843273
"Additionally, some research has explored cutting and pasting segments of text from the full document to generate a summary (Jing and McKeown 2000)",o,0,1383,o,0,0.91987664,True,0.91987664,0.07597035,0.0041530747
"Experimental results were only reported for the METEOR metric (Banerjee and Lavie, 2005)",o,0,1384,o,0,0.8861498,True,0.8861498,0.040190246,0.07365995
"1 Introduction This paper reports on our experience hand tagging the senses of 25 of the most frequent verbs in 12,925 sentences of the Wall Street Journal Treebank corpus (Marcus et al. 1993)",o,0,1385,o,0,0.7093162,True,0.7093162,0.28022432,0.010459436
"Secondly, while most pronoun resolution evaluations simply exclude non-referential pronouns, recent unsupervised approaches (Cherry and Bergsma, 2005; Haghighi and Klein, 2007) must deal with all pronouns in unrestricted text, and therefore need robust modules to automatically handle non-referential instances",n,2,1386,n,2,0.652666,True,0.28680423,0.0605298,0.652666
"The a0 coefficient is computed as follows: a0 a47 a1a32a2 a9 a1 a30 a68 a9 a1a32a30 Carletta (1996) reports that content analysis researchers generally think of a0a34a33 a49a36a35a37 as good reliability, with a49a36a35a38a40a39a37a41 a0 a41a25a49a36a35a37 allowing tentative conclusions to be drawn. All that remains is to define the chance agreement probability a1 a30 . Let a1a32a41 a1 a30 a7 and a1a32a42 a1 a30 a7 be the fraction of utterances that begin or end one or more segments in segmentation a30 respectively",o,0,1387,o,0,0.8830719,True,0.8830719,0.100515395,0.016412694
"Compared to a basic treebank grammar (Charniak, 1996), the grammars of highaccuracy parsers weaken independence assumptions by splitting grammar symbols and rules with either lexical (Charniak, 2000; Collins, 1999) or nonlexical (Klein and Manning, 2003; Matsuzaki et al. , 2005) conditioning information",p,1,1388,o,0,0.9292693,False,0.9292693,0.041522868,0.029207854
"First, we trained a finitestate shallow parser on base phrases extracted from the Penn Wall St. Journal (WSJ) Treebank (Marcus et al. , 1993)",o,0,1389,o,0,0.9651271,True,0.9651271,0.030819187,0.0040535927
"Recent work, (McClosky et al. , 2006), has shown that adding many millions of words of machine parsed and reranked LA Times articles does, in fact, improve performance of the parser on the closely related WSJ data",p,1,1390,o,0,0.46553358,False,0.46553358,0.413852,0.12061435
"A la Ramshaw and Marcus (1995), and Kudo and Matsumato (2000), we use the IOB tagging style for modeling and classification",o,0,1391,o,0,0.9652585,True,0.9652585,0.030984657,0.003756801
his therefore suggests that better parameters are likely to be learned in the 2Haghighi and Kleins (2007) generative coreference model mirrors this in the posterior distribution which it assigns to mention types given their salience (see their Table 1,o,0,1392,o,0,0.8366884,True,0.8366884,0.1412313,0.022080306
"Features identified using distributional similarity have previously been used for syntactic and semantic disambiguation (Hindle 1990; Dagan, Pereira, and Lee 1994) and to develop lexical resources from corpora (Lin 1998; Riloff and Jones 1999)",o,0,1393,o,0,0.9580739,True,0.9580739,0.039323006,0.0026031488
"Automatic subjectivity analysis would also be useful to perform flame recognition (Spertus 1997; Kaufer 2000), e-mail classification (Aone, Ramos-Santacruze, and Niehaus 2000), intellectual attribution in text (Teufel and Moens 2000), recognition of speaker role in radio broadcasts (Barzialy et al. 2000), review mining (Terveen et al. 1997), review classification (Turney 2002; Pang, Lee, and Vaithyanathan 2002), style in generation (Hovy 1987), and clustering documents by ideological point of view (Sack 1995)",o,0,1394,o,0,0.93520516,True,0.93520516,0.059190206,0.005604548
"For instance, automatic summary can be seen as a particular paraphrasing task (Barzilay and Lee, 2003) with the aim of selecting the shortest paraphrase",o,0,1395,o,0,0.9389791,True,0.9389791,0.05663843,0.00438244
"2 Evaluating Heterogeneous Parser Output Two commonly reported shallow parsing tasks are Noun-Phrase (NP) Chunking (Ramshaw and Marcus, 1995) and the CoNLL-2000 Chunking task (Sang and Buchholz, 2000), which extends the NPChunking task to recognition of 11 phrase types1 annotated in the Penn Treebank",o,0,1396,o,0,0.54873073,True,0.54873073,0.44524446,0.006024829
"We provide results using a range of automatic evaluation metrics: BLEU (Papineni et al. , 2002), Precision and Recall (Turian et al. , 2003), and Wordand Sentence Error Rates",o,0,1397,o,0,0.960225,True,0.960225,0.036603313,0.0031717294
"However, with the algorithms proposed in (Huang and Chiang, 2005; Chiang, 2007; Huang and Chiang, 2007), it is possible to develop a general-purpose decoder that can be used by all the parsing-based systems",o,0,1398,o,0,0.7698738,True,0.7698738,0.22078803,0.009338235
"Finally, in section 4 we add additional features to the maxent model, and chain these models into a conditional markov model (CMM), as used for tagging (Ratnaparkhi, 1996) or earlier NER work (Borthwick, 1999)",o,0,1399,o,0,0.9345675,True,0.9345675,0.058768407,0.0066640307
"Instead of using a single system output as the skeleton, we employ a minimum Bayes-risk decoder to select the best single system output from the merged N-best list by minimizing the BLEU (Papineni et al., 2002) loss",o,0,1400,o,0,0.9180777,True,0.9180777,0.06457336,0.01734895
"Some researchers (Lappin and Leass 1994; Kennedy and Boguraev 1996) use manually designed rules to take into account the grammatical role of the antecedent candidates as well as the governing relations between the candidate and the pronoun, while others use features determined over the parse tree in a machine-learning approach (Aone and Bennett 1995; Yang et al. 2004; Luo and Zitouni 2005)",o,0,1401,o,0,0.961397,True,0.961397,0.031161651,0.0074414024
"These methods often involve using a statistic such as 2 (Gale and Church, 1991) or the log likelihood ratio (Dunning, 1993) to create a score to measure the strength of correlation between source and target words",o,0,1402,o,0,0.9558103,True,0.9558103,0.041032568,0.0031571472
"(Och and Ney, 2003) discussed efficient implementation",p,1,1403,p,1,0.7995481,True,0.17949551,0.7995481,0.020956421
"Thispaperfocusesontheframeworkintroduced in Figure 2 for two reasons: (a) cautious al50 gorithms were shown to perform best for several NLP problems (including acquisition of IE patterns), and (b) it has nice theoretical properties: Abney (2004) showed that, regardless of the selection procedure, sequential bootstrapping algorithms converge to a local minimum of K, where K is an upper bound of the negative log likelihood of the data",o,0,1404,p,1,0.5806056,False,0.3963255,0.5806056,0.023068909
"For the MUC6 data set, we extract noun phrases (mentions) automatically, but for MPQA, we assume mentions for coreference resolution are given as in Stoyanov and Cardie (2006)",o,0,1405,o,0,0.96311164,True,0.96311164,0.023323612,0.013564743
"2 Related Work The popular IBM models for statistical machine translation are described in (Brown et al. , 1993) and the HMM-based alignment model was introduced in (Vogel et al. , 1996)",p,1,1406,p,1,0.8557761,True,0.13441533,0.8557761,0.0098085925
"As an alternative to the often used sourcechannel approach (Brown et al. 1993), we directly model the posterior probability Pr(e I 1 | f J 1 ) (Och and Ney 2002)",o,0,1407,o,0,0.7802954,True,0.7802954,0.0944528,0.12525189
"(Krenn, 2000b; Smadja, 1993))",o,0,1408,o,0,0.96904594,True,0.96904594,0.02422408,0.0067300694
"The first approach is to reuse the components of a generative model, but tune their relative weights in a discriminative fashion (Och and Ney, 2002; Och, 2003; Chiang, 2005)",o,0,1409,o,0,0.96261096,True,0.96261096,0.034234148,0.0031548666
"Several recent papers have studied the use of annotations obtained from Amazon Mechanical Turk, a marketplace for recruiting online workers (Su et al., 2007; Kaisser et al., 2008; Kittur et al., 2008; Sheng et al., 2008; Snow et al., 2008; Sorokin and Forsyth, 2008)",o,0,1410,o,0,0.96011466,True,0.96011466,0.036227953,0.003657355
"The former extracts collocations within a fixed window (Church and Hanks 1990; Smadja, 1993)",o,0,1411,o,0,0.9662202,True,0.9662202,0.026488537,0.0072912355
"We guess it is an acronym for the authors of (Galley et al., 2004): Michel Galley, Mark Hopkins, Kevin Knight and Daniel Marcu",o,0,1412,o,0,0.9619648,True,0.9619648,0.034839105,0.003196149
"On the other hand, structural annotation such as that used in syntactic treebanks (e.g. , Marcus et al. , 1993) assigns a syntactic category to a contiguous sequence of corpus positions",o,0,1413,o,0,0.9648554,True,0.9648554,0.030971717,0.004172932
"I have made a preliminary analysis of the inventory of syntactic categories used in the tagging for labelling trees in the 18 Penn Treebank (Marcus et al., 1993), comparing them to the categories used in CGEL",o,0,1414,o,0,0.9614966,True,0.9614966,0.03280836,0.0056949784
"3.1 Translation Model Form We first assume the general hypergraph setting of Huang and Chiang (2007), namely, that derivations under our translation model form a hypergraph",o,0,1415,o,0,0.96853125,True,0.96853125,0.028142124,0.0033266062
"In addition, the averaged parameters technology (Collins, 2002) is used to alleviate overfitting and achieve stable performance",p,1,1416,o,0,0.56577945,False,0.56577945,0.4212736,0.012946954
"1 Phrase-based Unigram Model Various papers use phrase-based translation systems (Och et al. , 1999; Marcu and Wong, 2002; Yamada and Knight, 2002) that have shown to improve translation quality over single-word based translation systems introduced in (Brown et al. , 1993)",n,2,1417,p,1,0.51022094,False,0.33781227,0.51022094,0.15196683
.2 Results on the Newsblaster data We measured how well the models trained on DUC data perform with current news labeled using human 4http://newsblaster.cs.columbia.edu 5a20 (kappa) is a measure of inter-annotator agreement over and above what might be expected by pure chance (See Carletta (1996) for discussion of its use in NLP).a20a22a21a24a23 if there is perfect agreement between annotators anda20a25a21a27a26 if the annotators agree only as much as you would expect by chanc,o,0,1418,o,0,0.87780386,True,0.87780386,0.08222861,0.039967544
"4.1 The test environment For our experiments, we used a manually corrected version of the Air Travel Information System (ATIS) spoken language corpus (Hemphill et al. , 1990) annotated in the Pennsylvania Treebank (Marcus et al. , 1993)",o,0,1419,o,0,0.96188205,True,0.96188205,0.031668346,0.0064495415
"If the alignments are not available, they can be automatically generated; e.g., using GIZA++ (Och and Ney, 2003)",o,0,1420,o,0,0.94259316,True,0.94259316,0.04032709,0.017079733
"Section 5 presents an error analysis for Collinss (1997) lexicalized model, which shows that the head-head dependencies used in this model fail to cope well with the flat structures in Negra",n,2,1421,n,2,0.56595546,True,0.35416588,0.07987857,0.56595546
"The first two phases are approached as straightforward classification in a maximum entropy framework (Berger et al. , 1996)",o,0,1422,o,0,0.93907934,True,0.93907934,0.054328363,0.006592388
"5.3 Performance of Taxonomy Induction In this section, we compare the following automatic taxonomy induction systems: HE, the system by Hearst (1992) with 6 hypernym patterns; GI, the system by Girju et al",o,0,1423,o,0,0.8999832,True,0.8999832,0.08913217,0.010884471
"The model we use is similar to that of (Ratnaparkhi, 1996)",o,0,1424,o,0,0.97125006,True,0.97125006,0.024670552,0.0040793093
nd Semantic Knowledge Sources for Coreference Resolution Ponzetto & Strube (2006) and Strube & Ponzetto (2006) aimed at showing that the encyclopedia that anyone can edit can be indeed used as a semantic resource for research in NL,o,0,1425,o,0,0.8376137,True,0.8376137,0.14922562,0.013160721
"Only recently have robust knowledge-based methods for some of these tasks begun to appear, and their performance is still not very good, as seen above in our discussion of using WordNet as a semantic network; 33 as for checking the plausibility of a hypothesis on the basis of causal knowledge about the world, we now have a much better theoretical grasp of how such inferences could be made (see, for example, Hobbs et al. \[1993\] and Lascarides and Asher \[1993\]), but we are still quite a long way from a general inference engine",o,0,1426,n,2,0.62673897,False,0.2528548,0.12040631,0.62673897
"First, we can construct an infinite number of more specialized PCFGs by splitting or refining the PCFGs nonterminals into increasingly finer states; this leads to the iPCFG or infinite PCFG (Liang et al., 2007)",o,0,1427,o,0,0.92455655,True,0.92455655,0.06928648,0.006157036
"Turney (Turney, 2001; Turney, 2002) reported that the NEAR operator outperformed simple page co-occurrence for his purposes; our early experiments informally showed the same for this work",o,0,1428,o,0,0.47275013,True,0.47275013,0.22645795,0.30079186
he description of the minimum cut framework in Section 4.1 was inspired by Pang and Lee (2004,o,0,1429,o,0,0.96270436,True,0.96270436,0.03187584,0.0054198
"(Smith and Smith, 2007))",o,0,1430,o,0,0.9677203,True,0.9677203,0.02640044,0.00587924
"3 Previous Work on Subjectivity Tagging In previous work (Wiebe et al., 1999), a corpus of sentences from the Wall Street Journal Treebank Corpus (Marcus et al., 1993) was manually anno- tated with subjectivity classifications by multiple judges",o,0,1431,o,0,0.96081996,True,0.96081996,0.034909327,0.004270673
"6.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996)",p,1,1432,o,0,0.5177884,False,0.5177884,0.478876,0.0033355742
"Three kinds of metrics have been defined: 1http://www.lsi.upc.edu/nlp/IQMT 2http://svn.ask.it.usyd.edu.au/trac/ candc DR-STM-l (Semantic Tree Matching) These metrics are similar to the Syntactic Tree Matching metric defined by Liu and Gildea (2005), in this case applied to DRSs instead of constituency trees",o,0,1433,o,0,0.96661013,True,0.96661013,0.02811546,0.005274362
"The most sophisticated of these techniques (such as Support Vector Machines) are unfortunately too computationally expensive to be used on large datasets like the Penn Treebank (Marcus et al. , 1993)",o,0,1434,n,2,0.90079284,False,0.06461907,0.0345881,0.90079284
"3.1 Experiments The model described in section 2 has been tested on the Brown corpus (Francis and Kucera, 1982), tagged with the 45 tags of the Penn treebank tagset (Marcus et al. , 1993), which constitute the initial tagset T0",o,0,1435,o,0,0.9576782,True,0.9576782,0.038695008,0.003626761
"The standard Minimum Error Rate training (Och, 2003) was applied to tune the weights for all feature types",o,0,1436,o,0,0.9344123,True,0.9344123,0.061993353,0.0035943778
"Finally, following Haghighi and Klein (2006) and Johnson (2007) we can instead insist that at most one HMM state can be mapped to any part-of-speech tag",o,0,1437,o,0,0.86356115,True,0.86356115,0.09755886,0.038879953
"Machine translation has code-like characteristics, and indeed, the initial models of (Brown et al. , 1993) took a word-substitution/transposition approach, trained on a parallel text",o,0,1438,o,0,0.9307968,True,0.9307968,0.06289464,0.0063085156
"As a result, the problem of opinion mining has seen increasing attention over the last three years from (Turney, 2002; Hu and Liu, 2004) and many others",o,0,1439,p,1,0.6380443,False,0.34859663,0.6380443,0.013359086
"An alternative is to create an automatic system that uses a set of training question-answer pairs to learn the appropriate question-answer matching algorithm (Chu-Carroll and Carpenter, 1999)",o,0,1440,o,0,0.9608822,True,0.9608822,0.036327798,0.0027900373
"In his Xtract system, Smadja (1993) first extracted significant pairs of words that consistently co-occur within a single syntactic structure using statistical scores called distance, strength and spread, and then examined concordances of the bi-grams to find longer frequent multiword units",o,0,1441,o,0,0.9481907,True,0.9481907,0.04679454,0.0050146724
"3.2 Translation performance For the experiments reported in this section, we used feature weights trained with minimum error rate training (MERT; Och, 2003) . Because MERT ignores the denominator in Equation 1, it is invariant with respect to the scale of the weight vector   the Moses implementation simply normalises the weight vector it finds by its lscript1-norm",o,0,1442,o,0,0.90891045,True,0.90891045,0.07747585,0.013613674
"They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set",o,0,1443,o,0,0.9620475,True,0.9620475,0.03325139,0.004700998
"To avoid this problem, generative models for NLP tasks have often been manually designed to achieve an appropriate representation of the joint distribution, such as in the parsing models of (Collins, 1997; Charniak, 2000)",o,0,1444,o,0,0.8843764,True,0.8843764,0.109403074,0.0062205074
"2.2 Perceptron algorithm Our discriminative n-gram model training approach uses the perceptron algorithm, as presented in (Roark et al. , 2004), which follows the general approach presented in (Collins, 2002)",o,0,1445,o,0,0.95730335,True,0.95730335,0.038776778,0.003919929
"An especially well-founded framework is maximum entropy (Berger et al. , 1996)",p,1,1446,p,1,0.90089846,True,0.089681424,0.90089846,0.0094201
"Regressive FLM (rFLM) h(FLM(e,j)) = w1 FLM(e,j)+b Regressive ALM (rALM) h(ALM(e,j)) = w1 ALM(e,j)+b Notice that h() here is supposed to relate FLM or ALM to some independent evaluation metric such as BLEU (Papineni et al. , 2002), not the log likelihood of a translation",o,0,1447,o,0,0.9334179,True,0.9334179,0.035805833,0.03077626
"However, this is not unprecedented: discriminatively weighted generative models have been shown to outperform purely discriminative competitors in various NLP classification tasks (Raina et al., 2004; Toutanova, 2006), and remain the standard approach in statistical translation modeling (Och, 2003)",p,1,1448,p,1,0.7852154,True,0.1769678,0.7852154,0.037816856
"1 Yarowsky (1995) proposes a method for word sense (translation) disambiguation that is based on a bootstrapping technique, which we refer to here as Monolingual Bootstrapping (MB)",o,0,1449,o,0,0.946681,True,0.946681,0.050270345,0.0030485953
"We show translation results in terms of the automatic BLEU evaluation metric (Papineni et al. , 2002) on the MT03 Arabic-English DARPA evaluation test set consisting of a212a89a212a89a87 sentences with a98a89a212a161a213a89a214a89a215 Arabic words with a95 reference translations",o,0,1450,o,0,0.9664836,True,0.9664836,0.028404986,0.0051114177
"This weak supervision has been encoded using priors and initializations (Klein and Manning, 2004; Smith, 2006), specialized models (Klein and Manning, 2004; Seginer, 2007; Bod, 2006), and implicit negative evidence (Smith, 2006)",o,0,1451,o,0,0.9440501,True,0.9440501,0.038455267,0.0174947
"Another attractive property of the voted perceptron is that it can be used with kernels, for example the kernels over parse trees described in (Collins and Duffy 2001; Collins and Duffy 2002)",o,0,1452,p,1,0.83080655,False,0.15522982,0.83080655,0.013963678
"We use the minimum-error rate training procedure by Och (2003) as implemented in the Moses toolkit to set the weights of the various translation and language models, optimizing for BLEU",o,0,1453,o,0,0.9394707,True,0.9394707,0.05625455,0.004274805
"In this paper we use a non-projective dependency tree CRF (Smith and Smith, 2007)",o,0,1454,o,0,0.9739499,True,0.9739499,0.022108443,0.0039416295
"(Cahill et al. , 2004)s approach for English resolves three LDD types in parser output trees without traces and coindexation (Figure 2(b)), i.e. topicalisation (TOPIC), wh-movement in relative clauses (TOPIC REL) and interrogatives (FOCUS)",o,0,1455,o,0,0.96468616,True,0.96468616,0.030599914,0.0047138915
"1 Introduction The probabilistic relation between verbs and their arguments plays an important role in modern statistical parsers and supertaggers (Charniak 1995, Collins 1996/1997, Joshi and Srinivas 1994, Kim, Srinivas, and Trueswell 1997, Stolcke et al. 1997), and in psychological theories of language processing (Clifton et al. 1984, Ferfeira & McClure 1997, Gamsey et al. 1997, Jurafsky 1996, MacDonald 1994, Mitchell & Holmes 1985, Tanenhaus et al. 1990, Trueswell et al. 1993)",o,0,1456,p,1,0.57686687,False,0.41916957,0.57686687,0.003963561
"Various clustering techniques have been proposed (Brown et al. , 1992; Jardino and Adda, 1993; Martin et al. , 1998) which perform automatic word clustering optimizing a maximum-likelihood criterion with iterative clustering algorithms",o,0,1457,o,0,0.94897676,True,0.94897676,0.047979083,0.0030440742
"This may be because their system was not tuned using minimum error rate training (Och, 2003)",o,0,1458,n,2,0.74437565,False,0.2282444,0.02737996,0.74437565
"Some methods use sentence alignment and additional statistics to find candidate translations of terms (Smadja, 1992; van der Eijk, 1993)",o,0,1459,o,0,0.96754616,True,0.96754616,0.023992509,0.008461321
"Tuning is done for each experimental condition using Ochs Minimum Error Training (Och, 2003)",o,0,1460,o,0,0.9657118,True,0.9657118,0.029115727,0.0051725884
"Different optimization techniques are available, like the Simplex algorithm or the special Minimum Error Training as described in (Och 2003)",o,0,1461,o,0,0.86584646,True,0.86584646,0.12788226,0.0062712342
"The approach is in the spirit of Smadja (1993) on retrieving collocations from text corpora, but is more integrated with parsing",o,0,1462,n,2,0.74234575,False,0.21614045,0.041513804,0.74234575
"is combined with [ ]E jiT,1+ to be aligned with [ ] F nmT,, then [ ]( ) [ ]( )ATTCNTATTr E K E i FEF jinmjinm,.Pr,P,1],[,],[ ],1[ += where K is the degree of .EiN Finally, the node translation probability is modeled as ( ) ( ) ( )tNtNlNlNNN EiFlEiFlEjFl PrPrPr  . And the text translation probability ( )EF ttPr is model using IBM model I (Brown et al 1993)",o,0,1463,o,0,0.89905417,True,0.89905417,0.079448126,0.021497676
"Beside simple cooccurrence counts within sliding windows, other SoA measures include functions based on TF/IDF (Fung and Yee, 1998), mutual information (PMI) (Lin, 1998), conditional probabilities (Schuetze and Pedersen, 1997), chi-square test, and the loglikelihood ratio (Dunning, 1993)",o,0,1464,o,0,0.9572353,True,0.9572353,0.037407145,0.0053575262
"(Downey et al., 2007) use HMM-based similarity for the same purpose",o,0,1465,o,0,0.96519643,True,0.96519643,0.029979981,0.004823518
2006) and McClosky et a,o,0,1466,o,0,0.9678216,True,0.9678216,0.02301804,0.009160415
"In (Matusov et al. , 2006), different word orderings are taken into account by training alignment models by considering all hypothesis pairs as a parallel corpus using GIZA++ (Och and Ney, 2003)",o,0,1467,o,0,0.9635554,True,0.9635554,0.030815044,0.005629676
"The traditional framework presented in (Brown et al. , 1993) assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence",o,0,1468,o,0,0.95668596,True,0.95668596,0.03861634,0.0046976805
"Tillmann and Zhang (2006) used a different update style based on a convex loss function:  = L(e, e; et)max parenleftBig 0, 1 parenleftBig si( f t, e)si( f t, e) parenrightBigparenrightBig 768 Table 1: Experimental results obtained by varying normalized tokens used with surface form",o,0,1469,o,0,0.9701377,True,0.9701377,0.026390575,0.0034716346
"Foralllanguagepairs,weusedtheMosesdecoder (Koehnetal.,2007), whichfollowsthephrase-based statistical machine translation approach (Koehn et al., 2003), with default settings as a starting point",o,0,1470,o,0,0.9618582,True,0.9618582,0.034301914,0.0038398358
"The phrase bilexicon is derived from the intersection of bidirectional IBM Model 4 alignments, obtained with GIZA++ (Och and Ney, 2003), augmented to improve recall using the grow-diag-final heuristic",o,0,1471,o,0,0.94289714,True,0.94289714,0.0509511,0.0061517134
"Then, some manual and automatic symbol splitting methods are presented, which get comparable performance with lexicalized parsers (Klein and Manning, 2003; Matsuzaki et al., 2005)",o,0,1472,o,0,0.5489201,True,0.5489201,0.36494613,0.086133815
"By core phrases, we mean the kind of nonrecursive simplifications of the NP and VP that in the literature go by names such as noun/verb groups (Appelt et al. , 1993) or chunks, and base NPs (Ramshaw and Marcus, 1995)",o,0,1473,o,0,0.93872154,True,0.93872154,0.055405833,0.0058726156
n alternative training criterion therefore directly optimizes translation quality as measured by an automatic evaluation criterion (Och 2003,o,0,1474,o,0,0.62032187,True,0.62032187,0.34796903,0.03170916
"The next section briefly reviews the word alignment based statistical machine translation (Brown et al. , 1993)",o,0,1475,o,0,0.9516824,True,0.9516824,0.04147832,0.0068392935
"First, two maximum entropy classifiers (Berger et al. , 1996) are applied, where the first predicts clause start labels and the second predicts clause end labels",o,0,1476,o,0,0.95110756,True,0.95110756,0.04296553,0.005926905
ur method was applied to 23 million words of the WSJ that were automatically tagged with Ratnaparkhi's maximum entropy tagger (Ratnaparkhi 1996) and chunked with the partial parser CASS (Abney 1996,o,0,1477,o,0,0.9487202,True,0.9487202,0.048519675,0.002760109
"4.2 Impact of Paraphrases on Machine Translation Evaluation The standard way to analyze the performance of an evaluation metric in machine translation is to compute the Pearson correlation between the automatic metric and human scores (Papineni et al. , 2002; Koehn, 2004; Lin and Och, 2004; Stent et al. , 2005)",o,0,1478,o,0,0.9608279,True,0.9608279,0.035275877,0.003896126
"Note that unlike the constructions in (Talbot and Osborne, 2007b) and (Church et al., 2007) no errors are possible for ngrams stored in the model",o,0,1479,o,0,0.74091727,True,0.74091727,0.07706933,0.1820134
"In addition to adapting the idea of Head Word Chains (Liu and Gildea, 2005), we also compared the input sentences argument structures against the treebank for certain syntactic categories",o,0,1480,o,0,0.9518116,True,0.9518116,0.042882018,0.0053064018
"Following the suggestions in (Carletta, 1996), Core et al. consider kappa scores above 0.67 to indicate significant agreement and scores above 0.8 reliable agreement",o,0,1481,o,0,0.87763435,True,0.87763435,0.09830571,0.02405999
"In addition to sentence fusion, compression algorithms (Chandrasekar, Doran, and Bangalore 1996; Grefenstette 1998; Mani, Gates, and Bloedorn 1999; Knight and Marcu 2002; Jing and McKeown 2000; Reizler et al. 2003) and methods for expansion of a multiparallel corpus (Pang, Knight, and Marcu 2003) are other instances of such methods",o,0,1482,o,0,0.9564681,True,0.9564681,0.038629018,0.004902817
"For detailed descriptions of SMT models see for example (Brown et al. , 1993; Och and Ney, 2003)",o,0,1483,o,0,0.9648343,True,0.9648343,0.02841889,0.0067467825
"This is the best automatically learned part-of-speech tagging result known to us, representing an error reduction of 4.4% on the model presented in Collins (2002), using the same data splits, and a larger error reduction of 12.1% from the more similar best previous loglinear model in Toutanova and Manning (2000)",o,0,1484,n,2,0.3938747,False,0.34937987,0.2567454,0.3938747
"In this paper, we give an overview of NLPWin, a multi-application natural language analysis and generation system under development at Microsoft Research (Jensen et al. , 1993; Gamon et al. , 1997; Heidorn 2000), incorporating analysis systems for 7 languages (Chinese, English, French, German, Japanese, Korean and Spanish)",o,0,1485,o,0,0.9199173,True,0.9199173,0.075695984,0.0043867147
"l lhmsetsu ideni,illcation is a ln'oblem similar to ohm,king (lLamshaw and Marcus, 1995; Sang and \h;ellsl;ra, 1999) in other l;mguages",o,0,1486,o,0,0.95316154,True,0.95316154,0.042398524,0.004439953
"Breidt(1993) alsopointedouta coupleof problemsthatmakes extractionfor Germanmoredifficultthanfor English: the stronginflectionfor verbs,the variable word-order,andthepositionalambiguityofthearguments.Sheshowsthatevendistinguishingsubjectsfromobjectsisverydifficultwithoutparsing",o,0,1487,o,0,0.8046706,True,0.8046706,0.10222748,0.093101904
"\[Brown et al. , 1992\] Peter F. Brown, Vincent J. Della Pietra, Petere V. deSouza, Jenifer C. Lai, and Robert L. Mercer",o,0,1488,o,0,0.96998256,True,0.96998256,0.024986671,0.005030701
"Traditionally, such unsupervised EM-trained HMM taggers are thought to be inaccurate, but (Goldberg et al., 2008) showed that by feeding the EM process with sufficiently good initial probabilities, accurate taggers (> 91% accuracy) can be learned for both English and Hebrew, based on a (possibly incomplete) lexicon and large amount of raw text",o,0,1489,o,0,0.70477575,True,0.70477575,0.25252557,0.04269871
"Discriminative training with hidden variables has been handled in this probabilistic framework (Quattoni et al. , 2004; Koo and Collins, 2005), but we choose Equation 3 for efficiency",o,0,1490,o,0,0.9017603,True,0.9017603,0.086539306,0.01170039
"My guess is that the features used in e.g., the Collins (2003) or Charniak (2000) parsers are probably close to optimal for English Penn Treebank parsing (Marcus et al., 1993), but that other features might improve parsing of other languages or even other English genres",o,0,1491,o,0,0.5735038,True,0.5735038,0.20053391,0.22596227
"Apart from this, the module is a straightforward implementation of (Ramshaw and Marcus, 1995), which in turn adapts (Brill, 1993) for syntactic chunking",o,0,1492,o,0,0.8866961,True,0.8866961,0.10515361,0.008150254
"Recent advances in these approaches include the use of a fully Bayesian HMM (Johnson, 2007; Goldwater and Griffiths, 2007)",o,0,1493,p,1,0.77697146,False,0.21660164,0.77697146,0.006426832
"1 Introduction Previous corpus-based sense disambiguation methods require substantial amounts of sense-tagged training data (Kelly and Stone, 1975; Black, 1988 and Hearst, 1991) or aligned bilingual corpora (Brown et al. , 1991; Dagan, 1991 and Gale et al. 1992)",o,0,1494,o,0,0.81366736,True,0.81366736,0.09106834,0.095264204
his results also agree with Dunning's argument about overestimation on the infrequent occurrences in which many infrequent pairs tend to get higher estimation (Dunning 1993,p,1,1495,o,0,0.77802753,False,0.77802753,0.13179922,0.09017323
"The translation and reference files are analyzed by a treebank-based, probabilistic LFG parser (Cahill et al. , 2004), which produces a set of dependency triples for each input",o,0,1496,o,0,0.9663408,True,0.9663408,0.030221412,0.0034378446
"Although state-of-the-art statistical parsers (Collins, 1997; Charniak, 2000) are more accurate, the simplicity and efficiency of deterministic parsers make them attractive in a number of situations requiring fast, light-weight parsing, or parsing of large amounts of data",p,1,1497,p,1,0.6989515,True,0.14141248,0.6989515,0.15963608
"An extension to WordNet was presented by (Snow et al., 2006)",o,0,1498,o,0,0.9445414,True,0.9445414,0.047781806,0.0076767746
"5.1.2 Learning Translation Model According to the standard statistical translation model (Brown et al., 1993), we can find the optimal model M by maximizing the probability of generating queries from documents or M = argmax M NY i=1 P(QijDi;M) 524 qw dw P(qwjdw,u) journal kdd 0.0176 journal conference 0.0123 journal journal 0.0176 journal sigkdd 0.0088 journal discovery 0.0211 journal mining 0.0017 journal acm 0.0088 music music 0.0375 music purchase 0.0090 music mp3 0.0090 music listen 0.0180 music mp3.com 0.0450 music free 0.0008 Table 1: Sample user profile To find the optimal word translation probabilities P(qwjdw;M ), we can use the EM algorithm",o,0,1499,o,0,0.9273559,True,0.9273559,0.06471441,0.007929727
n the following section we show how this drawback can be overcome using statistical alignments (Brown et al. 1993,o,0,1500,o,0,0.5100351,True,0.5100351,0.41954345,0.07042153
"NeATS computes the likelihood ratio (Dunning, 1993) to identify key concepts in unigrams, bigrams, and trigrams and clusters these concepts in order to identify major subtopics within the main topic",o,0,1501,o,0,0.943333,True,0.943333,0.052856646,0.003810272
"The intercoder reliability is a constant concern of everyone working with corpora to test linguistic hypotheses (Carletta, 1996), and the more so when one is coding for semanto-pragmatic interpretations, as in the case of the analysis of connectives",o,0,1502,o,0,0.54815394,True,0.54815394,0.18397877,0.2678673
"The following four metrics were used speci cally in this study: BLEU (Papineni et al. , 2002): A weighted geometric mean of the n-gram matches between test and reference sentences multiplied by a brevity penalty that penalizes short translation sentences",o,0,1503,o,0,0.9499257,True,0.9499257,0.04564072,0.004433531
"84 5.2 Machine translation on Europarl corpus We further tested our WDHMM on a phrase-based machine translation system to see whether our improvement on word alignment can also improve MT accuracy measured by BLEU score (Papineni et al. , 2002)",o,0,1504,o,0,0.6973144,True,0.6973144,0.2229839,0.079701714
"2 The Tagger We used Ratnaparkhi's maximum entropybased POS tagger (Ratnaparkhi, 1996)",o,0,1505,o,0,0.93341583,True,0.93341583,0.053046826,0.013537347
"This approach is similar to conventional techniques for automatic thesaurus construction (Lin, 1998)",o,0,1506,o,0,0.95867974,True,0.95867974,0.033664234,0.007655918
"The conceptually simplest approach to this latter problem is probably Turneys (2002), who has obtained interesting results on Task 2 by considering the algebraic sum of the orientations of terms as representative of the orientation of the document they belong to; but more sophisticated approaches arealsopossible (Hatzivassiloglou and Wiebe, 2000; Riloff et al. , 2003; Wilson et al. , 2004)",p,1,1507,p,1,0.60191596,True,0.28852054,0.60191596,0.10956353
"(Collins parser (Collins, 1997) always predicts a flat NP for such configurations)",o,0,1508,o,0,0.8730594,True,0.8730594,0.07574887,0.05119172
"(2002) and Pang and Lee (2004) in merely using binary unigram features, corresponding to the 17,744 unstemmed word or punctuation types with count  4 in the full 2000-document corpus",o,0,1509,o,0,0.9290654,True,0.9290654,0.052190825,0.01874372
"Our question here is not only what this relation looks like (as it was examined on the basis of Document Understanding Conference data in Lin (2004a)), but also how it compares to the reliability of other metrics",o,0,1510,o,0,0.9064628,True,0.9064628,0.047042616,0.04649455
"For MCE learning, we selected the reference compression that maximize the BLEU score (Papineni et al., 2002) (=argmax rR BLEU(r, R\r)) from the set of reference compressions and used it as correct data for training",o,0,1511,o,0,0.9524646,True,0.9524646,0.042173214,0.0053621526
"1 Introduction Syntactic methods are an increasingly promising approach to statistical machine translation, being both algorithmically appealing (Melamed, 2004; Wu, 1997) and empirically successful (Chiang, 2005; Galley et al. , 2006)",o,0,1512,p,1,0.926772,False,0.062257774,0.926772,0.010970218
he research presented in this paper is similar in motivation to Resnik's (1993) work on selectional restriction,o,0,1513,o,0,0.90420264,True,0.90420264,0.07737622,0.018421138
"This ITG constraint is characterized by the two forbidden structures shown in Figure 1 (Wu, 1997)",o,0,1514,o,0,0.95693415,True,0.95693415,0.03283254,0.010233316
"Word-based features are used as well, e.g. feature a75 a11a39a99a78a99a18a11 captures word-to-word translation de4On our test set, (Tillmann and Zhang, 2005) reports a BLEU score of a100a63a101a63a102a43a103 and (Ittycheriah and Roukos, 2005) reports a BLEU score of a104a89a103a63a102 a105 . pendencies similar to the use of Model a98 probabilities in (Koehn et al. , 2003)",o,0,1515,o,0,0.9584099,True,0.9584099,0.036938842,0.004651318
"1 Introduction There has been a great deal of recent interest in the unsupervised discovery of syntactic structure from text, both parts-of-speech (Johnson, 2007; Goldwater and Griffiths, 2007; Biemann, 2006; Dasgupta and Ng, 2007) and deeper grammatical structure like constituency and dependency trees (Klein and Manning, 2004; Smith, 2006; Bod, 2006; Seginer, 2007; Van Zaanen, 2001)",o,0,1516,o,0,0.8361351,True,0.8361351,0.15679857,0.007066411
"In particular, Abney defines a function K that is an upper bound on the negative log-likelihood, and shows his bootstrapping algorithms locally minimize K. We now present a generalization of Abneys K function and relate it to another semi-supervised learning technique, entropy regularization (Brand, 1999; Grandvalet and Bengio, 2005; Jiao et al. , 2006)",o,0,1517,o,0,0.87996763,True,0.87996763,0.09761216,0.02242022
"Still, it is in our next plans and part of our future work to embed in our model some of the interesting WSD approaches, like knowledgebased (Sinha and Mihalcea, 2007; Brody et al., 2006), corpus-based (Mihalcea and Csomai, 2005; McCarthy et al., 2004), or combinations with very high accuracy (Montoyo et al., 2005)",o,0,1518,o,0,0.557726,True,0.557726,0.42264143,0.019632535
"Be-Comp Following the general idea in (Kazama and Torisawa, 2007), we identify the ISA pattern in the definition sentence by extracting nominal complements of the verb be, taking 451 No",o,0,1519,o,0,0.96396303,True,0.96396303,0.031493723,0.0045431973
"The data consists of 2,544 main clauses from the Wall Street Journal Treebank corpus (Marcus et al. , 1993)",o,0,1520,o,0,0.96517056,True,0.96517056,0.029395739,0.005433684
"(levelopment of cor1)ora with morl)ho-synta(:ti(: and syntacti(: mmotation (Marcus et al. , 1993), (Sampson, 1995)",o,0,1521,o,0,0.9609611,True,0.9609611,0.03394679,0.005092147
"First, splitting and merging of sentences (Jing and McKeown, 2000), which seems related to content planning and aggregation",o,0,1522,o,0,0.9633173,True,0.9633173,0.031622816,0.005059964
"4.2 Smoothing: Gaussian Priors Since NLP maximum entropy models usually have lots of features and lots of sparseness (e.g. features seen in testing not occurring in training), smoothing is essential as a way to optimize the feature weights (Chen and Rosenfeld, 2000; Klein and Manning, 2003)",o,0,1523,o,0,0.86596453,True,0.86596453,0.105980806,0.028054707
"The Maximum Entropy Markov Model used in POS-tagging is described in detail in (Ratnaparkhi, 1996) and the LMR tagger here uses the same probability model",o,0,1524,o,0,0.9436053,True,0.9436053,0.051235825,0.005158901
"For instance, the Penn Treebank policy (Marcus et al. , 1993; Marcus et al. , 1994) is to annotate the lowest node that is unfinished with an -UNF tag as in Figure 4(a)",o,0,1525,o,0,0.9678526,True,0.9678526,0.025047723,0.0070996163
"After maximum BLEU tuning (Och, 2003a) on a held-out tuning set, we evaluate translation quality on a held-out test set",o,0,1526,o,0,0.94920087,True,0.94920087,0.040893335,0.0099058
"Other works based on this scheme like (Bharati et al., 1993; Bharati et al., 2002; Pedersen et al., 2004) have shown promising results",o,0,1527,p,1,0.8409423,False,0.151881,0.8409423,0.007176783
"These models include a standard unlexicalized PCFG parser, a head-lexicalized parser (Collins, 1997), and a maximum-entropy inspired parser (Charniak, 2000)",o,0,1528,o,0,0.96847075,True,0.96847075,0.027299562,0.0042296727
"Kazama and Torisawa (2007) extracted hyponymyrelationsfromtherstsentences(i.e., dening sentences) of Wikipedia articles and then used them as a gazetteer for NER",o,0,1529,o,0,0.96513236,True,0.96513236,0.03177778,0.0030898564
"(~(e) = max ((fl ,f~) ~ e) (23) (11  Y~) Now, the problem of learning probabilistic subcategorization preference is stated as: for every verb-noun collocation e in C, estimating the probability distribution P((fl, 6Resnik (1993) applys the idea of the KL distance to measuring the association of a verb v and its object noun class c. Our definition of ekt corresponds to an extension of Resnik's association score, which considers dependencies of more than one case-markers in a subcategorization frame",o,0,1530,o,0,0.9291851,True,0.9291851,0.058472756,0.012342134
"We decided to use the class of maximum entropy models, which are probabilistically sound, can make use of possibly many overlapping features, and can be trained efficiently (Berger et al., 1996)",p,1,1531,o,0,0.60501856,False,0.60501856,0.38083586,0.014145546
"4 Related work Algorithms for retrieving collocations has been described (Smadja, 1993) (Haruno et al. , 1996)",o,0,1532,o,0,0.9504229,True,0.9504229,0.04599187,0.0035852524
"AL has already been applied to several NLP tasks, such as document classification (Schohn and Cohn, 2000), POS tagging (Engelson and Dagan, 1996), chunking (Ngai and Yarowsky, 2000), statistical parsing (Thompson et al. , 1999; Hwa, 2000), and information extraction (Lewis and Catlett, 1994; Thompson et al. , 1999)",o,0,1533,o,0,0.91616714,True,0.91616714,0.07904391,0.0047888607
"This system uses all featuresof conventionalphrase-basedSMT as in (Koehn et al., 2003)",o,0,1534,o,0,0.95672303,True,0.95672303,0.03699217,0.006284733
"This latter point is a critical difference that contrasts to the major weakness of the work of (Liang et al. , 2006) which uses a top-N list of translations to select the maximum BLEU sentence as a target for training (so called local update)",n,2,1535,n,2,0.57614285,True,0.20365109,0.22020604,0.57614285
"Within the NLP community, n-best list ranking has been looked at carefully in parsing, extractive summarization (Barzilay et al. 1999; Hovy and Lin 1998), and machine translation (Zhang et al. 2006), to name a few",o,0,1536,o,0,0.5944366,True,0.5944366,0.39714196,0.008421417
"To measure the coherence of sentences, we use a statistical parser Toolkit (Collins, 1997) to assign each sentence a parsers score that is the related log probability of parsing",o,0,1537,o,0,0.9537422,True,0.9537422,0.043701638,0.0025561913
"Step Description mean stddev % 1.5 Sample 1.5s 0.07s 0.7% 1.6 Extraction 38.2s 0.13s 18.6% 1.7 Build tree 127.6s 27.60s 62.3% 1.8 Percolation 31.4s 4.91s 15.3% 1.911 Leaf updates 6.2s 1.75s 3.0% 1.511 Total 204.9s 32.6s 100.0% 2004),10 the only one that we were able to train and test under exactly the same experimental conditions (including the use of POS tags from Ratnaparkhi (1996))",o,0,1538,o,0,0.5709592,True,0.5709592,0.2128576,0.21618323
"While the idea of exploiting multiple news reports for paraphrase acquisition is not new, previous efforts (for example, Shinyama et al. 2002; Barzilay and Lee 2003) have been restricted to at most two news sources",n,2,1539,o,0,0.57277477,False,0.57277477,0.15173316,0.2754921
"Performance of Alternative Models 157 5 Related Work Previous parsing models (e.g. , Collins, 1997; Charniak, 2000) maximize the joint probability P(S, T) of a sentence S and its parse tree T. We maximize the conditional probability P(T | S)",o,0,1540,o,0,0.94522583,True,0.94522583,0.047529098,0.0072451346
"Maximum entropy (ME) models have been used in bilingual sense disambiguation, word reordering, and sentence segmentation (Berger et al. , 1996), parsing, POS tagging and PP attachment (Ratnaparkhi, 1998), machine translation (Och and Ney, 2002), and FrameNet classification (Fleischman et al. , 2003)",o,0,1541,o,0,0.92977184,True,0.92977184,0.066616535,0.0036116256
"Second, the automatic approach, in which the model is automatically obtained from corpora (either raw or annotated) 1, and consists of n-grams (Garside et al. , 1987; Cutting et ah, 1992), rules (Hindle, 1989) or neural nets (Schmid, 1994)",o,0,1542,o,0,0.966165,True,0.966165,0.0302399,0.0035951461
"In all experiments that follow, each system configuration was independently optimized on the NIST 2003 Chinese-English test set (919 sentences) using minimum error rate training (Och, 2003) and tested on the NIST 2005 Chinese-English task (1082 sentences)",o,0,1543,o,0,0.96121544,True,0.96121544,0.033234034,0.005550576
"The Perceptron style for natural language processing problems as initially proposed by (Collins, 2002) can provide state of the art results on various domains including text chunking, syntactic parsing, etc. The main drawback of the Perceptron style algorithm is that it does not have a mechanism for attaining the maximize margin of the training data",p,1,1544,n,2,0.84887874,False,0.110078275,0.04104297,0.84887874
"(Barzilay & Lee, 2003) present a knowledge-lean algorithm that uses multiple-sequence alignment to 177 learn generate sentence-level paraphrases essentially from unannotated corpus data alone",o,0,1545,o,0,0.9535517,True,0.9535517,0.041847583,0.0046007037
"Our method, extending this line of research with the use of labelled LFG dependencies, partial matching, and n-best parses, allows us to considerably outperform Liu and Gildea?s (2005) highest correlations with human judgement (they report 0.144 for the correlation with human fluency judgement, 0.202 for the correlation with human overall judgement), although it has to be kept in mind that such comparison is only tentative, as their correlation is calculated on a different test set",n,2,1546,o,0,0.4322174,False,0.4322174,0.19500598,0.37277666
"The usual recall and precision metrics (e.g. , how many of the interesting bits of information were detected, and how many of the found bits were actually correct) require either a test corpus previously annotated with the required information, or manual evaluation (Fleischman et al. , 2003)",o,0,1547,o,0,0.9428518,True,0.9428518,0.04520969,0.0119385
"5 Related Work Automatically finding sentences with the same meaning has been extensively studied in the field of automatic paraphrasing using parallel corpora and corporawith multiple descriptionsof the same events (Barzilay and McKeown, 2001; Barzilay and Lee, 2003)",o,0,1548,o,0,0.55272883,True,0.55272883,0.4436966,0.0035745949
"Salience Feature Pronoun Name Nominal TOP 0.75 0.17 0.08 HIGH 0.55 0.28 0.17 MID 0.39 0.40 0.21 LOW 0.20 0.45 0.35 NONE 0.00 0.88 0.12 Table 2: Posterior distribution of mention type given salience (taken from Haghighi and Klein (2007)) 3.3 Modifications to the H&K Model Next, we discuss the potential weaknesses of H&Ks model and propose three modifications to it",o,0,1549,o,0,0.7164788,True,0.7164788,0.120733656,0.1627875
"A number of alignment techniques have been proposed, varying from statistical methods (Brown et al. , 1991; Gale and Church, 1991) to lexical methods (Kay and RSscheisen, 1993; Chen, 1993)",o,0,1550,o,0,0.9373975,True,0.9373975,0.060219135,0.0023833285
"To determine the tree head-word we used a set of rules similar to that described by (Magerman, 1995)(Jelinek et al. , 1994) and also used by (Collins, 1996), which we modified in the following way:  The head of a prepositional phrase (PP-IN NP) was substituted by a function the name of which corresponds to the preposition, and its sole argument corresponds to the head of the noun phrase NP",o,0,1551,o,0,0.96231407,True,0.96231407,0.03422881,0.0034571157
"In many cases, improving semi-supervised models was done by seeding these models with domain information taken from dictionaries or ontology (Cohen and Sarawagi, 2004; Collins and Singer, 1999; Haghighi and Klein, 2006; Thelen and Riloff, 2002)",o,0,1552,o,0,0.8687667,True,0.8687667,0.12564757,0.0055856435
"First, a non-anaphoric NP classifier identifies definite noun phrases that are existential, using both syntactic rules and our learned existential NP recognizer (Bean and Riloff, 1999), and removes them from the resolution process",o,0,1553,o,0,0.92576605,True,0.92576605,0.064666584,0.009567347
"We can confirm that changing the dimensionality parameter h has rather little effect (Table 4), which is in line with previous findings (Ando and Zhang, 2005; Blitzer et al., 2006)",o,0,1554,o,0,0.55272853,True,0.55272853,0.35721704,0.09005439
"7 For the most frequent 184 expressions, on the average, the agreement rate between two human annotators is 0.93 and the Kappa value is 0.73, which means allowing tentative conclusions to be drawn (Carletta, 1996; Ng et al. , 1999)",o,0,1555,o,0,0.8974232,True,0.8974232,0.073700964,0.028875805
"Concluding Remarks Formalisms for finite-state and context-free transduction have a long history (e.g. , Lewis and Stearns 1968; Aho and Ullman 1972), and such formalisms have been applied to the machine translation problem, both in the finite-state case (e.g. , Vilar et al. 1996) and the context-free case (e.g. , Wu 1997)",o,0,1556,o,0,0.67809814,True,0.67809814,0.31843954,0.0034623526
"4.1 Corpora Sentence compression systems have been tested on product review data from the Ziff-Davis (ZD, henceforth) Corpus by Knight and Marcu (2000), general news articles by Clarke and Lapata (CL, henceforth) corpus (2007) and biomedical articles (Lin and Wilbur, 2007)",o,0,1557,o,0,0.91218954,True,0.91218954,0.08410439,0.003706131
"6 Related Work The popular IBM models for statistical machine translation are described in (Brown et al. , 1993)",p,1,1558,p,1,0.9183407,True,0.07237037,0.9183407,0.009288884
"BLEU For all translation tasks, we report caseinsensitive NIST BLEU scores (Papineni et al., 2002) using 4 references per sentence",o,0,1559,o,0,0.96640223,True,0.96640223,0.029858463,0.0037392783
"Transformation-based learning has also been successfully applied to text chunking (Ramshaw and Marcus, 1995), morphological disambiguation (Oflazer and Tur, 1996), and phrase parsing (Vilain and Day, 1996)",o,0,1560,p,1,0.9052176,False,0.09153043,0.9052176,0.0032519966
"Finally, knowledge of polarity can be combined with corpus-based collocation extraction methods (Smadja, 1993) to automatically produce entries for the lexical functions used in MeaningText Theory (Mel'~uk and Pertsov, 1987) for text generation",o,0,1561,o,0,0.94040257,True,0.94040257,0.05614562,0.0034517667
"Because our algorithm does not consider the context given by the preceding sentences, we have conducted the following experiment to see to what extent the discourse context could improve the performance of the wordsense disambiguation: Using the semantic concordance files (Miller et al. , 1993), we have counted the occurrences of content words which previously appear in the same discourse file",o,0,1562,o,0,0.88429105,True,0.88429105,0.08470242,0.031006608
"Both Charniak (2000) and Bikel (2004) were trained using the goldstandard tags, as this produced higher accuracy on the development set than using Ratnaparkhi (1996)s tags",n,2,1563,n,2,0.7797741,True,0.1724265,0.047799353,0.7797741
"IBM constraints (Berger et al., 1996), lexical word reordering model (Tillmann, 2004), and inversion transduction grammar (ITG) constraints (Wu, 1995; Wu, 1997) belong to this type of approach",o,0,1564,o,0,0.9640928,True,0.9640928,0.031032354,0.0048747957
"BLEU (Papineni et al. , 2002b) is one of the methods for automatic evaluation of translation quality",o,0,1565,o,0,0.95942765,True,0.95942765,0.036479287,0.0040931124
"7.1 Interand Intra-annotator agreement We measured pairwise agreement among annotators usingthekappacoefficient(K)whichiswidelyused in computational linguistics for measuring agreement in category judgments (Carletta, 1996)",o,0,1566,o,0,0.5110131,True,0.5110131,0.48571107,0.003275893
"3.1 Agreement for Emotion Classes The kappa coefficient of agreement is a statistic adopted by the Computational Linguistics community as a standard measure for this purpose (Carletta, 1996)",o,0,1567,o,0,0.9376108,True,0.9376108,0.05973493,0.0026542111
"Most of this prior work deals with supervised transfer learning, and thus requires labeled source domain data, though there are examples of unsupervised (Arnold et al., 2007), semi-supervised (Grandvalet and Bengio, 2005; Blitzer et al., 2006), and transductive approaches (Taskar et al., 2003)",o,0,1568,o,0,0.90666366,True,0.90666366,0.06751565,0.025820734
"(2007), we introduced the Movie Review Polarity Dataset Enriched with Annotator Rationales.8 It is based on the dataset of Pang and Lee (2004),9 which consists of 1000 positive and 1000 negative movie reviews, tokenized and divided into 10 folds (F0F9)",o,0,1569,o,0,0.91155446,True,0.91155446,0.08286412,0.005581448
"1 Introduction Currently, most of the phrase-based statistical machine translation (PBSMT) models (Marcu and Wong, 2002; Koehn et al., 2003) adopt full matching strategy for phrase translation, which means that a phrase pair (tildewidef,tildewidee) can be used for translating a source phrase f, only if tildewidef = f. Due to lack of generalization ability, the full matching strategy has some limitations",n,2,1570,n,2,0.8384561,True,0.12819743,0.0333465,0.8384561
"This means that the 1)roblem of recognizing named entities in those cases can be solved by incorporating techniques of base noun phrase chunking (Ramshaw and Marcus, 1995)",p,1,1571,o,0,0.8333497,False,0.8333497,0.15102501,0.015625292
"Various machine learning strategies have been proposed to address this problem, including semi-supervised learning (Zhu, 2007), domain adaptation (Wu and Dietterich, 2004; Blitzer et al., 2006; Blitzer et al., 2007; Arnold et al., 2007; Chan and Ng, 2007; Daume, 2007; Jiang and Zhai, 2007; Reichart and Rappoport, 2007; Andreevskaia and Bergler, 2008), multi-task learning (Caruana, 1997; Reichart et al., 2008; Arnold et al., 2008), self-taught learning (Raina et al., 2007), etc. A commonality among these methods is that they all require the training data and test data to be in the same feature space",o,0,1572,o,0,0.78717935,True,0.78717935,0.19757769,0.015242997
"The basic engine used to perform the tagging in these experiments is a direct descendent of the maximum entropy (ME) tagger of (Ratnaparkhi, 1996) which in turn is related to the taggers of (Kupiec, 1992) and (Merialdo, 1994)",o,0,1573,o,0,0.93345684,True,0.93345684,0.06270588,0.0038372427
"6.3 Unsupervised sentiment classification Turney proposed the unsupervised method for sentiment classification (Turney, 2002), and similar method is utilized by many other researchers (Yu and Hatzivassiloglou, 2003)",o,0,1574,o,0,0.8193355,True,0.8193355,0.17308904,0.0075753527
"The implementation of the algorithm is one that has a core of code that can run on either the Penn Treebank (Marcus et al. , 1993) or on the Chinese Treebank",o,0,1575,o,0,0.9617896,True,0.9617896,0.033083834,0.0051264875
"The best previous result is an accuracy of 56.1% (Turney, 2006)",p,1,1576,p,1,0.76710474,True,0.20306413,0.76710474,0.029831147
"This paper proposes a method for building a bilingual lexicon through a pivot language by using phrase-based statistical machine translation (SMT) (Koehn et al., 2003)",o,0,1577,o,0,0.94522285,True,0.94522285,0.05045091,0.004326254
"In computational linguistics, our pattern discovery procedure extends over previous approaches that use surface patterns as indicators of semantic relations between nouns or verbs ((Hearst, 1998; Chklovski and Pantel, 2004; Etzioni et al., 2004; Turney, 2006; Davidov and Rappoport, 2008) inter alia)",o,0,1578,o,0,0.9562542,True,0.9562542,0.037136883,0.0066088815
"Accurate automatic analysis of these aspects of language will augment existing research in the fields of sentiment (Pang et al. , 2002) andsubjectivityanalysis(Wiebeetal",o,0,1579,p,1,0.5517529,False,0.42761254,0.5517529,0.020634564
"We compared our system to Pharaoh, a leading phrasal SMT decoder (Koehn et al. , 2003), and our treelet system",o,0,1580,o,0,0.70896155,True,0.70896155,0.28283283,0.0082056
"Under a phrase based translation model (Koehn et al. , 2003; Marcu and Wong, 2002), this distinction is important and will be discussed in more detail",o,0,1581,o,0,0.6115829,True,0.6115829,0.3534389,0.034978107
"Many authors claim that class-based methods are more robust against data sparseness problems (Dagan,1994), (Pereira, 1993), (Brown et al. ,1992)",o,0,1582,n,2,0.5200239,False,0.25511554,0.22486058,0.5200239
"In a different work, Banerjee and Lavie (2005) argued that the measured reliability of metrics can be due to averaging effects but might not be robust across translations",o,0,1583,n,2,0.48742887,False,0.4446767,0.06789436,0.48742887
"This fact, along with the observation that machine translation quality improves as the amount of monolingual training material increases, has lead to the introduction of randomised techniques for representing large LMs in small space (Talbot and Osborne, 2007; Talbot and Brants, 2008)",o,0,1584,o,0,0.8047291,True,0.8047291,0.19076696,0.004503968
"In parsing, the most relevant previous work is due to Collins (1997), who considered three binary features of the intervening material: did it contain (a) any word tokens at all, (b) any verbs, (c) any commas or colons",o,0,1585,p,1,0.5339722,False,0.4379486,0.5339722,0.028079262
"A simple example is shown in Figure 1, where the arc between a and hat indicates that hat is the head of a. Current statistical dependency parsers perform better if the dependency lengthes are shorter (McDonald and Nivre, 2007)",o,0,1586,o,0,0.46221372,True,0.46221372,0.2942316,0.24355465
"Recently, several solutions to the problem of tagging unknown words have been presented (Charniak et al. 1993; Meteer, Schwartz, and Weischedel 1991)",o,0,1587,o,0,0.7904496,True,0.7904496,0.19070485,0.018845493
"Also, adding a constituent size/distance effect, as described by Schubert (1986) and as used by some researchers in parsing (e.g. Lesmo and Torasso (1985) and Collins (1997)) would almost certainly improve parsing",o,0,1588,o,0,0.6084032,True,0.6084032,0.36973664,0.021860164
"6.2 Experimental Settings We utilize a maximum entropy (ME) model (Berger et al., 1996) to design the basic classifier for WSD and TC tasks",o,0,1589,o,0,0.9484794,True,0.9484794,0.047977358,0.0035431506
"This additional conditioning has the effect of making the choice of generation rules sensitive to the history of the generation process, and, we argue, provides a simpler, more uniform, general, intuitive and natural probabilistic generation model obviating the need for CFG-grammar transforms in the original proposal of (Cahill and van Genabith, 2006)",n,2,1590,o,0,0.44158936,False,0.44158936,0.40482962,0.153581
"3 Related work Word collocation Various collocation metrics have been proposed, including mean and variance (Smadja, 1994), the t-test (Church et al. , 1991), the chi-square test, pointwise mutual information (MI) (Church and Hanks, 1990), and binomial loglikelihood ratio test (BLRT) (Dunning, 1993)",o,0,1591,o,0,0.94930404,True,0.94930404,0.04775019,0.0029456764
"The cohesion between words has been evaluated with the mutual information measure, as in (Church and Hanks, 1990)",o,0,1592,o,0,0.96427476,True,0.96427476,0.031472526,0.004252675
"Tile full description of Model 4 (Brown et al. , 1993) is rather complica.ted as there have to be considered tile cases that English words have fertility larger than one and that English words have fertility zero",o,0,1593,n,2,0.4888334,False,0.43202633,0.079140194,0.4888334
"1 Introduction In this paper, we present an approach for extracting the named entities (NE) of natural language inputs which uses the maximum entropy (ME) framework (Berger et al. , 1996)",o,0,1594,o,0,0.9515013,True,0.9515013,0.04329665,0.0052020703
"Dependency relations are produced using a version of the Collins parser (Collins, 1997) that has been adapted for building dependencies",o,0,1595,o,0,0.9563779,True,0.9563779,0.040717542,0.002904549
